<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python3.x标准模块库目录]]></title>
    <url>%2F2018%2F11%2F23%2Fpython%E8%B5%84%E6%BA%90%2F</url>
    <content type="text"><![CDATA[Python 资源大全中文版关于项目我们要做什么？ 基于 awesome-python 列表整理。此外还将从其他来源补充好资源。 可参考已整理的内容： 《Scrapy：Python 的爬虫框架》 《Flask：一个使用 Python 编写的轻量级 Web 应用框架》 资源列表环境管理管理 Python 版本和环境的工具 p：非常简单的交互式 python 版本管理工具。官网 pyenv：简单的 Python 版本管理工具。官网 Vex：可以在虚拟环境中执行命令。官网 virtualenv：创建独立 Python 环境的工具。官网 virtualenvwrapper：virtualenv 的一组扩展。官网 包管理管理包和依赖的工具。 pip：Python 包和依赖关系管理工具。官网 pip-tools：保证 Python 包依赖关系更新的一组工具。官网 pipenv：Pyhton 官方推荐的新一代包管理工具。官网 conda：跨平台，Python 二进制包管理工具。官网 Curdling：管理 Python 包的命令行工具。官网 wheel：Python 分发的新标准，意在取代 eggs。官网 包仓库本地 PyPI 仓库服务和代理。 warehouse：下一代 PyPI。官网 bandersnatch：PyPA 提供的 PyPI 镜像工具。官网 devpi：PyPI 服务和打包/测试/分发工具。官网 localshop：本地 PyPI 服务（自定义包并且自动对 PyPI 镜像）。官网 分发打包为可执行文件以便分发。 PyInstaller：将 Python 程序转换成独立的执行文件（跨平台）。官网 dh-virtualenv：构建并将 virtualenv 虚拟环境作为一个 Debian 包来发布。官网 Nuitka：将脚本、模块、包编译成可执行文件或扩展模块。官网 py2app：将 Python 脚本变为独立软件包（Mac OS X）。官网 py2exe：将 Python 脚本变为独立软件包（Windows）。官网 pynsist：一个用来创建 Windows 安装程序的工具，可以在安装程序中打包 Python 本身。官网 构建工具将源码编译成软件。 buildout：一个构建系统，从多个组件来创建，组装和部署应用。官网 BitBake：针对嵌入式 Linux 的类似 make 的构建工具。官网 fabricate：对任何语言自动找到依赖关系的构建工具。官网 PlatformIO：多平台命令行构建工具。官网 PyBuilder：纯 Python 实现的持续化构建工具。官网 SCons：软件构建工具。官网 交互式解析器交互式 Python 解析器。 IPython：功能丰富的工具，非常有效的使用交互式 Python。官网 bpython：界面丰富的 Python 解析器。官网 ptpython：高级交互式 Python 解析器， 构建于 python-prompt-toolkit 之上。官网 文件文件管理和 MIME（多用途的网际邮件扩充协议）类型检测。 aiofiles：基于 asyncio，提供文件异步操作。官网 imghdr：（Python 标准库）检测图片类型。官网 mimetypes：（Python 标准库）将文件名映射为 MIME 类型。官网 path.py：对 os.path 进行封装的模块。官网 pathlib：（Python3.4+ 标准库）跨平台的、面向对象的路径操作库。官网 python-magic：文件类型检测的第三方库 libmagic 的 Python 接口。官网 Unipath：用面向对象的方式操作文件和目录。官网 watchdog：管理文件系统事件的 API 和 shell 工具。官网 日期和时间操作日期和时间的类库。 arrow：更好的 Python 日期时间操作类库。官网 Chronyk：Python 3 的类库，用于解析手写格式的时间和日期。官网 dateutil：Python datetime 模块的扩展。官网 delorean：解决 Python 中有关日期处理的棘手问题的库。官网 maya：人性化的时间处理库。官网 moment：一个用来处理时间和日期的 Python 库。灵感来自于 Moment.js。官网 pendulum：一个比 arrow 更具有明确的，可预测的行为的时间操作库。官网 PyTime：一个简单易用的 Python 模块，用于通过字符串来操作日期/时间。官网 pytz：现代以及历史版本的世界时区定义。将时区数据库引入 Python。官网 when.py：提供用户友好的函数来帮助用户进行常用的日期和时间操作。官网 文本处理用于解析和操作文本的库。 通用 chardet：字符编码检测器，兼容 Python2 和 Python3。官网 difflib：(Python 标准库)帮助我们进行差异化比较。官网 ftfy：让 Unicode 文本更完整更连贯。官网 fuzzywuzzy：模糊字符串匹配。官网 Levenshtein：快速计算编辑距离以及字符串的相似度。官网 pangu.py：在中日韩语字符和数字字母之间添加空格。官网 pypinyin：汉字拼音转换工具 Python 版。官网 shortuuid：一个生成器库，用以生成简洁的，明白的，URL 安全的 UUID。官网 simplejson：Python 的 JSON 编码、解码器。官网 unidecode：Unicode 文本的 ASCII 转换形式 。官网 uniout：打印可读的字符，而不是转义的字符串。官网 xpinyin：一个用于把汉字转换为拼音的库。官网 yfiglet-figlet：pyfiglet -figlet 的 Python 实现。 flashtext: 一个高效的文本查找替换库。官网 Slug 化 awesome-slugify：一个 Python slug 化库，可以保持 Unicode。官网 python-slugify：Python slug 化库，可以把 unicode 转化为 ASCII。官网 unicode-slugify：一个 slug 工具，可以生成 unicode slugs ,需要依赖 Django 。官网 解析器 phonenumbers：解析，格式化，储存，验证电话号码。官网 PLY：lex 和 yacc 解析工具的 Python 实现。官网 Pygments：通用语法高亮工具。官网 pyparsing：生成通用解析器的框架。官网 python-nameparser：把一个人名分解为几个独立的部分。官网 python-user-agents：浏览器 user agent 解析器。官网 sqlparse：一个无验证的 SQL 解析器。官网 特殊文本格式处理一些用来解析和操作特殊文本格式的库。 通用 tablib：一个用来处理中表格数据的模块。官网 Office Marmir：把输入的 Python 数据结构转换为电子表单。官网 openpyxl：一个用来读写 Excel 2010 xlsx/xlsm/xltx/xltm 文件的库。官网 pyexcel：一个提供统一 API，用来读写，操作 Excel 文件的库。官网 python-docx：读取，查询以及修改 Microsoft Word 2007/2008 docx 文件。官网 relatorio：模板化 OpenDocument 文件。官网 unoconv：在 LibreOffice/OpenOffice 支持的任意文件格式之间进行转换。官网 XlsxWriter：一个用于创建 Excel .xlsx 文件的 Python 模块。官网 xlwings：一个使得在 Excel 中方便调用 Python 的库（反之亦然），基于 BSD 协议。官网 xlwt：读写 Excel 文件的数据和格式信息。官网 / xlrd PDF PDFMiner：一个用于从 PDF 文档中抽取信息的工具。官网 PyPDF2：一个可以分割，合并和转换 PDF 页面的库。官网 ReportLab：快速创建富文本 PDF 文档。官网 Markdown Mistune：快速并且功能齐全的纯 Python 实现的 Markdown 解析器。官网 Python-Markdown：John Gruber’s Markdown 的 Python 版实现。官网 Python-Markdown2：纯 Python 实现的 Markdown 解析器，比 Python-Markdown 更快，更准确，可扩展。官网 YAML PyYAML：Python 版本的 YAML 解析器。官网 CSV csvkit：用于转换和操作 CSV 的工具。官网 Archive unp：一个用来方便解包归档文件的命令行工具。官网 自然语言处理用来处理人类语言的库。 NLTK：一个先进的平台，用以构建处理人类语言数据的 Python 程序。官网 jieba：中文分词工具。官网 langid.py：独立的语言识别系统。官网 Pattern：Python 网络信息挖掘模块。官网 SnowNLP：一个用来处理中文文本的库。官网 TextBlob：为进行普通自然语言处理任务提供一致的 API。官网 TextGrocery：一简单高效的短文本分类工具，基于 LibLinear 和 Jieba。官网 thulac:清华大学自然语言处理与社会人文计算实验室研制推出的一套中文词法分析工具包官网 文档用以生成项目文档的库。 Sphinx：Python 文档生成器。官网 awesome-sphinxdoc：官网 MkDocs：对 Markdown 友好的文档生成器。官网 pdoc：一个可以替换 Epydoc 的库，可以自动生成 Python 库的 API 文档。官网 Pycco：文学编程（literate-programming）风格的文档生成器。官网 readthedocs：一个基于 Sphinx/MkDocs 的在线文档托管系统，对开源项目免费开放使用。官网 配置用来保存和解析配置的库。 config：logging 模块作者写的分级配置模块。官网 ConfigObj：INI 文件解析器，带验证功能。官网 ConfigParser：(Python 标准库) INI 文件解析器。官网 profig：通过多种格式进行配置，具有数值转换功能。官网 python-decouple：将设置和代码完全隔离。官网 命令行工具用于创建命令行程序的库。 命令行程序开发 asciimatics：跨平台，全屏终端包（即鼠标/键盘输入和彩色，定位文本输出），完整的复杂动画和特殊效果的高级 API。官网 cement：Python 的命令行程序框架。官网 click：一个通过组合的方式来创建精美命令行界面的包。官网 cliff：一个用于创建命令行程序的框架，可以创建具有多层命令的命令行程序。官网 clint：Python 命令行程序工具。官网 colorama：跨平台彩色终端文本。官网 docopt：Python 风格的命令行参数解析器。官网 Gooey：一条命令，将命令行程序变成一个 GUI 程序。官网 python-prompt-toolkit：一个用于构建强大的交互式命令行程序的库。官网 python-fire：Google 出品的一个基于 Python 类的构建命令行界面的库。官网 Pythonpy：在命令行中直接执行任何 Python 指令。官网 生产力工具 aws-cli：Amazon Web Services 的通用命令行界面。官网 bashplotlib：在终端中进行基本绘图。官网 caniusepython3：判断是哪个项目妨碍你你移植到 Python3。官网 cookiecutter：从 cookiecutters（项目模板）创建项目的一个命令行工具。官网 doitlive：一个用来在终端中进行现场演示的工具。官网 pyftpdlib：一个速度极快和可扩展的 Python FTP 服务库。官网 howdoi：通过命令行获取即时的编程问题解答。官网 httpie：一个命令行 HTTP 客户端，cURL 的替代品，易用性更好。官网 PathPicker：从 bash 输出中选出文件。官网 percol：向 UNIX shell 传统管道概念中加入交互式选择功能。官网 SAWS：一个加强版的 AWS 命令行。官网 thefuck：修正你之前的命令行指令。官网 mycli：一个 MySQL 命令行客户端，具有自动补全和语法高亮功能。官网 pgcli：Postgres 命令行工具，具有自动补全和语法高亮功能。官网 try：一个从来没有更简单的命令行工具，用来试用 python 库。官网 下载器用来进行下载的库. s3cmd：一个用来管理 Amazon S3 和 CloudFront 的命令行工具。官网 s4cmd：超级 S3 命令行工具，性能更加强劲。官网 you-get：一个 YouTube/Youku/Niconico 视频下载器，使用 Python3 编写。官网 youtube-dl：一个小巧的命令行程序，用来下载 YouTube 视频。官网 图像处理用来操作图像的库. pillow：Pillow 是一个更加易用版的 PIL。官网 hmap：图像直方图映射。官网 imgSeek：一个使用视觉相似性搜索一组图片集合的项目。官网 nude.py：裸体检测。官网 pyBarcode：不借助 PIL 库在 Python 程序中生成条形码。官网 pygram：类似 Instagram 的图像滤镜。官网 python-qrcode：一个纯 Python 实现的二维码生成器。官网 Quads：基于四叉树的计算机艺术。官网 scikit-image：一个用于（科学）图像处理的 Python 库。官网 thumbor：一个小型图像服务，具有剪裁，尺寸重设和翻转功能。官网 wand：MagickWand的 Python 绑定。MagickWand 是 ImageMagick 的 C API 。官网 face_recognition：简单易用的 python 人脸识别库。官网 OCR光学字符识别库。 pyocr：Tesseract 和 Cuneiform 的一个封装(wrapper)。官网 pytesseract：Google Tesseract OCR 的另一个封装(wrapper)。官网 python-tesseract：Google Tesseract OCR 的一个包装类。 音频用来操作音频的库 audiolazy：Python 的数字信号处理包。官网 audioread：交叉库 (GStreamer + Core Audio + MAD + FFmpeg) 音频解码。官网 beets：一个音乐库管理工具及 MusicBrainz 标签添加工具。官网 dejavu：音频指纹提取和识别。官网 django-elastic-transcoder：Django + Amazon Elastic Transcoder。官网 eyeD3：一个用来操作音频文件的工具，具体来讲就是包含 ID3 元信息的 MP3 文件。官网 id3reader：一个用来读取 MP3 元数据的 Python 模块。官网 m3u8：一个用来解析 m3u8 文件的模块。官网 mutagen：一个用来处理音频元数据的 Python 模块。官网 pydub：通过简单、简洁的高层接口来操作音频文件。官网 pyechonest：Echo Nest API 的 Python 客户端。官网 talkbox：一个用来处理演讲/信号的 Python 库。官网 TimeSide：开源 web 音频处理框架。官网 tinytag：一个用来读取 MP3, OGG, FLAC 以及 Wave 文件音乐元数据的库。官网 mingus：一个高级音乐理论和曲谱包，支持 MIDI 文件和回放功能。官网 Video用来操作视频和 GIF 的库。 moviepy：一个用来进行基于脚本的视频编辑模块，适用于多种格式，包括动图 GIFs。官网 scikit-video：SciPy 视频处理常用程序。官网 地理位置地理编码地址以及用来处理经纬度的库。 GeoDjango：世界级地理图形 web 框架。官网 GeoIP：MaxMind GeoIP Legacy 数据库的 Python API。官网 geojson：GeoJSON 的 Python 绑定及工具。官网 geopy：Python 地址编码工具箱。官网 pygeoip：纯 Python GeoIP API。官网 django-countries：一个 Django 应用程序，提供用于表格的国家选择功能，国旗图标静态文件以及模型中的国家字段。官网 HTTP使用 HTTP 的库。 aiohttp：基于 asyncio 的异步 HTTP 网络库。官网 requests：人性化的 HTTP 请求库。官网 grequests：requests 库 + gevent ，用于异步 HTTP 请求.官网 httplib2：全面的 HTTP 客户端库。官网 treq：类似 requests 的 Python API 构建于 Twisted HTTP 客户端之上。官网 urllib3：一个具有线程安全连接池，支持文件 post，清晰友好的 HTTP 库。官网 数据库Python 实现的数据库。 pickleDB：一个简单，轻量级键值储存数据库。官网 PipelineDB：流式 SQL 数据库。官网 TinyDB：一个微型的，面向文档型数据库。官网 ZODB：一个 Python 原生对象数据库。一个键值和对象图数据库。官网 数据库驱动用来连接和操作数据库的库。 MySQL：awesome-mysql 系列 aiomysql：基于 asyncio 的异步 MySQL 数据库操作库。官网 mysql-python：Python 的 MySQL 数据库连接器。官网 ysqlclient：mysql-python 分支，支持 Python 3。 oursql：一个更好的 MySQL 连接器，支持原生预编译指令和 BLOBs。官网 PyMySQL：纯 Python MySQL 驱动，兼容 mysql-python。官网 PostgreSQL psycopg2：Python 中最流行的 PostgreSQL 适配器。官网 queries：psycopg2 库的封装，用来和 PostgreSQL 进行交互。官网 txpostgres：基于 Twisted 的异步 PostgreSQL 驱动。官网 其他关系型数据库 apsw：另一个 Python SQLite 封装。官网 dataset：在数据库中存储 Python 字典 pymssql：一个简单的 Microsoft SQL Server 数据库接口。官网 NoSQL 数据库 asyncio-redis：基于 asyncio 的 redis 客户端 (PEP 3156)。官网 cassandra-python-driver：Cassandra 的 Python 驱动。官网 HappyBase：一个为 Apache HBase 设计的，对开发者友好的库。官网 Plyvel：一个快速且功能丰富的 LevelDB 的 Python 接口。官网 py2neo：Neo4j restful 接口的 Python 封装客户端。官网 pycassa：Cassandra 的 Python Thrift 驱动。官网 PyMongo：MongoDB 的官方 Python 客户端。官网 redis-py：Redis 的 Python 客户端。官网 telephus：基于 Twisted 的 Cassandra 客户端。官网 txRedis：基于 Twisted 的 Redis 客户端。官网 ORM实现对象关系映射或数据映射技术的库。 关系型数据库 Django Models：Django 的一部分。官网 SQLAlchemy：Python SQL 工具以及对象关系映射工具。官网 awesome-sqlalchemy 系列 Peewee：一个小巧，富有表达力的 ORM。官网 PonyORM：提供面向生成器的 SQL 接口的 ORM。官网 python-sql：编写 Python 风格的 SQL 查询。官网 NoSQL 数据库 django-mongodb-engine：Django MongoDB 后端。官网 PynamoDB：Amazon DynamoDB 的一个 Python 风格接口。官网 flywheel：Amazon DynamoDB 的对象映射工具。官网 MongoEngine：一个 Python 对象文档映射工具，用于 MongoDB。官网 hot-redis：为 Redis 提供 Python 丰富的数据类型。官网 redisco：一个 Python 库，提供可以持续存在在 Redis 中的简单模型和容器。官网 其他 butterdb：Google Drive 电子表格的 Python ORM。官网 Web 框架全栈 Web 框架。 Django：Python 界最流行的 web 框架。官网 awesome-django 系列 Flask：一个 Python 微型框架。官网 awesome-flask 系列 pyramid：一个小巧，快速，接地气的开源 Python web 框架。 awesome-pyramid 系列 Bottle：一个快速小巧，轻量级的 WSGI 微型 web 框架。官网 CherryPy：一个极简的 Python web 框架，服从 HTTP/1.1 协议且具有 WSGI 线程池。官网 TurboGears：一个可以扩展为全栈解决方案的微型框架。官网 web.py：一个 Python 的 web 框架，既简单，又强大。官网 web2py：一个全栈 web 框架和平台，专注于简单易用。官网 Tornado：一个 web 框架和异步网络库。官网 sanic：基于 Python3.5+ 的异步网络框架。官网 权限允许或拒绝用户访问数据或功能的库。 Carteblanche：站在用户和设计者角度开发的一个代码对齐模块，很好地处理了代码导航及权限。官网 django-guardian：Django 1.2+ 实现了单个对象权限。官网 django-rules：一个小巧但是强大的应用，提供对象级别的权限管理，且不需要使用数据库。官网 CMS内容管理系统 odoo-cms: 一个开源的，企业级 CMS，基于 odoo。官网 django-cms：一个开源的，企业级 CMS，基于 Django。官网 djedi-cms：一个轻量级但却非常强大的 Django CMS ，考虑到了插件，内联编辑以及性能。官网 FeinCMS：基于 Django 构建的最先进的内容管理系统之一。官网 Kotti：一个高级的，Python 范的 web 应用框架，基于 Pyramid 构建。官网 Mezzanine：一个强大的，持续的，灵活的内容管理平台。官网 Opps：一个为杂志，报纸网站以及大流量门户网站设计的 CMS 平台，基于 Django。官网 Plone：一个构建于开源应用服务器 Zope 之上的 CMS。官网 Quokka：灵活，可扩展的小型 CMS，基于 Flask 和 MongoDB。官网 Wagtail：一个 Django 内容管理系统。官网 Widgy：最新的 CMS 框架，基于 Django。官网 电子商务用于电子商务以及支付的框架和库。 django-oscar：一个用于 Django 的开源的电子商务框架。官网 django-shop：一个基于 Django 的店铺系统。官网 Cartridge：一个基于 Mezzanine 构建的购物车应用。官网 shoop：一个基于 Django 的开源电子商务平台。官网 alipay：非官方的 Python 支付宝 API。官网 merchant：一个可以接收来自多种支付平台支付的 Django 应用。官网 money：一个货币类库。带有可选的 CLDR 后端本地化格式，提供可扩展的货币兑换解决方案。官网 python-currencies：显示货币格式以及它的数值。官网 RESTful API用来开发 RESTful APIs 的库 Django django-rest-framework：一个强大灵活的工具，用来构建 web API。官网 django-tastypie：为 Django 应用开发 API。官网 django-formapi：为 Django 的表单验证，创建 JSON APIs 。官网 Flask flask-api：为 flask 开发的，可浏览 Web APIs 。官网 flask-restful：为 flask 快速创建 REST APIs 。官网 flask-restless：为 SQLAlchemy 定义的数据库模型创建 RESTful APIs 。官网 flask-api-utils：为 Flask 处理 API 表示和验证。官网 eve：REST API 框架，由 Flask, MongoDB 等驱动。官网 Pyramid cornice：一个 Pyramid 的 REST 框架 。官网 与框架无关的 falcon：一个用来建立云 API 和 web app 后端的高性能框架。官网 sandman：为现存的数据库驱动系统自动创建 REST APIs 。官网 restless：框架无关的 REST 框架 ，基于从 Tastypie 学到的知识。官网 ripozo：快速创建 REST/HATEOAS/Hypermedia APIs。官网 验证实现验证方案的库。 OAuth Authomatic：简单但是强大的框架，身份验证/授权客户端。官网 django-allauth：Django 的验证应用。官网 django-oauth-toolkit：为 Django 用户准备的 OAuth2。官网 django-oauth2-provider：为 Django 应用提供 OAuth2 接入。官网 Flask-OAuthlib：OAuth 1.0/a, 2.0 客户端实现，供 Flask 使用。官网 OAuthLib：一个 OAuth 请求-签名逻辑通用、 完整的实现。官网 python-oauth2：一个完全测试的抽象接口。用来创建 OAuth 客户端和服务端。官网 python-social-auth：一个设置简单的社会化验证方式。官网 rauth：OAuth 1.0/a, 2.0, 和 Ofly 的 Python 库。官网 sanction：一个超级简单的 OAuth2 客户端实现。官网 其他 jose：JavaScript 对象签名和加密草案的实现。官网 PyJWT：JSON Web 令牌草案 01。官网 python-jws：JSON Web 签名草案 02 的实现。官网 python-jwt：一个用来生成和验证 JSON Web 令牌的模块。官网 模板引擎模板生成和词法解析的库和工具。 Jinja2：一个现代的，对设计师友好的模板引擎。官网 Chameleon：一个 HTML/XML 模板引擎。 模仿了 ZPT（Zope Page Templates）, 进行了速度上的优化。官网 Genshi：Python 模板工具，用以生成 web 感知的结果。官网 Mako：Python 平台的超高速轻量级模板。官网 队列处理事件以及任务队列的库。 celery：一个异步任务队列/作业队列，基于分布式消息传递。官网 huey：小型多线程任务队列。官网 mrq：Mr. Queue -一个 Python 的分布式 worker 任务队列， 使用 Redis 和 gevent。官网 rq：简单的 Python 作业队列。官网 simpleq：一个简单的，可无限扩张的，基于亚马逊 SQS 的队列。官网 搜索对数据进行索引和执行搜索查询的库和软件。 django-haystack：Django 模块化搜索。官网 elasticsearch-py：Elasticsearch 的官方底层 Python 客户端。官网 elasticsearch-dsl-py：Elasticsearch 的官方高级 Python 客户端。官网 solrpy：solr 的 Python 客户端。官网 Whoosh：一个快速的纯 Python 搜索引擎库。官网 动态消息用来创建用户活动的库。 django-activity-stream：从你的站点行为中生成通用活动信息流。官网 Stream-Framework：使用 Cassandra 和 Redis 创建动态消息和通知系统。官网 资源管理管理、压缩、缩小网站资源的工具。 django-compressor：将链接和内联的 JavaScript 或 CSS 压缩到一个单独的缓存文件中。官网 django-storages：一个针对 Django 的自定义存储后端的工具集合。官网 fanstatic：打包、优化，并且把静态文件依赖作为 Python 的包来提供。官网 File Conveyor：一个后台驻留的程序，用来发现和同步文件到 CDNs, S3 和 FTP。官网 Flask-Assets：帮你将 web 资源整合到你的 Flask app 中。官网 jinja-assets-compressor：一个 Jinja 扩展，用来编译和压缩你的资源。官网 webassets：为你的静态资源打包、优化和管理生成独一无二的缓存 URL。官网 缓存缓存数据的库。 Beaker：一个缓存和会话库，可以用在 web 应用和独立 Python 脚本和应用上。官网 django-cache-machine：Django 模型的自动缓存和失效。官网 django-cacheops：具有自动颗粒化事件驱动失效功能的 ORM。官网 django-viewlet：渲染模板，同时具有额外的缓存控制功能。官网 dogpile.cache：dogpile.cache 是 Beaker 的下一代替代品，由同一作者开发。官网 HermesCache：Python 缓存库，具有基于标签的失效和 dogpile effect 保护功能。官网 johnny-cache：django 应用缓存框架。官网 pylibmc：libmemcached 接口的 Python 封装。官网 电子邮件用来发送和解析电子邮件的库。 django-celery-ses：带有 AWS SES 和 Celery 的 Django email 后端。官网 envelopes：供人类使用的电子邮件库。官网 flanker：一个 email 地址和 Mime 解析库。官网 imbox：Python IMAP 库。官网 inbox.py：Python SMTP 服务器。官网 inbox：一个开源电子邮件工具箱。官网 lamson：Python 风格的 SMTP 应用服务器。官网 mailjet：Mailjet API 实现，用来提供批量发送邮件，统计等功能。官网 marrow.mailer：高性能可扩展邮件分发框架。官网 modoboa：一个邮件托管和管理平台，具有现代的、简约的 Web UI。官网 pyzmail：创建，发送和解析电子邮件。官网 Talon：Mailgun 库，用来抽取信息和签名。官网 yagmail：yagmail是一个GMAIL / SMTP客户端，旨在使其尽可能简单地发送电子邮件。官网 国际化用来进行国际化的库。 Babel：一个 Python 的国际化库。官网 Korean：一个韩语词态库。官网 URL 处理解析 URLs 的库 furl：一个让处理 URL 更简单小型 Python 库。官网 purl：一个简单的，不可变的 URL 类，具有简洁的 API 来进行询问和处理。官网 pyshorteners：一个纯 Python URL 缩短库。官网 shorturl：生成短小 URL 和类似 bit.ly 短链的 Python 实现。官网 webargs：一个解析 HTTP 请求参数的库，内置对流行 web 框架的支持，包括 Flask, Django, Bottle, Tornado 和 Pyramid。官网 HTML 处理处理 HTML 和 XML 的库。 BeautifulSoup：以 Python 风格的方式来对 HTML 或 XML 进行迭代，搜索和修改。官网 bleach：一个基于白名单的 HTML 清理和文本链接库。官网 cssutils：一个 Python 的 CSS 库。官网 html5lib：一个兼容标准的 HTML 文档和片段解析及序列化库。官网 lxml：一个非常快速，简单易用，功能齐全的库，用来处理 HTML 和 XML。官网 MarkupSafe：为 Python 实现 XML/HTML/XHTML 标记安全字符串。官网 pyquery：一个解析 HTML 的库，类似 jQuery。官网 requests-html：人性化的，Pythonic 的 HTML 解析库。官网 untangle：将 XML 文档转换为 Python 对象，使其可以方便的访问。官网 xhtml2pdf：HTML/CSS 转 PDF 工具。官网 xmltodict：像处理 JSON 一样处理 XML。官网 爬取网络站点的库 Scrapy：一个快速高级的屏幕爬取及网页采集框架。官网 cola：一个分布式爬虫框架。官网 Demiurge：基于 PyQuery 的爬虫微型框架。官网 feedparser：通用 feed 解析器。官网 Grab：站点爬取框架。官网 MechanicalSoup：用于自动和网络站点交互的 Python 库。官网 portia：Scrapy 可视化爬取。官网 pyspider：一个强大的爬虫系统。官网 RoboBrowser：一个简单的，Python 风格的库，用来浏览网站，而不需要一个独立安装的浏览器。官网 网页内容提取用于进行网页内容提取的库。 Haul：一个可以扩展的图像爬取工具。官网 html2text：将 HTML 转换为 Markdown 格式文本。官网 lassie：人性化的网页内容检索库。官网 micawber：一个小型网页内容提取库，用来从 URLs 提取富内容。官网 newspaper：使用 Python 进行新闻提取，文章提取以及内容策展。官网 opengraph：一个用来解析开放内容协议(Open Graph Protocol)的 Python 模块。官网 python-goose：HTML 内容/文章提取器。官网 python-readability：arc90 公司 readability 工具的 Python 高速端口。官网 sanitize：为杂乱的数据世界带来调理性。官网 sumy：一个为文本文件和 HTML 页面进行自动摘要的模块。官网 textract：从任何格式的文档中提取文本，Word，PowerPoint，PDFs 等等。官网 表单进行表单操作的库。 Deform：Python HTML 表单生成库，受到了 formish 表单生成库的启发。官网 django-bootstrap3：集成了 Bootstrap 3 的 Django。官网 django-crispy-forms：一个 Django 应用，他可以让你以一种非常优雅且 DRY（Don’t repeat yourself） 的方式来创建美观的表单。官网 django-remote-forms：一个平台独立的 Django 表单序列化工具。官网 WTForms：一个灵活的表单验证和呈现库。官网 WTForms-JSON：一个 WTForms 扩展，用来处理 JSON 数据。官网 数据验证数据验证库。多用于表单验证。 Cerberus：一个映射验证器（mappings-validator）。支持多种规则，提供归一化功能，可以方便地定制为 Python 风格的 schema 定义。官网 colander：一个用于对从 XML, JSON，HTML 表单获取的数据或其他同样简单的序列化数据进行验证和反序列化的系统。官网 kmatch：一种用于匹配/验证/筛选 Python 字典的语言。官网 schema：一个用于对 Python 数据结构进行验证的库。官网 Schematics：数据结构验证。官网 valideer：轻量级可扩展的数据验证和适配库。官网 voluptuous：一个 Python 数据验证库。主要是为了验证传入 Python 的 JSON，YAML 等数据。官网 jsonschema：JSON Schema的 python 实现，用于 JSON 数据的验证。官网 反垃圾技术帮助你和电子垃圾进行战斗的库。 django-simple-captcha：一个简单、高度可定制的 Django 应用，可以为任何 Django 表单添加验证码。官网 django-simple-spam-blocker：一个用于 Django 的简单的电子垃圾屏蔽工具。官网 标记用来进行标记的库。 django-taggit：简单的 Django 标记工具。官网 管理面板管理界面库。 Ajenti：一个你的服务器值得拥有的管理面板。官网 django-suit：Django 管理界面的一个替代品 (仅对于非商业用途是免费的)。官网 django-xadmin：Django admin 的一个替代品，具有很多不错的功能。官网 flask-admin：一个用于 Flask 的简单可扩展的管理界面框架。官网 flower：一个对 Celery 集群进行实时监控和提供 web 管理界面的工具。官网 Grappelli：Django 管理界面的一个漂亮的皮肤。官网 Wooey：一个 Django 应用，可以为 Python 脚本创建 web 用户界面。官网 静态站点生成器静态站点生成器是一个软件，它把文本和模板作为输入，然后输出 HTML 文件。 Pelican：使用 Markdown 或 ReST 来处理内容， Jinja 2 来制作主题。支持 DVCS, Disqus.。AGPL 许可。官网 Cactus：为设计师设计的静态站点生成器。官网 Hyde：基于 Jinja2 的静态站点生成器。官网 Nikola：一个静态网站和博客生成器。官网 Tinkerer：Tinkerer 是一个博客引擎/静态站点生成器，由 Sphinx 驱动。官网 Lektor：一个简单易用的静态 CMS 和博客引擎。官网 进程操作系统进程启动及通信库。 envoy：比 Python subprocess 模块更人性化。官网 sarge：另一 种 subprocess 模块的封装。官网 sh：一个完备的 subprocess 替代库。官网 并发和并行用以进行并发和并行操作的库。 multiprocessing：(Python 标准库) 基于进程的“线程”接口。官网 threading：(Python 标准库)更高层的线程接口。官网 eventlet：支持 WSGI 的异步框架。官网 gevent：一个基于协程的 Python 网络库，使用 greenlet。官网 Tomorrow：用于产生异步代码的神奇的装饰器语法实现。官网 uvloop：在 libuv 之上超快速实现 asyncio 事件循环。官网 网络用于网络编程的库。 asyncio：(Python 标准库) 异步 I/O, 事件循环, 协程以及任务。官网 Twisted：一个事件驱动的网络引擎。官网 pulsar：事件驱动的并发框架。官网 diesel：基于 Greenlet 的事件 I/O 框架。官网 pyzmq：一个 ZeroMQ 消息库的 Python 封装。官网 Toapi：一个轻巧，简单，快速的 Flask 库，致力于为所有网站提供 API 服务。官网 txZMQ：基于 Twisted 的 ZeroMQ 消息库的 Python 封装。官网 WebSocket帮助使用 WebSocket 的库。 AutobahnPython：给 Python 、使用的 WebSocket &amp; WAMP 基于 Twisted 和 asyncio。官网 Crossbar：开源统一应用路由(Websocket &amp; WAMP for Python on Autobahn)。官网 django-socketio：给 Django 用的 WebSockets。官网 WebSocket-for-Python：为 Python2/3 以及 PyPy 编写的 WebSocket 客户端和服务器库。官网 WSGI 服务器兼容 WSGI 的 web 服务器 gunicorn：Pre-forked, 部分是由 C 语言编写的。官网 uwsgi：uwsgi 项目的目的是开发一组全栈工具，用来建立托管服务， 由 C 语言编写。官网 bjoern：异步，非常快速，由 C 语言编写。官网 fapws3：异步 (仅对于网络端)，由 C 语言编写。官网 meinheld：异步，部分是由 C 语言编写的。官网 netius：异步，非常快速。官网 paste：多线程，稳定，久经考验。官网 rocket：多线程。官网 waitress：多线程, 是它驱动着 Pyramid 框架。官网 Werkzeug：一个 WSGI 工具库，驱动着 Flask ，而且可以很方便大嵌入到你的项目中去。官网 RPC 服务器兼容 RPC 的服务器。 SimpleJSONRPCServer：这个库是 JSON-RPC 规范的一个实现。官网 SimpleXMLRPCServer：(Python 标准库) 简单的 XML-RPC 服务器实现，单线程。官网 zeroRPC：zerorpc 是一个灵活的 RPC 实现，基于 ZeroMQ 和 MessagePack。官网 密码学 cryptography：这个软件包意在提供密码学基本内容和方法提供给 Python 开发者。官网 hashids：在 Python 中实现 hashids 。官网 Paramiko：SSHv2 协议的 Python (2.6+, 3.3+) ，提供客户端和服务端的功能。官网 Passlib：安全密码存储／哈希库，官网 PyCrypto：Python 密码学工具箱。官网 PyNacl：网络和密码学(NaCl) 库的 Python 绑定。官网 图形用户界面用来创建图形用户界面程序的库。 curses：内建的 ncurses 封装，用来创建终端图形用户界面。官网 enaml：使用类似 QML 的 Declaratic 语法来创建美观的用户界面。官网 kivy：一个用来创建自然用户交互（NUI）应用程序的库，可以运行在 Windows, Linux, Mac OS X, Android 以及 iOS 平台上。官网 pyglet：一个 Python 的跨平台窗口及多媒体库。官网 PyQt：跨平台用户界面框架 Qt 的 Python 绑定 ，支持 Qt v4 和 Qt v5。官网 PySide：跨平台用户界面框架 Qt 的 Python 绑定 ，支持 Qt v4。官网 Tkinter：Tkinter 是 Python GUI 的一个事实标准库。官网 Toga：一个 Python 原生的, 操作系统原生的 GUI 工具包。官网 urwid：一个用来创建终端 GUI 应用的库，支持组件，事件和丰富的色彩等。官网 wxPython：wxPython 是 wxWidgets C++ 类库和 Python 语言混合的产物。官网 PyGObject：GLib/GObject/GIO/GTK+ (GTK+3) 的 Python 绑定。官网 Flexx：Flexx 是一个纯 Python 语言编写的用来创建 GUI 程序的工具集，它使用 web 技术进行界面的展示。官网 游戏开发超赞的游戏开发库。 Cocos2d：cocos2d 是一个用来开发 2D 游戏， 示例和其他图形/交互应用的框架。基于 pyglet。官网 Panda3D：由迪士尼开发的 3D 游戏引擎，并由卡内基梅陇娱乐技术中心负责维护。使用 C++ 编写, 针对 Python 进行了完全的封装。官网 Pygame：Pygame 是一组 Python 模块，用来编写游戏。官网 PyOgre：Ogre 3D 渲染引擎的 Python 绑定，可以用来开发游戏和仿真程序等任何 3D 应用。官网 PyOpenGL：OpenGL 的 Python 绑定及其相关 APIs。官网 PySDL2：SDL2 库的封装，基于 ctypes。官网 RenPy：一个视觉小说（visual novel）引擎。官网 日志用来生成和操作日志的库。 logging：(Python 标准库) 为 Python 提供日志功能。官网 logbook：Logging 库的替代品。官网 Eliot：为复杂的和分布式系统创建日志。官网 Raven：Sentry 的 Python 客户端。官网 Sentry：实时记录和收集日志的服务器。官网 测试进行代码库测试和生成测试数据的库。 测试框架 unittest：(Python 标准库) 单元测试框架。官网 nose：nose 扩展了 unittest 的功能。官网 contexts：一个 Python 3.3+ 的 BDD 框架。受到 C# – Machine.Specifications 的启发。官网 hypothesis：Hypothesis 是一个基于先进的 Quickcheck 风格特性的测试库。官网 mamba：Python 的终极测试工具， 拥护 BDD。官网 PyAutoGUI：PyAutoGUI 是一个人性化的跨平台 GUI 自动测试模块。官网 pyshould：Should 风格的断言，基于 PyHamcrest。官网 pytest：一个成熟的全功能 Python 测试工具。官网 green：干净，多彩的测试工具。官网 pyvows：BDD 风格的测试工具，受 Vows.js 的启发。官网 Robot Framework：一个通用的自动化测试框架。官网 Web 测试 Selenium：Selenium WebDriver 的 Python 绑定。官网 locust：使用 Python 编写的，可扩展的用户加载测试工具。官网 sixpack：一个和语言无关的 A/B 测试框架。官网 splinter：开源的 web 应用测试工具。官网 Mock 测试 mock：(Python 标准库) 一个用于伪造测试的库。官网 doublex：Python 的一个功能强大的 doubles 测试框架。官网 freezegun：通过伪造日期模块来生成不同的时间。官网 httmock：针对 Python 2.6+ 和 3.2+ 生成 伪造请求的库。官网 httpretty：Python 的 HTTP 请求 mock 工具。官网 responses：伪造 Python 中的 requests 库的一个通用库。官网 VCR.py：在你的测试中记录和重放 HTTP 交互。官网 对象工厂 factoryboy：一个 Python 用的测试固件 (test fixtures) 替代库。官网 mixer：另外一个测试固件 (test fixtures) 替代库，支持 Django, Flask, SQLAlchemy, Peewee 等。官网 modelmommy：为 Django 测试创建随机固件。官网 代码覆盖率 coverage：代码覆盖率测量。官网 Codecov：一个代码覆盖率测试工具，为开源项目提供免费代码覆盖率测试服务。官网 伪数据 faker：一个 Python 库，用来生成伪数据。官网 fake2db：伪数据库生成器。官网 radar：生成随机的日期/时间。官网 错误处理 FuckIt.py：FuckIt.py 使用最先进的技术来保证你的 Python 代码无论对错都能继续运行。官网 代码分析和 Lint 工具进行代码分析，解析和操作代码库的库和工具。 代码分析 coala：语言独立和易于扩展的代码分析应用程序。官网 code2flow：把你的 Python 和 JavaScript 代码转换为流程图。官网 pycallgraph：这个库可以把你的 Python 应用的流程(调用图)进行可视化。官网 pysonar2：Python 类型推断和检索工具。官网 Lint 工具 Flake8：模块化源码检查工具: pep8, pyflakes 以及 co。官网 Pylint：一个完全可定制的源码分析器。官网 YAPF: Google 的 Python 代码格式化工具。官网 pylama：Python 和 JavaScript 的代码审查工具。官网 代码格式化 autopep8：自动格式化 Python 代码，以使其符合 PEP8 规范。官网 black：一个坚定的 Python 代码格式化工具。官网 调试工具用来进行代码调试的库。 调试器 ipdb：IPython 启用的 pdb。官网 pudb：全屏，基于控制台的 Python 调试器。官网 pyringe：可以在 Python 进程中附加和注入代码的调试器。官网 wdb：一个奇异的 web 调试器，通过 WebSockets 工作。官网 winpdb：一个具有图形用户界面的 Python 调试器，可以进行远程调试，基于 rpdb2。官网 django-debug-toolbar：为 Django 显示各种调试信息。官网 django-devserver：一个 Django 运行服务器的替代品。官网 flask-debugtoolbar：django-debug-toolbar 的 flask 版。官网 性能分析器 lineprofiler：逐行性能分析。官网 Memory Profiler：监控 Python 代码的内存使用。官网、内存 profiling：一个交互式 Python 性能分析工具。官网 其他 pyelftools：解析和分析 ELF 文件以及 DWARF 调试信息。官网 python-statsd：statsd 服务器的 Python 客户端。官网 科学计算和数据分析用来进行科学计算和数据分析的库。 astropy：一个天文学 Python 库。官网 bcbio-nextgen：这个工具箱为全自动高通量测序分析提供符合最佳实践的处理流程。官网 bccb：生物分析相关代码集合。官网 Biopython：Biopython 是一组可以免费使用的用来进行生物计算的工具。官网 blaze：NumPy 和 Pandas 的大数据接口。官网 cclib：一个用来解析和解释计算化学软件包输出结果的库。官网 NetworkX：一个为复杂网络设计的高性能软件。官网 Neupy：执行和测试各种不同的人工神经网络算法。官网 Numba：Python JIT (just in time) 编译器，针对科学用的 Python ，由 Cython 和 NumPy 的开发者开发。官网 NumPy：使用 Python 进行科学计算的基础包。官网 Open Babel：一个化学工具箱，用来描述多种化学数据。官网 Open Mining：使用 Python 挖掘商业情报 (BI) (Pandas web 接口)。官网 orange：通过可视化编程或 Python 脚本进行数据挖掘，数据可视化，分析和机器学习。官网 Pandas：提供高性能，易用的数据结构和数据分析工具。官网 PyDy：PyDy 是 Python Dynamics 的缩写，用来为动力学运动建模工作流程提供帮助， 基于 NumPy, SciPy, IPython 和 matplotlib。官网 PyMC：马尔科夫链蒙特卡洛采样工具。官网 RDKit：化学信息学和机器学习软件。官网 SciPy：由一些基于 Python ，用于数学，科学和工程的开源软件构成的生态系统。官网 statsmodels：统计建模和计量经济学。官网 SymPy：一个用于符号数学的 Python 库。官网 zipline：一个 Python 算法交易库。官网 Bayesian-belief-networks：优雅的贝叶斯信念网络框架。官网 数据可视化进行数据可视化的库。 参见: awesome-javascript。 matplotlib：一个 Python 2D 绘图库。官网 bokeh：用 Python 进行交互式 web 绘图。官网 ggplot：ggplot2 给 R 提供的 API 的 Python 版本。官网 plotly：协同 Python 和 matplotlib 工作的 web 绘图库。官网 pyecharts：基于百度 Echarts 的数据可视化库。官网 pygal：一个 Python SVG 图表创建工具。官网 pygraphviz：Graphviz 的 Python 接口。官网 PyQtGraph：交互式实时 2D/3D/ 图像绘制及科学/工程学组件。官网 SnakeViz：一个基于浏览器的 Python’s cProfile 模块输出结果查看工具。官网 vincent：把 Python 转换为 Vega 语法的转换工具。官网 VisPy：基于 OpenGL 的高性能科学可视化工具。官网 计算机视觉计算机视觉库。 OpenCV：开源计算机视觉库。官网 pyocr：Tesseract 和 Cuneiform 的包装库。官网 pytesseract：Google Tesseract OCR 的另一包装库。官网 SimpleCV：一个用来创建计算机视觉应用的开源框架。官网 机器学习机器学习库。 参见: awesome-machine-learning. Caffe: 一个 Caffe 的 python 接口。官网 Caffe2：一个轻量级的，模块化的，可扩展的深度学习框架。官网 Crab：灵活、快速的推荐引擎。官网 gensim：人性化的话题建模库。官网 hebel：GPU 加速的深度学习库。官网 keras: 以 tensorflow/theano/CNTK 为后端的深度学习封装库，快速上手神经网络。官网 MXNet：一个高效和灵活的深度学习框架。官网 NuPIC：智能计算 Numenta 平台。官网 pattern：Python 网络挖掘模块。官网 PyBrain：另一个 Python 机器学习库。官网 pydeep：Python 深度学习库。官网 Pylearn2：一个基于 Theano 的机器学习库。官网 python-recsys：一个用来实现推荐系统的 Python 库。官网 Pytorch：一个具有张量和动态神经网络，并有强大 GPU 加速能力的深度学习框架。官网 scikit-learn：基于 SciPy 构建的机器学习 Python 模块。官网 skflow：一个 TensorFlow 的简化接口(模仿 scikit-learn)。官网 TensorFlow：谷歌开源的最受欢迎的深度学习框架。官网 Theano：一个快速数值计算库。官网 vowpalporpoise：轻量级 Vowpal Wabbit 的 Python 封装。官网 MapReduceMapReduce 框架和库。 dpark：Spark 的 Python 克隆版，一个类似 MapReduce 的框架。官网 dumbo：这个 Python 模块可以让人轻松的编写和运行 Hadoop 程序。官网 luigi：这个模块帮你构建批处理作业的复杂流水线。官网 mrjob：在 Hadoop 或 Amazon Web Services 上运行 MapReduce 任务。官网 PySpark：Spark 的 Python API 。官网 streamparse：运行针对事实数据流的 Python 代码。集成了 Apache Storm。官网 函数式编程使用 Python 进行函数式编程。 CyToolz：Toolz 的 Cython 实现 : 高性能函数式工具。官网 fn.py：在 Python 中进行函数式编程 : 实现了一些享受函数式编程缺失的功能。官网 funcy：炫酷又实用的函数式工具。官网 Toolz：一组用于迭代器，函数和字典的函数式编程工具。官网 第三方 API用来访问第三方 API 的库。 参见： List of Python API Wrappers and Libraries。 apache-libcloud：一个为各种云设计的 Python 库。官网 boto：Amazon Web Services 的 Python 接口。官网 django-wordpress：WordPress models and views for Django.官网 facebook-sdk：Facebook 平台的 Python SDK.官网 facepy：Facepy 让和 Facebook’s Graph API 的交互变得更容易。官网 gmail：Gmail 的 Python 接口。官网 google-api-python-client：Python 用的 Google APIs 客户端库。官网 gspread：Google 电子表格的 Python API.官网 twython：Twitter API 的封装。官网 DevOps 工具用于 DevOps 的软件和库。 Ansible：一个非常简单的 IT 自动化平台。官网 SaltStack：基础设施自动化和管理系统。官网 OpenStack：用于构建私有和公有云的开源软件。官网 Docker Compose：快速，分离的开发环境，使用 Docker。官网 Fabric：一个简单的，Python 风格的工具，用来进行远程执行和部署。官网 cuisine：为 Fabric 提供一系列高级函数。官网 Fabtools：一个用来编写超赞的 Fabric 文件的工具。官网 gitapi：Git 的纯 Python API。官网 hgapi：Mercurial 的纯 Python API。官网 honcho：Foreman 的 Python 克隆版，用来管理基于 Procfile 的应用。官网 pexpect：Controlling interactive programs in a pseudo-terminal like 在一个伪终端中控制交互程序，就像 GNU expect 一样。官网 psutil：一个跨平台进程和系统工具模块。官网 supervisor：UNIX 的进程控制系统。官网 任务调度任务调度库。 APScheduler：轻巧但强大的进程内任务调度，使你可以调度函数。官网 django-schedule：一个 Django 排程应用。官网 doit：一个任务执行和构建工具。官网 gunnery：分布式系统使用的多用途任务执行工具 ，具有 web 交互界面。官网 Joblib：一组为 Python 提供轻量级作业流水线的工具。官网 Plan：如有神助地编写 crontab 文件。官网 schedule：人性化的 Python 任务调度库。官网 Spiff：使用纯 Python 实现的强大的工作流引擎。官网 TaskFlow：一个可以让你方便执行任务的 Python 库，一致并且可靠。官网 AirFlow：Airflow 是Airbnb公司开源的，是一个工作流分配管理系统，通过有向非循环图的方式管理任务流程，设置任务依赖关系和时间调度。官方 外来函数接口使用外来函数接口的库。 cffi：用来调用 C 代码的外来函数接口。官网 ctypes：(Python 标准库) 用来调用 C 代码的外来函数接口。官网 PyCUDA：Nvidia CUDA API 的封装。官网 SWIG：简化的封装和接口生成器。官网 高性能让 Python 更快的库。 Cython：优化的 Python 静态编译器。使用类型混合使 Python 编译成 C 或 C++ 模块来获得性能的极大提升。官网 PeachPy：嵌入 Python 的 x86-64 汇编器。可以被用作 Python 内联的汇编器或者是独立的汇编器，用于 Windows, Linux, OS X, Native Client 或者 Go 。官网 PyPy：使用 Python 实现的 Python。解释器使用黑魔法加快 Python 运行速度且不需要加入额外的类型信息。官网 Pyston：使用 LLVM 和现代 JIT 技术构建的 Python 实现，目标是为了获得很好的性能。官网 Stackless Python：一个强化版的 Python。官网 微软的 Windows 平台在 Windows 平台上进行 Python 编程。 Python(x,y)：面向科学应用的 Python 发行版，基于 Qt 和 Spyder。官网 pythonlibs：非官方的 Windows 平台 Python 扩展二进制包。官网 PythonNet：Python 与 .NET 公共语言运行库 (CLR)的集成。官网 PyWin32：针对 Windows 的 Python 扩展。官网 WinPython：Windows 7/8 系统下便携式开发环境。官网 网络可视化和 SDN用来进行网络可视化和 SDN(软件定义网络)的工具和库。 Mininet：一款流行的网络模拟器以及用 Python 编写的 API。官网 POX：一个针对基于 Python 的软件定义网络应用（例如 OpenFlow SDN 控制器）的开源开发平台。官网 Pyretic：火热的 SDN 编程语言中的一员，为网络交换机和模拟器提供强大的抽象能力。官网 SDX Platform：基于 SDN 的 IXP 实现，影响了 Mininet, POX 和 Pyretic。官网 NRU：一个基于组件的软件定义网络框架。官网 硬件用来对硬件进行编程的库。 ino：操作 Arduino 的命令行工具。官网 Pyro：Python 机器人编程库。官网 PyUserInput：跨平台的，控制鼠标和键盘的模块。官网 scapy：一个非常棒的操作数据包的库。官网 wifi：一个 Python 库和命令行工具用来在 Linux 平台上操作 WiFi。官网 Pingo：Pingo 为类似 Raspberry Pi，pcDuino， Intel Galileo 等设备提供统一的 API 用以编程。官网 兼容性帮助从 Python 2 向 Python 3 迁移的库。 Python-Future：这就是 Python 2 和 Python 3 之间丢失的那个兼容性层。官网 Python-Modernize：使 Python 代码更加现代化以便最终迁移到 Python 3。官网 Six：Python 2 和 3 的兼容性工具。官网 杂项不属于上面任何一个类别，但是非常有用的库。 blinker：一个快速的 Python 进程内信号/事件分发系统。官网 itsdangerous：一系列辅助工具用来将可信的数据传入不可信的环境。官网 pluginbase：一个简单但是非常灵活的 Python 插件系统。官网 Pychievements：一个用来创建和追踪成就的 Python 框架。官网 Tryton：一个通用商务框架。官网 算法和设计模式Python 实现的算法和设计模式。 algorithms：一个 Python 算法模块。官网 python-patterns：Python 设计模式的集合。官网 sortedcontainers：快速，纯 Python 实现的 SortedList，SortedDict 和 SortedSet 类型。官网 编辑器插件编辑器和 IDE 的插件 Emacs Elpy：Emacs Python 开发环境。官网 Sublime Text SublimeJEDI：一个 Sublime Text 插件，用来使用超赞的自动补全库 Jedi。官网 Anaconda：Anaconda 把你的 Sublime Text 3 变成一个功能齐全的 Python IDE。官网 Vim YouCompleteMe：引入基于 Jedi 的 Python 自动补全引擎。官网 Jedi-vim：绑定 Vim 和 Jedi 自动补全库对 Python 进行自动补全。官网 Python-mode：将 Vim 变成 Python IDE 的一款多合一插件。官网 Visual Studio PTVS：Visual Studio 的 Python 工具。官网 集成开发环境流行的 Python 集成开发环境。 PyCharm：商业化的 Python IDE ，由 JetBrains 开发。也有免费的社区版提供。官网 LiClipse：基于 Eclipse 的免费多语言 IDE 。使用 PyDev 来支持 Python 。官网 Spyder：开源 Python IDE。官网 自动聊天工具用于开发聊天机器人的库 Errbot：最简单和最流行的聊天机器人用来实现自动聊天工具。官网 服务在线工具和简化开发的 API 。 金融数据 Tushare ：一个可以提供免费股票、基金、期货、港股等金融数据的 Python 开源数据。官网 Ta-Lib ：金融数据技术分析库，可以依据原始金融数据计算各种技术指标,计算性能比较优异。官网 持续集成参见: awesome-CIandCD. Travis CI：一个流行的工具，为你的开源和 私人 项目提供持续集成服务。(仅支持 GitHub)官网 CircleCI：一个持续集成工具，可以非常快速的进行并行测试。 (仅支持 GitHub)官网 Vexor CI：一个为私人 app 提供持续集成的工具，支持按分钟付费。官网 Wercker：基于 Docker 平台，用来构建和部署微服务。官网 代码质量 Codacy：自动化代码审查，更加快速的发布高质量代码。对于开源项目是免费的。官网 QuantifiedCode：一个数据驱动、自动、持续的代码审查工具。官网 资源在这里可以找到新的 Python 库。 网站 r/Python CoolGithubProjects Django Packages Full Stack Python Python 3 Wall of Superpowers Python Hackers Python ZEEF Trending Python repositories on GitHub today PyPI Ranking 周刊 Import Python Newsletter Pycoder’s Weekly Python Weekly Twitter @codetengu @getpy @planetpython @pycoders @pypi @pythontrending @PythonWeekly 学习指南 Scipy-lecture-notes：如何用 Python 来做学术？官网 SScientific-python-lectures：Python 科学计算的资料。官网 Mario-Level-1：用 Python 和 Pygame 写的超级马里奥第一关。官网 Python Koans：Python 的交互式学习工具。官网 Minecraft：用 python 写的 Minecraft 游戏。官网 pycrumbs：Python 资源大全。官网 python-patterns：使用 python 实现设计模式。官网 Projects：Python 项目大集合。官网 The Hitchhiker’s Guide to Python：旅行者的 Python 学习指南。官网 Code Like a Pythonista: Idiomatic Python：如何像 Python 高手(Pythonista)一样编程。官网]]></content>
      <categories>
        <category>资源</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python3.x标准模块库目录]]></title>
    <url>%2F2018%2F11%2F23%2FPython3-x%E6%A0%87%E5%87%86%E6%A8%A1%E5%9D%97%E5%BA%93%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[Python3.x标准模块库目录 文本1. string：通用字符串操作 2. re：正则表达式操作 3. difflib：差异计算工具 4. textwrap：文本填充 5. unicodedata：Unicode字符数据库 6. stringprep：互联网字符串准备工具 7. readline：GNU按行读取接口 8. rlcompleter：GNU按行读取的实现函数 二进制数据9. struct：将字节解析为打包的二进制数据 10. codecs：注册表与基类的编解码器 数据类型11. datetime：基于日期与时间工具 12. calendar：通用月份函数 13. collections：容器数据类型 14. collections.abc：容器虚基类 15. heapq：堆队列算法 16. bisect：数组二分算法 17. array：高效数值数组 18. weakref：弱引用 19. types：内置类型的动态创建与命名 20. copy：浅拷贝与深拷贝 21. pprint：格式化输出 22. reprlib：交替repr()的实现 数学23. numbers：数值的虚基类 24. math：数学函数 25. cmath：复数的数学函数 26. decimal：定点数与浮点数计算 27. fractions：有理数 28. random：生成伪随机数 函数式编程29. itertools：为高效循环生成迭代器 30. functools：可调用对象上的高阶函数与操作 31. operator：针对函数的标准操作 文件与目录32. os.path：通用路径名控制 33. fileinput：从多输入流中遍历行 34. stat：解释stat()的结果 35. filecmp：文件与目录的比较函数 36. tempfile：生成临时文件与目录 37. glob：Unix风格路径名格式的扩展 38. fnmatch：Unix风格路径名格式的比对 39. linecache：文本行的随机存储 40. shutil：高级文件操作 41. macpath：Mac OS 9路径控制函数 持久化42. pickle：Python对象序列化 43. copyreg：注册机对pickle的支持函数 44. shelve：Python对象持久化 45. marshal：内部Python对象序列化 46. dbm：Unix“数据库”接口 47. sqlite3：针对SQLite数据库的API 2.0 压缩48. zlib：兼容gzip的压缩 49. gzip：对gzip文件的支持 50. bz2：对bzip2压缩的支持 51. lzma：使用LZMA算法的压缩 52. zipfile：操作ZIP存档 53. tarfile：读写tar存档文件 # 文件格式化 54. csv：读写CSV文件 55. configparser：配置文件解析器 56. netrc：netrc文件处理器 57. xdrlib：XDR数据编码与解码 58. plistlib：生成和解析Mac OS X .plist文件 加密59. hashlib：安全散列与消息摘要 60. hmac：针对消息认证的键散列 操作系统工具61. os：多方面的操作系统接口 62. io：流核心工具 63. time：时间的查询与转化 64. argparser：命令行选项、参数和子命令的解析器 65. optparser：命令行选项解析器 66. getopt：C风格的命令行选项解析器 67. logging：Python日志工具 68. logging.config：日志配置 69. logging.handlers：日志处理器 70. getpass：简易密码输入 71. curses：字符显示的终端处理 72. curses.textpad：curses程序的文本输入域 73. curses.ascii：ASCII字符集工具 74. curses.panel：curses的控件栈扩展 75. platform：访问底层平台认证数据 76. errno：标准错误记号 77. ctypes：Python外部函数库 并发78. threading：基于线程的并行 79. multiprocessing：基于进程的并行 80. concurrent：并发包 81. concurrent.futures：启动并行任务 82. subprocess：子进程管理 83. sched：事件调度 84. queue：同步队列 85. select：等待I/O完成 86. dummy_threading：threading模块的替代（当_thread不可用时） 87. _thread：底层的线程API（threading基于其上） 88. _dummy_thread：_thread模块的替代（当_thread不可用时） 进程间通信89. socket：底层网络接口 90. ssl：socket对象的TLS/SSL填充器 91. asyncore：异步套接字处理器 92. asynchat：异步套接字命令/响应处理器 93. signal：异步事务信号处理器 94. mmap：内存映射文件支持 互联网95. email：邮件与MIME处理包 96. json：JSON编码与解码 97. mailcap：mailcap文件处理 98. mailbox：多种格式控制邮箱 99. mimetypes：文件名与MIME类型映射 100. base64：RFC 3548：Base16、Base32、Base64编码 101. binhex：binhex4文件编码与解码 102. binascii：二进制码与ASCII码间的转化 103. quopri：MIME quoted-printable数据的编码与解码 104. uu：uuencode文件的编码与解码 # HTML与XML 105. html：HTML支持 106. html.parser：简单HTML与XHTML解析器 107. html.entities：HTML通用实体的定义 108. xml：XML处理模块 109. xml.etree.ElementTree：树形XML元素API 110. xml.dom：XML DOM API 111. xml.dom.minidom：XML DOM最小生成树 112. xml.dom.pulldom：构建部分DOM树的支持 113. xml.sax：SAX2解析的支持 114. xml.sax.handler：SAX处理器基类 115. xml.sax.saxutils：SAX工具 116. xml.sax.xmlreader：SAX解析器接口 117. xml.parsers.expat：运用Expat快速解析XML 互联网协议与支持118. webbrowser：简易Web浏览器控制器 119. cgi：CGI支持 120. cgitb：CGI脚本反向追踪管理器 121. wsgiref：WSGI工具与引用实现 122. urllib：URL处理模块 123. urllib.request：打开URL连接的扩展库 124. urllib.response：urllib模块的响应类 125. urllib.parse：将URL解析成组件 126. urllib.error：urllib.request引发的异常类 127. urllib.robotparser：robots.txt的解析器 128. http：HTTP模块 129. http.client：HTTP协议客户端 130. ftplib：FTP协议客户端 131. poplib：POP协议客户端 132. imaplib：IMAP4协议客户端 133. nntplib：NNTP协议客户端 134. smtplib：SMTP协议客户端 135. smtpd：SMTP服务器 136. telnetlib：Telnet客户端 137. uuid：RFC4122的UUID对象 138. socketserver：网络服务器框架 139. http.server：HTTP服务器 140. http.cookies：HTTPCookie状态管理器 141. http.cookiejar：HTTP客户端的Cookie处理 142. xmlrpc：XML-RPC服务器和客户端模块 143. xmlrpc.client：XML-RPC客户端访问 144. xmlrpc.server：XML-RPC服务器基础 145. ipaddress：IPv4/IPv6控制库 多媒体146. audioop：处理原始音频数据 147. aifc：读写AIFF和AIFC文件 148. sunau：读写Sun AU文件 149. wave：读写WAV文件 150. chunk：读取IFF大文件 151. colorsys：颜色系统间转化 152. imghdr：指定图像类型 153. sndhdr：指定声音文件类型 154. ossaudiodev：访问兼容OSS的音频设备 国际化155. gettext：多语言的国际化服务 156. locale：国际化服务 编程框架157. turtle：Turtle图形库 158. cmd：基于行的命令解释器支持 159. shlex：简单词典分析 Tk图形用户接口160. tkinter：Tcl/Tk接口 161. tkinter.ttk：Tk主题控件 162. tkinter.tix：Tk扩展控件 163. tkinter.scrolledtext：滚轴文本控件 开发工具164. pydoc：文档生成器和在线帮助系统 165. doctest：交互式Python示例 166. unittest：单元测试框架 167. unittest.mock：模拟对象库 168. test：Python回归测试包 169. test.support：Python测试工具套件 170. venv：虚拟环境搭建 调试171. bdb：调试框架 172. faulthandler：Python反向追踪库 173. pdb：Python调试器 174. timeit：小段代码执行时间测算 175. trace：Python执行状态追踪 运行时176. sys：系统相关的参数与函数 177. sysconfig：访问Python配置信息 178. builtins：内置对象 179. __main__：顶层脚本环境 180. warnings：警告控制 181. contextlib：with状态的上下文工具 182. abc：虚基类 183. atexit：出口处理器 184. traceback：打印或读取一条栈的反向追踪 185. __future__：未来状态定义 186. gc：垃圾回收接口 187. inspect：检查存活的对象 188. site：址相关的配置钩子（hook） 189. fpectl：浮点数异常控制 190. distutils：生成和安装Python模块 解释器191. code：基类解释器 192. codeop：编译Python代码 导入模块193. imp：访问import模块的内部 194. zipimport：从ZIP归档中导入模块 195. pkgutil：包扩展工具 196. modulefinder：通过脚本查找模块 197. runpy：定位并执行Python模块 198. importlib：import的一种实施 Python语言199. parser：访问Python解析树 200. ast：抽象句法树 201. symtable：访问编译器符号表 202. symbol：Python解析树中的常量 203. token：Python解析树中的常量 204. keyword：Python关键字测试 205. tokenize：Python源文件分词 206. tabnany：模糊缩进检测 207. pyclbr：Python类浏览支持 208. py_compile：编译Python源文件 209. compileall：按字节编译Python库 210. dis：Python字节码的反汇编器 211. pickletools：序列化开发工具 其它212. formatter：通用格式化输出 Windows相关213. msilib：读写Windows Installer文件 214. msvcrt：MS VC++ Runtime的有用程序 215. winreg：Windows注册表访问 216. winsound：Windows声音播放接口 Unix相关217. posix：最常用的POSIX调用 218. pwd：密码数据库 219. spwd：影子密码数据库 220. grp：组数据库 221. crypt：Unix密码验证 222. termios：POSIX风格的tty控制 223. tty：终端控制函数 224. pty：伪终端工具 225. fcntl：系统调用fcntl()和ioctl() 226. pipes：shell管道接口 227. resource：资源可用信息 228. nis：Sun的NIS的接口 229. syslog：Unix syslog程序库]]></content>
      <categories>
        <category>python模块</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django之用户认证-auth模块]]></title>
    <url>%2F2018%2F11%2F16%2FDjango%E4%B9%8B%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81-auth%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[用户认知———auth模块 一、auth模块 from django.contrib import auth 1、authenticate()：验证用户输入的用户名和密码是否相同 提供了用户认证，即验证用户名以及密码是否正确,一般需要usernamepassword两个关键字参数 如果认证信息有效，会返回一个User对象。authenticate()会在User对象上设置一个属性标识，那 种认证，后端认证了该用户，且信息在后面的登录过程中是需要的。当我们试图登录一个从数据库 中直接取出来不经过authenticate()的User对象会报错的！！！ 2、login(HttpRequest,user):登录 该函数接受一个HttpRequest对象，以及一个认证的User对象 此函数使用django的session框架给每个已认证的用户附加上session id等信息。 1234567891011121314&gt; from django.contrib.auth import authenticate, login&gt; &gt; def my_view(request):&gt; username = request.POST['username']&gt; password = request.POST['password']&gt; user = authenticate(username=username, password=password)&gt; if user:&gt; login(request, user)&gt; # Redirect to a success page.&gt; ...&gt; else:&gt; # Return an 'invalid login' error message.&gt; ...&gt; 3、logout(request):注销用户 该函数接受一个HttpRequest对象，无返回值，当调用该函数是时，当请求的session信息会全部 清除。该用户即使没有登录，使用该函数也不会登录。 123456&gt; from django.contrib.auth import logout&gt; &gt; def logout_view(request):&gt; logout(request)&gt; # Redirect to a success page.&gt; 4、user对象的is_authenticated() 要求 用户登录后才能访问某些页面 如果用户没有登录就访问该页面的话直接跳转登录页面 用户在跳转的登录界面中完成登录后，自动访问跳转到之前访问的地址 方法一 1234&gt; def my_view(request):&gt; if not request.user.is_authenticated():&gt; return redirect('%s?next=%s' % (settings.LOGIN_URL, request.path))&gt; 方法二：django已经为我们设计好了一个用于次情况的装饰器：login_request() 123456&gt; from django.contrib.auth.decorators import login_required&gt; &gt; @login_required&gt; def my_view(request):&gt; ...&gt; 若用户没有登录，则会跳转到django默认的登录URL’/account/login’(这个值可以在settings文件中 通过LOGIN_URL进行修改）。并传递当前访问url的绝对路径（登录成功后，会重定向该路径） 二、User对象 User对象属性： username password（必填项）password用哈希算法保存到数据库 is_staff：用户是否拥有网站的管理权限 is_active：是否允许用户登录，设置为‘False’，可以不用删除用户来禁止用户登录 is_authenticated() 如果是真正的User对象，返回值恒为True。用于检测用户是否已经通过认证。 通过认证并不意味着用户拥有任何权限，甚至也不检查该用户是否处于激活状态，这只是表明 用户成功通过了认证。 这个方法很重要，在后台使用 request.user.is_authenticated()判断用户是否已经登录，如果True则可以向前台展示 -request.user.name 创建用户create_user 123&gt; from django.contrib.auth.models import User&gt; user = User.objects.create_user（username='',password='',email=''）&gt; check_passw(passwd):密码检测 用户需要修改密码的时候 首先要让他输入原来的密码 ，如果给定的字符串通过了密码检查，返回 True 修改密码：set_password() 1234&gt; user = User.objects.get(username='')&gt; user.set_password(password='')&gt; user.save &gt; 三、简单实例 登录： 12345678910111213141516&gt;def log_in(request):&gt; print(request.POST)&gt; if request.method =="POST":&gt; username = request.POST.get("username")&gt; password = request.POST.get("password")&gt; print(username,password)&gt; user=auth.authenticate(username=username,password=password)#验证用户名和密码&gt; if user:&gt; #如果认证成功，就让登录，这个login里面包括了session操作和cookie&gt; auth.login(request,user)&gt; return redirect("/chakan/")&gt; else:&gt; s = "用户名和密码输入错误"&gt; return render(request,"login.html",&#123;"s":s&#125;)&gt; return render(request,"login.html")&gt; 修改密码： 1234567891011121314151617&gt;def set_pwd(request):&gt; if request.method=="POST":&gt; oldpassword = request.POST.get("oldpassword")&gt; newpassword = request.POST.get("newpassword")&gt; #得到当前登录的用户，判断旧密码是不是和当前的密码一样&gt; username = request.user #打印的是当前登录的用户名&gt; user = User.objects.get(username=username) #查看用户&gt; ret = user.check_password(oldpassword) #检查密码是否正确&gt; if ret:&gt; user.set_password(newpassword) #如果正确就给设置一个新密码&gt; user.save() #保存&gt; return redirect("/login/")&gt; else:&gt; info = "输入密码有误"&gt; return render(request,"set_pwd.html",&#123;"info":info&#125;)&gt; return render(request,"set_pwd.html")&gt; 注册： 12345678910&gt;def reg(request):&gt; if request.method=="POST":&gt; username = request.POST.get("username")&gt; password = request.POST.get("password")&gt; #得到用户输入的用户名和密码创建一个新用户&gt; User.objects.create_user(username=username,password=password) #User是以个对象&gt; s = "恭喜你注册成功，现在可以登录了"&gt; return redirect("/login/")&gt; return render(request,"reg.html")&gt; 注销： 1234&gt;def log_out(request):&gt; auth.logout(request)&gt; return redirect("/login/")&gt;]]></content>
      <categories>
        <category>Django</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django-admin管理工具]]></title>
    <url>%2F2018%2F11%2F15%2FDjango-admin%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[admin组件使用Django提供了基于web的管理工具 Django 自动管理工具是 django.contrib 的一部分。你可以在项目的 settings.py 中的 INSTALLED_APPS 看到它： # Application definition INSTALLED_APPS = [ &apos;django.contrib.admin&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;, &quot;app01&quot; ] django.contrib是一套庞大的功能集，它是Django基本代码的组成部分。 激活管理工具 通常在生成项目的时候会在urls.py中自动设置好 from django.conf.urls import url from django.contrib import admin urlpatterns = [ url(r&apos;^admin/&apos;, admin.site.urls), ] 当这一切配置好后，Django管理工具就可以运行了。 使用管理工具启动开发服务器，然后在浏览器中访问 http://127.0.0.1:8000/admin/，得到登陆界面， 你可以通过命令 python manage.py createsuperuser 来创建超级用户。 为了让 admin 界面管理某个数据模型，我们需要先注册该数据模型到 admin from django.db import models # Create your models here. class Author(models.Model): name=models.CharField( max_length=32) age=models.IntegerField() def __str__(self): return self.name class Publish(models.Model): name=models.CharField( max_length=32) email=models.EmailField() def __str__(self): return self.name class Book(models.Model): title = models.CharField( max_length=32) publishDate=models.DateField() price=models.DecimalField(max_digits=5,decimal_places=2) publisher=models.ForeignKey(to=&quot;Publish&quot;) authors=models.ManyToManyField(to=&apos;Author&apos;) def __str__(self): return self.title admin的定制在admin中只需要将Model中的某个类注册，即可在Admin中实现增删改查的功能，如： admin.site.register(models.UserInfo) 但是这种方式比较简单，如果想进行更多的定制操作，需要利用ModelAdmin进行操作， 如： 方式一： class UserAdmin(admin.ModelAdmin): list_display = (&apos;user&apos;, &apos;pwd&apos;,) admin.site.register(models.UserInfo, UserAdmin) # 第一个参数可以是列表 方式二： @admin.register(models.UserInfo) # 第一个参数可以是列表 class UserAdmin(admin.ModelAdmin): list_display = (&apos;user&apos;, &apos;pwd&apos;,) ModelAdmin中提供了大量的可定制功能，如： 1 list_display，列表时，定制显示的列。 @admin.register(models.UserInfo) class UserAdmin(admin.ModelAdmin): list_display = (&apos;user&apos;, &apos;pwd&apos;, &apos;xxxxx&apos;) def xxxxx(self, obj): return &quot;xxxxx&quot; 2 list_display_links，列表时，定制列可以点击跳转。 @admin.register(models.UserInfo) class UserAdmin(admin.ModelAdmin): list_display = (&apos;user&apos;, &apos;pwd&apos;, &apos;xxxxx&apos;) list_display_links = (&apos;pwd&apos;,) 3 list_filter，列表时，定制右侧快速筛选。4 list_select_related，列表时，连表查询是否自动select_related5 list_editable，列表时，可以编辑的列 @admin.register(models.UserInfo) class UserAdmin(admin.ModelAdmin): list_display = (&apos;user&apos;, &apos;pwd&apos;,&apos;ug&apos;,) list_editable = (&apos;ug&apos;,) 6 search_fields，列表时，模糊搜索的功能 @admin.register(models.UserInfo) class UserAdmin(admin.ModelAdmin): search_fields = (&apos;user&apos;, &apos;pwd&apos;) 7 date_hierarchy，列表时，对Date和DateTime类型进行搜索 @admin.register(models.UserInfo) class UserAdmin(admin.ModelAdmin): date_hierarchy = &apos;ctime&apos; 8 inlines，详细页面，如果有其他表和当前表做FK，那么详细页面可以进行动态增加和删除 class UserInfoInline(admin.StackedInline): # TabularInline extra = 0 model = models.UserInfo class GroupAdminMode(admin.ModelAdmin): list_display = (&apos;id&apos;, &apos;title&apos;,) inlines = [UserInfoInline, ] 9 action，列表时，定制action中的操作 @admin.register(models.UserInfo) class UserAdmin(admin.ModelAdmin): # 定制Action行为具体方法 def func(self, request, queryset): print(self, request, queryset) print(request.POST.getlist(&apos;_selected_action&apos;)) func.short_description = &quot;中文显示自定义Actions&quot; actions = [func, ] # Action选项都是在页面上方显示 actions_on_top = True # Action选项都是在页面下方显示 actions_on_bottom = False # 是否显示选择个数 actions_selection_counter = True 10 定制HTML模板 add_form_template = None change_form_template = None change_list_template = None delete_confirmation_template = None delete_selected_confirmation_template = None object_history_template = None 11 raw_id_fields，详细页面，针对FK和M2M字段变成以Input框形式 @admin.register(models.UserInfo) class UserAdmin(admin.ModelAdmin): raw_id_fields = (&apos;FK字段&apos;, &apos;M2M字段&apos;,) 12 fields，详细页面时，显示字段的字段 @admin.register(models.UserInfo) class UserAdmin(admin.ModelAdmin): fields = (&apos;user&apos;,) 13 exclude，详细页面时，排除的字段 @admin.register(models.UserInfo) class UserAdmin(admin.ModelAdmin): exclude = (&apos;user&apos;,) 14 readonly_fields，详细页面时，只读字段 @admin.register(models.UserInfo) class UserAdmin(admin.ModelAdmin): readonly_fields = (&apos;user&apos;,) 15 fieldsets，详细页面时，使用fieldsets标签对数据进行分割显示 @admin.register(models.UserInfo) class UserAdmin(admin.ModelAdmin): fieldsets = ( (&apos;基本数据&apos;, { &apos;fields&apos;: (&apos;user&apos;, &apos;pwd&apos;, &apos;ctime&apos;,) }), (&apos;其他&apos;, { &apos;classes&apos;: (&apos;collapse&apos;, &apos;wide&apos;, &apos;extrapretty&apos;), # &apos;collapse&apos;,&apos;wide&apos;, &apos;extrapretty&apos; &apos;fields&apos;: (&apos;user&apos;, &apos;pwd&apos;), }), ) 16 详细页面时，M2M显示时，数据移动选择（方向：上下和左右） @admin.register(models.UserInfo) class UserAdmin(admin.ModelAdmin): filter_vertical = (&quot;m2m字段&quot;,) # 或filter_horizontal = (&quot;m2m字段&quot;,) 17 ordering，列表时，数据排序规则 @admin.register(models.UserInfo) class UserAdmin(admin.ModelAdmin): ordering = (&apos;-id&apos;,) 或 def get_ordering(self, request): return [&apos;-id&apos;, ] 18 radio_fields，详细页面时，使用radio显示选项（FK默认使用select） radio_fields = {&quot;ug&quot;: admin.VERTICAL} # 或admin.HORIZONTAL 19 form = ModelForm，用于定制用户请求时候表单验证 from app01 import models from django.forms import ModelForm from django.forms import fields class MyForm(ModelForm): others = fields.CharField() class Meta: model = models = models.UserInfo fields = &quot;__all__&quot; @admin.register(models.UserInfo) class UserAdmin(admin.ModelAdmin): form = MyForm 20 empty_value_display = “列数据为空时，显示默认值” @admin.register(models.UserInfo) class UserAdmin(admin.ModelAdmin): empty_value_display = &quot;列数据为空时，默认显示&quot; list_display = (&apos;user&apos;,&apos;pwd&apos;,&apos;up&apos;) def up(self,obj): return obj.user up.empty_value_display = &quot;指定列数据为空时，默认显示&quot; 例子： from django.contrib import admin # Register your models here. from .models import * class BookInline(admin.StackedInline): # TabularInline extra = 0 model = Book class BookAdmin(admin.ModelAdmin): list_display = (&quot;title&quot;,&apos;publishDate&apos;, &apos;price&apos;,&quot;foo&quot;,&quot;publisher&quot;) list_display_links = (&apos;publishDate&apos;,&quot;price&quot;) list_filter = (&apos;price&apos;,) list_editable=(&quot;title&quot;,&quot;publisher&quot;) search_fields = (&apos;title&apos;,) date_hierarchy = &apos;publishDate&apos; preserve_filters=False def foo(self,obj): return obj.title+str(obj.price) # 定制Action行为具体方法 def func(self, request, queryset): print(self, request, queryset) print(request.POST.getlist(&apos;_selected_action&apos;)) func.short_description = &quot;中文显示自定义Actions&quot; actions = [func, ] # Action选项都是在页面上方显示 actions_on_top = True # Action选项都是在页面下方显示 actions_on_bottom = False # 是否显示选择个数 actions_selection_counter = True change_list_template=&quot;my_change_list_template.html&quot; class PublishAdmin(admin.ModelAdmin): list_display = (&apos;name&apos;, &apos;email&apos;,) inlines = [BookInline, ] admin.site.register(Book, BookAdmin) # 第一个参数可以是列表 admin.site.register(Publish,PublishAdmin) admin.site.register(Author) admin源码解析单例模式单例模式（Singleton Pattern）是一种常用的软件设计模式，该模式主要目的是确保 某一个类只有一个实例存在。当我们希望在整个系统中，某个类只能出现一个实例 时，单例对象就能派上用场。 比如，某个服务器程序的配置信息存放在一个文件中，客户端通过一个APPConfig 的类来读取配置文件的信息。如果在程序运行期间，有很多地方需要使用配置文 件的内容，也就是说，很多地方都需要APPConfig的实例对象，而这样会严重浪费 内存资源，尤其是在配置文件内容很多的情况下。事实上，类似AppConfig这样的 类，我们希望在程序运行期间只存在一个实例对象。 在python中，我们可以用很多种方式来实现单例模式：使用模块（模块的导入）使用new使用装饰器（decorator）使用元类（metaclass）（1）使用new 为了使类只能出现一个实例，我们可以使用new来控制实例的创建过程，代码 如下： class Singleton(object): _instance = None def __new__(cls, *args, **kw): if not cls._instance: cls._instance = super(Singleton, cls).__new__(cls, *args, **kw) return cls._instance class MyClass(Singleton): a = 1 在上面的代码中，我们将类的实例和一个类变量instance关联起来，如果cls.instance为None则创建实例，否则直接返回cls._instance执行情况： &gt;&gt;&gt; one = MyClass() &gt;&gt;&gt; two = MyClass() &gt;&gt;&gt; one == two True &gt;&gt;&gt; one is two True &gt;&gt;&gt; id(one), id(two) (4303862608, 4303862608) (2)使用模块 其实，Python 的模块就是天然的单例模式，因为模块在第一次导入时，会生成 .pyc 文件，当 第二次导入时，就会直接加载 .pyc 文件，而不会再次执行模块代码。因此，我们只需把相关的 函数和数据定义在一个模块中，就可以获得一个单例对象了。如果我们真的想要一个单例类，可 以考虑这样做： # mysingleton.py class My_Singleton(object): def foo(self): pass my_singleton = My_Singleton() 将上面的代码保存在文件 mysingleton.py 中，然后这样使用： from mysingleton import my_singleton my_singleton.foo() admin执行流程循环加载执行所有已经注册的app中的admin.py文件def autodiscover(): autodiscover_modules(&apos;admin&apos;, register_to=site) 执行代码＃admin.py class BookAdmin(admin.ModelAdmin): list_display = (&quot;title&quot;,&apos;publishDate&apos;, &apos;price&apos;) admin.site.register(Book, BookAdmin) admin.site.register(Publish) admin.siteclass AdminSite(object):... # This global object represents the default admin site, for the common case. # You can instantiate AdminSite in your own code to create a custom admin site. site = AdminSite() 这里应用的是一个单例模式，对于AdminSite类的一个单例模式，执行的每一个app中的每一个admin.site 都是一个对象。 执行register方法admin.site.register(Book, BookAdmin) admin.site.register(Publish) class ModelAdmin(BaseModelAdmin):pass def register(self, model_or_iterable, admin_class=None, **options): if not admin_class: admin_class = ModelAdmin # Instantiate the admin class to save in the registry self._registry[model] = admin_class(model, self) # 思考：在每一个app的admin .py中加上 print(admin.site._registry) ＃ 执行结果？ 到这里，注册结束！ admin的URL配置urlpatterns = [ url(r&apos;^admin/&apos;, admin.site.urls), ] class AdminSite(object): def get_urls(self): from django.conf.urls import url, include urlpatterns = [] # Add in each model&apos;s views, and create a list of valid URLS for the # app_index valid_app_labels = [] for model, model_admin in self._registry.items(): urlpatterns += [ url(r&apos;^%s/%s/&apos; % (model._meta.app_label, model._meta.model_name), include(model_admin.urls)), ] if model._meta.app_label not in valid_app_labels: valid_app_labels.append(model._meta.app_label) return urlpatterns @property def urls(self): return self.get_urls(), &apos;admin&apos;, self.name url方法的扩展应用from django.shortcuts import HttpResponse def test01(request): return HttpResponse(&quot;test01&quot;) def test02(request): return HttpResponse(&quot;test02&quot;) urlpatterns = [ url(r&apos;^admin/&apos;, admin.site.urls), url(r&apos;^ward/&apos;, ([ url(r&apos;^test01/&apos;, test01), url(r&apos;^test02/&apos;, test02), ],None,None)), ] 扩展优化from django.conf.urls import url,include from django.contrib import admin from django.shortcuts import HttpResponse def change_list_view(request): return HttpResponse(&quot;change_list_view&quot;) def add_view(request): return HttpResponse(&quot;add_view&quot;) def delete_view(request): return HttpResponse(&quot;delete_view&quot;) def change_view(request): return HttpResponse(&quot;change_view&quot;) def get_urls(): temp=[ url(r&quot;^$&quot;.format(app_name,model_name),change_list_view), url(r&quot;^add/$&quot;.format(app_name,model_name),add_view), url(r&quot;^\d+/del/$&quot;.format(app_name,model_name),delete_view), url(r&quot;^\d+/change/$&quot;.format(app_name,model_name),change_view), ] return temp url_list=[] for model_class,obj in admin.site._registry.items(): model_name=model_class._meta.model_name app_name=model_class._meta.app_label # temp=url(r&quot;{0}/{1}/&quot;.format(app_name,model_name),(get_urls(),None,None)) temp=url(r&quot;{0}/{1}/&quot;.format(app_name,model_name),include(get_urls())) url_list.append(temp) urlpatterns = [ url(r&apos;^admin/&apos;, admin.site.urls), url(r&apos;^ward/&apos;, (url_list,None,None)), ]]]></content>
      <categories>
        <category>Django</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[vue-cli目录结构总结的步骤]]></title>
    <url>%2F2018%2F11%2F14%2Fvue-cli%E8%87%AA%E5%B7%B1%E6%80%BB%E7%BB%93%E7%9A%84%E6%AD%A5%E9%AA%A4%2F</url>
    <content type="text"><![CDATA[main.js这是js的入口文件// The Vue build version to load with the `import` command // (runtime-only or standalone) has been set in webpack.base.conf with an alias. import Vue from &apos;vue&apos; import App from &apos;./App&apos; import router from &apos;./router&apos; import store from &quot;./store&quot; import axios from &apos;axios&apos; // 使用element-ui import ElementUI from &apos;element-ui&apos; import &apos;element-ui/lib/theme-chalk/index.css&apos; Vue.use(ElementUI); // 全局的（一个一个比较麻烦） // axios.request({ // url: XXX, // method: &quot;get&quot; // }); // 通过使用原型链 这样所有的组件都可以通过$axios去访问了 Vue.prototype.$axios = axios; Vue.config.productionTip = false; /* eslint-disable no-new */ new Vue({ el: &apos;#app&apos;, router, store, components: { App }, template: &apos;&lt;App/&gt;&apos; }); App.vue页面级App组件&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;MyHeader&gt;&lt;/MyHeader&gt; &lt;router-view&gt;&lt;/router-view&gt; &lt;MyFooter&gt;&lt;/MyFooter&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; import MyHeader from &quot;./components/MyHeader&quot; import MyFooter from &quot;./components/MyFooter&quot; export default { name: &apos;App&apos;, components: { MyHeader, MyFooter, } } &lt;/script&gt; &lt;style&gt; body { margin: 0; padding: 0; } &lt;/style&gt; router-index.jsimport Vue from &apos;vue&apos; import Router from &apos;vue-router&apos; import Home from &apos;../components/headers/Home&apos; import Course from &apos;../components/headers/Course&apos; Vue.use(Router); export default new Router({ routes: [ { path: &apos;/&apos;, name: &apos;home&apos;, component: Home }, { path: &apos;/course&apos;, name: &apos;course&apos;, component: Course } ] }) Vuex+axios的使用store.jsimport Vue from &quot;vue&quot; import Vuex from &quot;vuex&quot; Vue.use(Vuex); export default new Vuex.Store({ // this.$store.state.name 拿数据 state: { name: &apos;1&apos;, }, // 对state中的数据进行处理 // this.$store.getters.new_name 拿数据 getters: { new_name: function (state) { return state.name + &apos;xxx&apos;; }, new_new_name: function (state, getters) { return getters.new_name + &apos;000&apos;; }, }, mutations: { change_data: function (state, data) { // 自己处理change_data事件的 state.name = data; } } }) Course.vue&lt;template&gt; &lt;div&gt; &lt;h1&gt;course&lt;/h1&gt; {{name}} {{new_name}} &lt;hr&gt; {{try_again}} &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { name: &quot;Course&quot;, data(){ return { name : this.$store.state.name, new_name: this.$store.getters.new_new_name, try_again: &apos;&apos;, } }, // 方法执行完会改版数据但是不会刷新 // methods: { // my_click: function () { // this.$store.commit(&quot;change_data&quot;, &apos;到到&apos;) // } // }, // 能够监听到数据的改变能够实时跟新 // computed: { // name: function () { // return this.$store.state.name; // } // } mounted(){ let that = this; this.$axios.request({ url: &quot;http://127.0.0.1:8000/tryagain/&quot;, method: &apos;get&apos;, }).then(function (data) { // success do something~~ that.try_again = data.data }).catch(function (data) { // fail do something~~ }) // 单纯的发get请求 // this.$axios.get(&quot;url&quot;, {}).then() } } &lt;/script&gt; &lt;style scoped&gt; &lt;/style&gt;]]></content>
      <categories>
        <category>Vue</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Vuex+axios]]></title>
    <url>%2F2018%2F11%2F13%2FVuex-axios%2F</url>
    <content type="text"><![CDATA[Vuex 简介vuex是一个专门为Vue.js设计的集中式状态管理架构。 状态？ 我们把它理解为在data中需要共享给其他组件使用的部分。 Vuex和单纯的全局对象有以下不同： 1、Vuex 的状态存储是响应式的。当vue组件从store中读取状态的时候， 若store中的状态发生变化，那么相应的组件也会相应的得到高效更新。 2、你不能直接改变store中的状态。改变store中的状态的唯一途径就是显示的 提交(commit)mutation。这样使得我们可以方便的跟踪每一个状态的变化， 从而让我们能够实现一些工具来帮助我们更好的了解我们的应用。 安装使用vuex– npm install vuex vuex的使用一 // main.js import Vue from &apos;vue&apos; import App from &apos;./App&apos; import router from &apos;./router&apos; import vuex from &apos;vuex&apos; Vue.use(vuex) Vue.config.productionTip = false const store = new vuex.Store({ state: { show: false, } }); new Vue({ el: &apos;#app&apos;, router, store, components: { App }, template: &apos;&lt;App/&gt;&apos; }); vuex的使用二 // 为了方便维护，我们通常把在src下面新建一个store文件夹， // 然后在里面新建一个index.js import Vue from &apos;vue&apos; import Vue_x from &quot;vuex&quot; Vue.use(Vue_x); export default new Vue_x.Store({ state: { show: false, }, }); // 那么main.js要改成 import Vue from &apos;vue&apos; import App from &apos;./App&apos; import router from &apos;./router&apos; import store from &quot;./store&quot; Vue.config.productionTip = false; new Vue({ el: &apos;#app&apos;, router, store, components: { App }, template: &apos;&lt;App/&gt;&apos; }); State简而言之~~state是保存我们data中需要共享的数据。 由于Vuex的存储是响应式的，从store实例中读取状态的最简单的方式就是在计算属性中返回某个状态。 this.$store.state.count 组件中获取vuex中状态 // 创建一个组件 const Counter = { template: `&lt;div&gt;{{ count }}&lt;/div&gt;`, computed: { count(){ return this.$store.state.count } } }; Getter有时候我们需要从store中的state中派生出一些状态，例如对数据进行简单的计算。 并且很多组件都需要用到此方法，我们要么复制这个函数，要么抽取到一个公共函数，多处导入。 我们vuex提供了更加方便的方法，getter ，它就像计算属性一样，getter的返回值会根据它的依赖被 缓存起来，只有它的依赖发生改变时，才会重新计算。 Getter会接收state作为其第一个参数： import Vue from &apos;vue&apos; import Vue_x from &quot;vuex&quot; Vue.use(Vue_x); export default new Vue_x.Store({ state: { count: 20, }, // 通过 this.$store.getters.my_func getters: { my_func: function (state) { return state.count * 2 } }, }); Getter也可以接收getters为第二个参数： import Vue from &apos;vue&apos; import Vue_x from &quot;vuex&quot; Vue.use(Vue_x); export default new Vue_x.Store({ state: { count: 20, }, // 通过 this.$store.getters.my_func getters: { my_func: function (state) { return state.count * 2 }, // 通过 this.$store.getters.my_func_count my_func_count: function (state, getters) { return getters.my_func.length } }, }); Mutatiion更改Vuex中的store中的状态的唯一方法是提交mutation。 每个mutation都有一个字符串的事件类型(type)，和一个回调函数handler。 也就是说我们要触发mutation中定义的方法(type)，然后才会执行这个方法(handler)。 这个方法就是我们更改状态的地方，它会接收state为第一个参数，后面接收其他参数： Mutation基本使用 import Vue from &apos;vue&apos; import Vue_x from &quot;vuex&quot; Vue.use(Vue_x); export default new Vue_x.Store({ state: { count: 20, }, // 需要通过 this.$store.commit(&apos;increment&apos;, 10) mutations: { increment (state, n) { // 变更状态 state.count += n } } }); Mutation需要遵守Vue的响应规则 既然vuex中的store中的状态是响应式的，那么当我们状态变更时，监视状态的vue组件也会更新。 这就意味着vuex中的mutation也需要与使用vue一样遵守一些注意事项： – 1，最好提前在你的store中初始化好所有的所需要的属性 – 2，当对象需要添加属性时，你应该使用 – Vue.set(obj, ‘newProp’, 123) – 以新对象代替老对象 state.obj = { …state.obj, newProp: 123} axios的简单使用基于Promise的HTTP请求客户端，可以同时在浏览器和node.js使用。 ## 使用npm安装axios – npm install axios -D 基本的配置// main.js import axios from &quot;axios&quot; Vue.prototype.$axios = axios // 组件中 methods: { init () { this.$axios({ method: &quot;get&quot;, url: &quot;/user&quot; }) }, }; 基本的使用get请求 test(){ this.$axios.get(this.$store.state.apiList.course,{ params: { id: 123, } }).then(function (response) { // 请求成功回调函数 }).catch(function (response) { // 请求失败的回调函数 }) } post请求 test(){ this.$axios.post(this.$store.state.apiList.course,{ course_title: &quot;Python&quot;, course_price: &quot;19.88&quot; }).then(function (response) { // 请求成功回调函数 }).catch(function (response) { // 请求失败的回调函数 }) } 发送多个并发请求 function getCourse(){ return this.$axios.get(&apos;/course/12&apos;) } function getCourse_all() { return this.$axios.get(&apos;/course&apos;) } this.$axios.all([getCourse_all(),getCourse()]) .then().catch() axios.request methods: { init(){ var that = this this.$axios.request({ url: that.$store.state.apiList.course, method: &apos;get&apos; }).then(function (data) { if (data.status === 200){ that.courseList = data.data } }).catch(function (reason) { console.log(reason) }) } },]]></content>
      <categories>
        <category>Vue</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[npm+webpack+vue-cli快速上手]]></title>
    <url>%2F2018%2F11%2F13%2Fnpm-webpack-vue-cli%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%2F</url>
    <content type="text"><![CDATA[Node.js npm什么是Node.js 以及npm简单的来说 Node.js 就是运行在服务端的JavaScript，基于Chrome V8 引擎的。 npm 是Node.js 的包管理工具。 npm的安装和更新Node.js下载安装 Node.js 官网下载安装。npm自带的包管理工具。 查看安装版本信息： – node -v 查看Node.js 版本信息 – npm -v 查看npm版本信息 更新npm到指定版本： – npm install npm@5.3.0 -g – npm install npm@latest -g 更新最新的稳定版本 npm 常用操作之前我们用JQuery或者Bootstrap用cdn 或者直接手动下载并放入项目，而且要管理版本。 有了npm，我们管理自己的依赖包以及版本更加简单。 到自己项目目录下，进行以下命令： – npm init -y 输入-y使用默认配置项 生成package.json文件。 – npm i jquery@0.0.0 简写install 为 i 下载依赖 不写@ 默认最新版本 – npm uninstall jquery 卸载依赖包 – npm update jquery 更新依赖包 – npm list 列出已安装的依赖 – npm install webpack –D 保存为开发环境依赖 – 老版本需要 –save 参数 现在不需要了 我们的项目目录下会生成一个 node_modules 目录，我们用npm下的包会在这个目录下。 我们所有的依赖信息放在package.json文件中，包括我们所有的依赖以及版本。 如果我们删掉 node_modules目录，可以使用 npm i 来下载所有依赖。 npm 常用配置项当我们用npm init 的时候用了参数 -y，如果不用-y我们可以进行一些配置。 在我们的package.json文件中有很多配置项 – name 项目名字 中间不能有空格只能用小写 – version 项目版本 – description 项目描述信息 – main 项目的入口文件 – scripts 指定命令的快捷方式 npm run test test是scripts里的键名 值为具体命令 – author 作者 – license 许可证 – dependencies 生成环境依赖的包以及版本信息 – devDependencies 开发环境的依赖 webpack3webpack是什么webpack是一个模块打包器，它将根据模块的依赖关系进行静态分析， 然后将这些模块按照指定的规则生成静态资源。 那么，我们为什么要用这个东西呢~~因为前端的包袱太多，历史遗留问题太重123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113##安装和配置 webpack是跑在Node.js环境下的，所以确定自己有node环境。安装方式： -- npm install webpack -g 全局安装 -- webpack &lt;要打包文件&gt; &lt;打包后文件&gt; 全局这种方式进行打包 -- npm install webpack 在自己的项目下 npm init 后在下载webpack 这就是局部安装 -- node_modules/.bin/webpack &lt;要打包文件&gt; &lt;打包后文件&gt; 项目里要打包文件是入口文件 -- 路径太长 太烦 可以自定义命令 在package.json 文件的 scripts下面自定义## entry 和 output entry 入口文件 output 出口文件 上面我们自定义命令的时候 命令太长了~~而且我们命令太多的时候我们需要每次都自定义多条命令~~ 我们可以把命令写在webpack.config.js文件中~~&gt;webpack.config.jsmodule.export = &#123; // 所有的入口文件 entry: &#123; home: &apos;./main.js&apos;, login: &apos;./login.js&apos;, &#125;, // 出口文件 output: &#123; filename: &apos;[name].bundle.js&apos;, path: __dirname + &apos;/dist&apos;, &#125; &#125;// backage.json 下的scriptsscripts: &#123; &quot;pack&quot;: &quot;node_moudles/.bin/webpack --watch&quot;&#125;// 运行命令npm run pack# webpack4## webpack的新特性1, webpack不在单独使用，需要webpack-cli -- 全局安装 npm install webpack webpack-cli -g -D -- 局部安装 npm install webpack webpack-cli -D2, 增加了模式区分 （development, production） --webpack --mode development/production 进行模式切换 -- development 开发者模式 打包默认不压缩代码 -- production 生产者模式 上线时使用，压缩代码。 默认是这个模式3，固定入口目录为src，与入口默认文件index.js，打包后文件在新增的dist目录下 -- 当只有一个入口文件也就是src/index.js时，无需增加webpack.config.js4，多入口以及多出口&gt;webpack.config.js entry: &#123; // 多入口 a: &quot;./src/js/index.js&quot;, b: &quot;./src/js/index2.js&quot;,&#125;output: &#123; // 多出口 path: path.resolve(__dirname, &apos;dist&apos;), filename: &apos;./js/[name].bundle.js&apos;&#125;# vue-clivue-cli是官方提供的快速构建这个单页面应用的脚手架。## 根据官方文档中的构件流程： -- 前提是已经安装了node.js 否则npm都用不了 -- 1，使用npm全局安装vue-cli npm install -g vue-cli -- 2, 安装完成后在自己的工作空间里 vue init webpack vue-demo 输入命令后进入安装阶段，需要用户输入一些信息 这里省略了..... -- 3，切换到我们的项目目录下 cd vue-demo npm run dev## 目录结构： -- build 里面是一些操作文件，使用npm run * 时其实执行的就是这里的文件 -- config 配置文件，执行文件需要的配置信息 -- src 资源文件 所有的组件以及所有的图片 都在这个文件夹下 -- node_modules 项目依赖包 -- static 静态资源 -- package.json 依赖包的json文件其实这里面命令很多~我们在后续项目中应用到再说 vue-cli配置JQuery、bootstrap第一步 下载安装 – npm install jquery – npm install bootstrap 第二步 修改build/webpack.base.conf.js const webpack = require(‘webpack’)// 在module.exports里添加插件plugins: [ new webpack.ProvidePlugin({ $: “jquery”, jQuery: “jquery”, “windows.jQuery”: “jquery”, // Popper: [‘popper.js’, ‘default’] })],// ***下面是如果手动下载bootstrap用的***resolve: { extensions: [‘.js’, ‘.vue’, ‘.json’], alias: { ‘vue$’: ‘vue/dist/vue.esm.js’, ‘@’: resolve(‘src’), // 如果是手动下载的bootstrap需要添加这个配置 // ‘assets’: path.resolve(__dirname, ‘../src/assets’), // ‘jquery’: ‘jquery/src/jquery’ } }, 修改配置文件 第三步 修改主程序的js文件 main.js import $ from ‘jquery’import ‘bootstrap/dist/css/bootstrap.min.css’import ‘bootstrap/dist/js/bootstrap.min.js’ vue-cli 3.0第一步 下载vue-cli 3.0 – npm install -g @vue/cli – 报错 npm error 可以运行下面命令 – npm cache clean –force &amp;&amp; npm cache verify 第二步 创建项目 – vue create xxxx 之后会出现很多选项，我们可以根据自己的习惯去选择~~ 第三步 目录结构以及配置文件 – vue-cli3 目录更加简单 – 我们手动在项目根目录下创建 vue.config.js 里面写vue的配置信息 vue-cli3 配置jQuery、bootstrap – 跟vue-cli2一样的配置，手动创建一个webpack.base.conf.js]]></content>
      <categories>
        <category>Vue</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Vue总结]]></title>
    <url>%2F2018%2F11%2F13%2FVue%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[vue总结 MVC Model View Controller MVVM Model View ViweMode ES6常用语法1.1 变量的提升 1.2 模板字符串 ``${} 1.3 数据的解构 1.4 类 class extends constructor super 1.5 函数 1.5.1 注意this和普通函数的区别 1.6 箭头函数 1.7 单体模式 1.8 import export export default Vue常用指令2.1 v-text innerText 2.2 v-html innerHtml 2.3 v-for :key 2.4 v-if v-else-if v-else appendChild 2.5 v-show display 2.6 v-on @xxxx=&quot;自己处理的方法&quot; 2.7 v-bind :属性名称=“属性的值” 2.8 v-model 2.8.1 input 2.8.2 textarea 2.8.3 select 2.9 指令修饰符 2.9.1 .lazy 2.9.2 .number 2.9.3 .trim 2.10 计算属性 2.10.1 放入缓存 2.10.2 只有数据改变的时候才会重新计算 2.11 数据监听 2.11.1 注意可变类型和不可变 2.11.2 深监听 deep=true 2.12 获取DOM 2.12.1 给便签绑定ref属性 ref=“属性值” 2.12.2 this.$refs.属性值 2.13 自定义指令 2.13.1 vue.directive(“指令名称”, function(el, binding){ el 绑定指令的便签元素 binding 指令的所有信息 }) 注意事项3.1 数据监听 3.1.1 改变数据 直接赋值 3.1.2 改变数组长度 能够被监听到，新值和旧值一样 3.1.3 改变数组内的值 app = new vue({}) app.$set(this.hobby, 0, &apos;抽烟&apos;) $set()修改数组中的值可以监听 $delete() Vue的组件组件的注册全局注册Vue.compontent(“组件名称”, {}) 局部注册const = app = new Vue({ el: &apos;#app&apos;, components: { 组件的名称: 组件的配置信息 } }) 子组件的注册在父组件中注册components ## 注意写组件标签 ## 每个组件的template只识别一个作用域块 通信父子的通信在父组件中给子组件绑定属性 子组件通过props=[&quot;属性名称&quot;] 子父的通信子组件先提交事件 this.$emit(&quot;事件名称&quot;, 值) 在父组件中给子组件绑定事件 &lt;child @事件名称=&quot;父亲处理的方法&quot;&gt;&lt;/child&gt; 非父子的通信其中一个组件向中间调度器提交事件 另一个组件监听中间调度器的事件 注意this的问题 中间调度器 let temp = new Vue(); temp.$emit(&quot;say&quot;, value) // 事件名称和值 mounted(){ that = this // 监听中间调度器中的方法 temp.$on(&quot;say&quot;, function(data){ // 这里的this是temp的this that.xxx = data // 这样改值 }) } 插槽&lt;slot&gt;&lt;/slot&gt; 命名的插槽 混合代码重用的 mixins = [base] Vue的生命周期vue生命周期之beforeCreate实例创建之前除标签外，所有的vue需要的数据，事件都不存在 vue生命周期之created实例创建之后，data和事件已经被解析到，el还没有找到 vue生命周期之beforeMount开始找标签，数据还没有被渲染，事件也没有被监听 vue生命周期之mounted开始渲染数据，开始监听事件 vue生命周期之beforeUpdata数据已经被修改在虚拟DOM，但没有被渲染到页面上 vue生命周期之updata开始使用Diff算法，将虚拟DOM中的修改应用大页面上，此时真实DOM中数据被修改 vue生命周期之beforeDestory所有的数据都存在 vue生命周期之destoryed所有的数据都有(虚拟DOM中找数据)展示的真实DOM已经是静态页面了 &lt;keep-alive&gt;&lt;/keep-alive&gt;vue提供的用来缓存被消除的标签 用activated和deactivated取代了beforeUpdate和destory的执行 最常用的钩子beforeMount mounted 路由注册let url = [ { path: &apos;/&apos;, name: &quot;home&quot;, component: { template: ``, } } ] let router = nwe VueRouter({ routes: url }) const app = new Vue({ el: &apos;app&apos;, router: router, }) &lt;router-link to=&apos;/&apos;&gt;首页&lt;/router-link&gt; &lt;router-link :to=&apos;{name: &quot;home&quot;}&apos;&gt;首页&lt;/router-link&gt; &lt;router-view&gt;&lt;/router-view&gt; 子路由children: [ {} ] append 在父路由对应的组件的template里面写router-link router-view 路由的命名name 注意to加冒号动态绑定 路由的参数{ path: &quot;/course/:id&quot;, } this.$route.params.id this.$route.query.xxx $route 是一个对象 存放当前路由的所有信息 $router VueRouter实例化对象 手动路由this.$router.push(&apos;/&apos;) this.$router.push({name:&quot;home&quot;}) 重定向redirect: {name: &apos;xxx&apos;, params: {key: value}} 路由的钩子router.beforeEach(function(to, from next){ // to 你要去哪 // from 你要从哪里来 // next() 你要去做什么 参数可以给路径 必须有，没有就不走 }) router.afterEach(function(to, from){ // to 你要去哪 // from 你从哪里来 }) to和from都是$route对象 路由的所有信息  node.js + npm + webpack + vue-cli(自带webpack)node.js / npm - npm 管理工作目录 npm init -y - 下载包 npm i xxx@0.0.0 - 卸载 npm uninstall xxx - 更新 npm updata xxx webpack 4 - 下载 npm i webpack webpack-cli - 打包 webpack --mode development/production - 打包默认的入口文件 src目录下的index.js - 出口文件 dist目录的main.js wue-cli 2 - 帮助我们快速搭建项目的脚手架工具 - 下载 npm i vue-cli - 用vue-cli帮助我们创建项目 vue init webpack xxxx(项目名称) - 启动项目 cd xxxx(项目名称) npm run dev - 打吧包 npm run build Vuex和axiosVuex存放一些公共的东西,是一个仓库 安装 npm i vuex 配置 导入 import vuex from &quot;vuex&quot; vue使用vuex vue.use(vuex) 实例化仓库 new vuex.Store({ state: {}, getters: {}, mutations: {} }) new Vue({ el: &apos;#app&apos;, store, }) 获取残仓库数据 this.$store.state.xxx this.$store.getters.xxx 改变仓库中的数据 组件向仓库提交修改事件 this.$store.commit(&quot;事件名称&quot;, data) 在仓库中的mutations中 mutations: { &quot;事件名称&quot;: function(state, data){ 修改state中的数据 } } 注意计算属性 仓库中的数据建议都放在计算属性中 axios向后端服务器发送请求 实现ajax技术的工具 配置 下载 npm i axios 导入 import axios from “axios” 在vue的原型链中加入方法 Vue.prototype.#axios = axios 发送请求 this.$axios.request({ url: &apos;&apos;, method: &apos;&apos;, }).then(function(){ }).catch(function(){ }) 前后端的接通后端设计一个接口 前端通过axios发送请求拿到数据 跨域问题 element-ui按照文档安装，并研究如何使用]]></content>
      <categories>
        <category>Vue</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Vue组件系统]]></title>
    <url>%2F2018%2F10%2F14%2Fvue%E7%BB%84%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[Vue组件系统之全局组件的注册 123456789101112131415161718192021222324252627&gt;&lt;div id='app'&gt;&gt; &lt;global-component&gt;&lt;/global-component&gt;&gt;&lt;/div&gt;&gt; &gt;&lt;script&gt;&gt; // 注册&gt; Vue.component(&gt; // 第一个是组件名称 第二个object&gt; "global-component", &#123;&gt; // 组件内容 抱一个div-单个根元素&gt; template: `&lt;div&gt;&lt;h3&gt;&#123;&#123; db &#125;&#125;&lt;/h3&gt;&lt;/div&gt;`,&gt; // data必须是函数&gt; data()&#123;&gt; // return中写数据&gt; return &#123;&gt; db: 'hello',&gt; &#125;&gt; &#125;&gt; &#125;&gt; );&gt; &gt; new Vue(&#123;&gt; el: '#app',&gt; // template: `&lt;global-component&gt;&lt;/global-component&gt;`&gt; &#125;)&gt;&lt;/script&gt;&gt; 12345678910111213141516171819202122232425262728&gt;&lt;div id='app'&gt;&gt; &gt;&lt;/div&gt;&gt; &gt;&lt;script&gt;&gt; // 注册组件&gt; Vue.component(&gt; // 第一个是组件名称 第二个object&gt; "global-component", &#123;&gt; // 组件内容 抱一个div-单个根元素，包在app这个div中&gt; template: `&lt;div&gt;&lt;h3&gt;&#123;&#123; db &#125;&#125;&lt;/h3&gt;&lt;/div&gt;`,&gt; // data必须是函数&gt; data()&#123;&gt; // return中写数据&gt; return &#123;&gt; db: 'hello',&gt; &#125;&gt; &#125;&gt; &#125;&gt; );&gt; &gt; new Vue(&#123;&gt; el: '#app',&gt; // 根元素会替换div&gt; template: `&lt;global-component&gt;&lt;/global-component&gt;`&gt; &#125;)&gt;&lt;/script&gt;&gt; 全局组件 12345678910111213141516171819202122232425262728&gt;// 总结&gt;Vue.component(&gt; // 第一个是组件名称 第二个object&gt; "global-component", &#123;&gt; // 组件内容 抱一个div-单个根元素，包在app这个div中&gt; template: `&lt;div&gt;&lt;h3&gt;&#123;&#123; db &#125;&#125;&lt;/h3&gt;&lt;/div&gt;`,&gt; // data必须是函数&gt; data()&#123;&gt; // return中写数据&gt; return &#123;&gt; db: 'hello',&gt; &#125;,&gt; computed: &#123;&#125;,&gt; watch: &#123;&#125;,&gt; methods: &#123;&#125;,&gt; &#125;&gt; &#125;&gt; );&gt;&gt;new Vue(&#123;&gt; el: '#app',&gt; // 根元素会替换div&gt; template: `&lt;global-component&gt;&lt;/global-component&gt;`&gt; &#125;)&gt;&gt;// data 必须是函数&gt;// 没有属性&gt; 组件系统之组件的复用 1234567891011121314151617181920212223242526272829&gt;&lt;div id='app'&gt;&gt; &lt;global-component&gt;&lt;/global-component&gt;&gt; &lt;global-component&gt;&lt;/global-component&gt;&gt; &lt;global-component&gt;&lt;/global-component&gt;&gt;&lt;/div&gt;&gt; &gt;&lt;script&gt;&gt; // 注册&gt; Vue.component(&gt; // 第一个是组件名称 第二个object&gt; "global-component", &#123;&gt; // 组件内容 抱一个div-单个根元素&gt; template: `&lt;div&gt;&lt;h3&gt;&#123;&#123; db &#125;&#125;&lt;/h3&gt;&lt;/div&gt;`,&gt; // data必须是函数&gt; data()&#123;&gt; // return中写数据&gt; return &#123;&gt; db: 'hello',&gt; &#125;&gt; &#125;&gt; &#125;&gt; );&gt; &gt; new Vue(&#123;&gt; el: '#app',&gt; &gt; &#125;)&gt;&lt;/script&gt;&gt; 组价系统之局部组件的注册 12345678910111213141516171819202122232425&gt;&lt;div id='app'&gt;&gt; &lt;app-header&gt;&lt;/app-header&gt;&gt; &gt;&lt;/div&gt;&gt; &gt;&lt;script&gt;&gt; let Header = &#123;&gt; template: `&lt;div&gt;&lt;h3&gt;&#123;&#123; db &#125;&#125;&lt;/h3&gt;&lt;/div&gt;`,&gt; data()&#123;&gt; return &#123;&gt; db: 'hello',&gt; &#125;&gt; &#125;,&gt; computed: &#123;&#125;,&gt; &#125;;&gt; &gt; new Vue(&#123;&gt; el: '#app',&gt; template: `&lt;app-header&gt;&lt;/app-header&gt;`,&gt; components: &#123;&gt; 'app-header': Header&gt; &#125;&gt; &#125;)&gt;&lt;/script&gt;&gt; 12345678910111213141516171819202122232425262728293031323334353637383940&gt;&lt;div id='app'&gt;&gt; &lt;!--&lt;App&gt;&lt;/App&gt;--&gt; &gt;&lt;/div&gt;&gt; &gt;&lt;script&gt;&gt; let Header = &#123;&gt; template: `&lt;div&gt;&lt;h3&gt;&#123;&#123; db &#125;&#125;&lt;/h3&gt;&lt;/div&gt;`,&gt; data()&#123;&gt; return &#123;&gt; db: 'hello',&gt; &#125;&gt; &#125;,&gt; computed: &#123;&#125;,&gt; // ...&gt; &#125;;&gt; // 在入口组件中注册写的局部组件&gt; let App = &#123;&gt; template: `&gt; &lt;div&gt;&gt; &lt;app-header&gt;&lt;/app-header&gt;&gt; &lt;/div&gt;&gt; `,&gt; components: &#123;&gt; 'app-header': Header&gt; &#125;,&gt; // 组件的私有数据&gt; data()&#123;&#125;,&gt; &#125;;&gt; // 根实例&gt; new Vue(&#123;&gt; el: '#app',&gt; // 作为根被渲染&gt; template: `&lt;App&gt;&lt;/App&gt;`,&gt; components: &#123;&gt; // App:App,&gt; App,&gt; &#125;&gt; &#125;)&gt;&lt;/script&gt;&gt; 局部组件 1234567891011121314151617181920212223242526&gt;- 总结&gt;&gt;创建组件&gt; 创建局部组件，起始就是创建一个JavaScript object&gt; let Header = &#123;&gt; template: `&lt;div&gt;&lt;h3&gt;&#123;&#123; db &#125;&#125;&lt;/h3&gt;&lt;/div&gt;`,&gt; data()&#123;&gt; return &#123;&gt; db: 'hello',&gt; &#125;&gt; &#125;,&gt; computed: &#123;&#125;,&gt; &#125;;&gt;注册组件&gt; &gt; new Vue(&#123;&gt; el: '#app',&gt; template: `&lt;app-header&gt;&lt;/app-header&gt;`,&gt; components: &#123;&gt; 'app-header': Header&gt; &#125;&gt; &#125;)&gt;&gt;组件可以嵌套使用&gt;&gt; Vue组件系统之父子组件的通信 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&gt;&lt;div id='app'&gt;&gt; &gt;&lt;/div&gt;&gt; &gt;&lt;script&gt;&gt; // 子&gt; let Header = &#123;&gt; template: `&lt;div&gt;&lt;h3&gt;&#123;&#123; db &#125;&#125;&lt;/h3&gt;&lt;h3&gt;&#123;&#123; fData &#125;&#125;&lt;/h3&gt;&lt;&lt;/div&gt;`,&gt; data()&#123;&gt; return &#123;&gt; db: 'hello',&gt; &#125;&gt; &#125;,&gt; // 接收父亲传来的数据&gt; props:['fData'],&gt; computed: &#123;&#125;,&gt; // ...&gt; &#125;;&gt; // 在入口组件中注册写的局部组件&gt; // 父&gt; let App = &#123;&gt; template: `&gt; &lt;div&gt;&gt; &lt;app-header v-bind:fData="fatherData"&gt;&lt;/app-header&gt;&gt; &lt;/div&gt;&gt; `,&gt; components: &#123;&gt; 'app-header': Header&gt; &#125;,&gt; // 组件的私有数据&gt; data()&#123;&gt; return &#123;fatherData: 0,&#125;&gt; &#125;,&gt; &#125;;&gt; // 根实例&gt; new Vue(&#123;&gt; el: '#app',&gt; // 作为根被渲染&gt; template: `&lt;App&gt;&lt;/App&gt;`,&gt; components: &#123;&gt; // App:App,&gt; App,&gt; &#125;&gt; &#125;)&gt;&lt;/script&gt;&gt; Vue组件系统之子父组件的通信 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&gt;&lt;div id='app'&gt;&gt;&lt;/dic&gt;&gt;&gt;&lt;script&gt;&gt; // 子&gt; let Header = &#123;&gt; template: `&lt;div&gt; &gt; &lt;button @click='sonClick'&gt;点击改变字体大小&lt;/button&gt;&gt; &lt;/div&gt;`,&gt; methods: &#123;&gt; sonClick: function()&#123;&gt; // 儿子的的行为传给父亲&gt; this.$emit("change-size", 0.1)&gt; &#125; &gt; &#125;,&gt; computed: &#123;&#125;,&gt; // ...&gt; &#125;;&gt; // 父&gt; let App = &#123;&gt; template: `&gt; &lt;div&gt;&gt; &lt;span :style="&#123; fontSize: postFontSize + 'em' &#125;"&gt;我是字体&lt;/span&gt;&gt; &lt;app-header v-on:change-size="fatherClick"&gt;&lt;/app-header&gt;&gt; &lt;/div&gt;&gt; `,&gt; components: &#123;&gt; 'app-header': Header&gt; &#125;,&gt; // 组件的私有数据&gt; data()&#123;&gt; return &#123;&gt; postFontSize: 1,&gt; &#125;&gt; &#125;,&gt; methods: &#123;&gt; // 自己定义的change-size事件，一直在监听，等着儿子传来的信息&gt; fatherClick: function(value)&#123;&gt; this.postFontSize += value;&gt; &#125;&gt; &#125;&gt; &#125;;&gt; // 根实例&gt; new Vue(&#123;&gt; el: '#app',&gt; // 作为根被渲染&gt; template: `&lt;App&gt;&lt;/App&gt;`,&gt; components: &#123;&gt; // App:App,&gt; App,&gt; &#125;&gt; &#125;)&gt; &gt;&lt;/script&gt;&gt; Vue组件系统之混入（mixin） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&gt;&lt;div id='app'&gt;&gt;&lt;/dic&gt;&gt; &lt;my-header&gt;&lt;/my-header&gt;&gt; &lt;p&gt;&lt;/p&gt;&gt; &lt;my-app&gt;&lt;/my-app&gt;&gt;&lt;script&gt;&gt; let Header = &#123;&gt; template: `&lt;div&gt; &gt; &lt;button @click='show('xxx')'&gt;点击显示xxx来了&lt;/button&gt;&gt; &lt;button @click='hide('xxx')'&gt;点击显示xxx去了&lt;/button&gt;&gt; &lt;/div&gt;`,&gt; methods: &#123;&gt; show: function(name)&#123;&gt; console.log(name+'来了');&gt; &#125;,&gt; hide: function(name)&#123;&gt; console.log(name+'来了');&gt; &#125;,&gt; &#125;,&gt; &#125;;&gt; let App = &#123;&gt; template: `&gt; &lt;div&gt;&gt; &lt;button @mouseenter='show('000')'&gt;点击显示000来了&lt;/button&gt;&gt; &lt;button @mouseleve='hide('000')'&gt;点击显示000去了&lt;/button&gt;&gt; &lt;/div&gt;&gt; `,&gt; methods: &#123;&gt; show: function(name)&#123;&gt; console.log(name+'来了');&gt; &#125;,&gt; hide: function(name)&#123;&gt; console.log(name+'来了');&gt; &#125;,&gt; &#125;&gt; &#125;;&gt; // 根实例&gt; new Vue(&#123;&gt; el: '#app',&gt; components: &#123;&gt; "my-header": Header,&gt; "my-app": App,&gt; &#125;&gt; &#125;)&gt; &gt;&lt;/script&gt;&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344&gt;&lt;div id='app'&gt;&gt; &lt;my-header&gt;&lt;/my-header&gt;&gt; &lt;p&gt;&lt;/p&gt;&gt; &lt;my-app&gt;&lt;/my-app&gt;&gt;&lt;/dic&gt;&gt;&gt;&lt;script&gt;&gt; let mixs = &#123;&gt; methods:&#123;&gt; show: function(name)&#123;&gt; console.log(name+'来了');&gt; &#125;,&gt; hide: function(name)&#123;&gt; console.log(name+'来了');&gt; &#125;,&gt; &#125;&gt; &#125;&gt; let Header = &#123;&gt; template: `&lt;div&gt; &gt; &lt;button @click='show('xxx')'&gt;点击显示xxx来了&lt;/button&gt;&gt; &lt;button @click='hide('xxx')'&gt;点击显示xxx去了&lt;/button&gt;&gt; &lt;/div&gt;`,&gt; mixins: [mixs],&gt; &#125;;&gt; let App = &#123;&gt; template: `&gt; &lt;div&gt;&gt; &lt;button @mouseenter='show("000")'&gt;点击显示000来了&lt;/button&gt;&gt; &lt;button @mouseleve='hide("000")'&gt;点击显示000去了&lt;/button&gt;&gt; &lt;/div&gt;&gt; `,&gt; mixins: [mixs],&gt; &#125;;&gt; // 根实例&gt; new Vue(&#123;&gt; el: '#app',&gt; components: &#123;&gt; "my-header": Header,&gt; "my-app": App,&gt; &#125;&gt; &#125;)&gt; &gt;&lt;/script&gt;&gt; Vue组件系统之插槽 123456789101112131415161718192021222324252627&gt;- 内容分发&gt;&lt;style&gt;&gt; .box &#123;&gt; width: 50px;&gt; height: 50px;&gt; float: left;&gt; &#125;&gt;&lt;/style&gt;&gt;&lt;div id='app'&gt;&gt; &lt;global-component&gt;首页&lt;/global-component&gt;&gt; &lt;global-component&gt;免费&lt;/global-component&gt;&gt; &lt;global-component&gt;收费&lt;/global-component&gt;&gt;&lt;/div&gt;&gt; &gt;&lt;script&gt;&gt; // 注册全局组件&gt; Vue.component(&gt; "global-component", &#123;&gt; template: `&lt;div class="box"&gt;&lt;slot&gt;&lt;/slot&gt;&lt;/div&gt;`,&gt; &#125;&gt; );&gt; &gt; new Vue(&#123;&gt; el: '#app',&gt; &#125;)&gt;&lt;/script&gt;&gt; Vue组件系统之具名插槽 1234567891011121314151617181920212223242526272829303132&gt;&lt;style&gt;&gt; .box &#123;&gt; width: 50px;&gt; height: 50px;&gt; float: left;&gt; &#125;&gt;&lt;/style&gt;&gt;&lt;div id='app'&gt;&gt; &lt;global-component&gt;&gt; &lt;div slot='home'&gt;首页&lt;/div&gt;&gt; &lt;div slot='free'&gt;免费&lt;/div&gt;&gt; &lt;div slot='toll'&gt;收费&lt;/div&gt;&gt; &lt;/global-component&gt;&gt;&lt;/div&gt;&gt; &gt;&lt;script&gt;&gt; // 注册全局组件&gt; Vue.component(&gt; "global-component", &#123;&gt; template: `&lt;div class="box"&gt;&gt; &lt;slot name="home"&gt;&lt;/slot&gt;&gt; &lt;slot name="free"&gt;&lt;/slot&gt;&gt; &lt;slot name="toll"&gt;&lt;/slot&gt;&gt; &lt;/div&gt;`,&gt; &#125;&gt; );&gt; &gt; new Vue(&#123;&gt; el: '#app',&gt; &#125;)&gt;&lt;/script&gt;&gt;]]></content>
      <categories>
        <category>Vue</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[docker命令]]></title>
    <url>%2F2018%2F10%2F12%2Fdocker%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[使用镜像获取镜像docker pull [选项] [Docker Registry地址]&lt;仓库名&gt;:&lt;标签&gt; $ docker pull ubuntu:14.04 运行镜像$ docker run -it --rm ubuntu:14.04 bash -i 交互式操作 -t 终端 --rm 容器退出后随之将其删除 ubuntu:14.04:这是指用 ubuntu:14.04 镜像为基础来启动容器。 bash:放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是。 列出镜像docker images 虚悬镜像$ docker images -f dangling=true 一般来说，虚悬镜像已经失去了存在的价值，是可以随意删除的，可以用下面的命令删除。 $ docker rmi $(docker images -q -f dangling=true) 中间层镜像$ docker images -a 列出部分镜像$ docker images ubuntu $ docker images ubuntu:16.04 $ docker images -f since=mongo:3.2 （-f filter） $ docker images -f label=com.example.version=0.1 以特定格式显示$ docker images -q $ docker images --format &quot;{{.ID}}: {{.Repository}}&quot; $ docker images --format &quot;table {{.ID}}\t{{.Repository}}\t{{.Tag}}&quot; docker save 和 docker load比如我们希望保存这个 alpine 镜像 $ docker save alpine | gzip &gt; alpine-latest.tar.gz $ docker load -i alpine-latest.tar.gz 删除本地镜像docker rmi [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...] 操作容器启动容器启动容器有两种方式，一种是基于镜像新建一个容器并启动，另外一个是将在终止 状态(stopped)的容器重新启动。 因为 Docker 的容器实在太轻量级了，很多时候用户都是随时删除和新创建容器。 新建并启动当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括: 检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 $ sudo docker run ubuntu:14.04 /bin/echo &apos;Hello world&apos; $ sudo docker run -t -i ubuntu:14.04 /bin/bash 启动已经终止容器docker start 后台（background）运行-d 参数 $ sudo docker run -d ubuntu:14.04 /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot; 进入容器$ sudo docker run -idt ubuntu 243c32535da7d142fb0e6df616a3c3ada0b8ab417937c853a9e1c251f499f550 $ sudo docker ps CONTAINER ID TED 243c32535da7 econds ago c_hypatia $sudo docker attach nostalgic_hypatia root@243c32535da7:/# 但是使用 attach 命令有时候并不方便。当多个窗口同时 attach 到同一个容器的 时候， 所有窗口都会同步显示。当某个窗口因命令阻塞时,其他窗口也无法执行操作 了。 导出和导入容器 导出容器导出容器 $ sudo docker export 7691a814370e &gt; ubuntu.tar 导入容器快照 $ cat ubuntu.tar | sudo docker import - test/ubuntu:v1.0 此外，也可以通过指定 URL 或者某个目录来导入，例如 $sudo docker import http://example.com/exampleimage.tgz example/imagerepo *注:用户既可以使用 来导入镜像存储文件到本地镜像库，也可以 使用 来导入一个容器快照到本地镜像库。 这两者的区别在于容 器快照文件将丢弃所有的历史记录和元数据信息(即仅保存容器当时的快照状 态)， 而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入 时可以重新指定标签等元数据信息。 删除容器$sudo docker rm trusting_newton 清理所有处于终止状态的容器$ docker rm `docker ps -a -q` 访问仓库登录可以通过执行 docker login 命令来输入用户名、密码和邮箱来完成注册和登录。 注册成功后，本地用户目录的 .dockercfg 中将保存用户的认证信息。 基本操作用户无需登录即可通过 docker search 命令来查找官方仓库中的镜像， 并利用 docker pull 命令来将它下载到本地。 自动创建自动创建(Automated Builds)功能对于需要经常升级镜像内程序来说，十分方 便。 有时候，用户创建了镜像，安装了某个软件，如果软件发布新版本则需要手动 更新镜像。。 而自动创建允许用户通过 Docker Hub 指定跟踪一个目标网站(目前支持 GitHub 或 BitBucket) 上的项目，一旦项目发生新的提交，则自动执行创建。 要配置自动创建，包括如下的步骤: 创建并登录 Docker Hub，以及目标网站; 在目标网站中连接帐户到 Docker Hub; 在 Docker Hub 中 配置一个自动创建; 选取一个目标网站中的项目(需要含 Dockerfile)和分支; 指定 Dockerfile 的位置，并提交创建。 之后，可以 在Docker Hub 的 自动创建页面 中跟踪每次创建的状态。 数据管理使用网络高级网络配置]]></content>
      <categories>
        <category>docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[权限管理的三级菜单的流程]]></title>
    <url>%2F2018%2F08%2F14%2F%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%BB%84%E4%BB%B6%E6%B5%81%E7%A8%8B%E5%A4%A7%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[权限管理的三级菜单的流程 权限控制 url代表了权限 表结构（6张表，ORM创建4个类，两个many2many会自动再生成两张表） 1234567891011121314151617181920&gt; 用户表&gt; 用户名&gt; 密码&gt; 多对多 roles(角色)&gt; 角色表&gt; 标题 title&gt; 多对多 permission(权限)&gt; 权限表&gt; 标题 title&gt; 权限 url&gt; URL别名 name - 设置唯一(方便为了将权限粒度控制到按钮级别)&gt; 外键 menu(菜单)&gt; 外键 permission(self自己)&gt; 菜单表&gt; 标题 title&gt; 图标 icon&gt; 权重 weight&gt; 用户和角色关系表&gt; 角色和权限的关系表&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&gt; &gt;from django.db import models&gt; &gt;&gt; &gt;&gt; &gt;class Menu(models.Model):&gt; &gt; &quot;&quot;&quot;&gt; &gt; 一级菜单&gt; &gt; &quot;&quot;&quot;&gt; &gt; title = models.CharField(max_length=32, verbose_name=&apos;标题&apos;, unique=True) # 一级菜单的名字&gt; &gt; icon = models.CharField(max_length=32, verbose_name=&apos;图标&apos;, null=True, blank=True)&gt; &gt; weight = models.IntegerField(verbose_name=&apos;权重&apos;, default=1)&gt; &gt;&gt; &gt; class Meta:&gt; &gt; verbose_name_plural = &apos;菜单表&apos;&gt; &gt; verbose_name = &apos;菜单表&apos;&gt; &gt;&gt; &gt; def __str__(self):&gt; &gt; return self.title&gt; &gt;&gt; &gt;&gt; &gt;class Permission(models.Model):&gt; &gt; &quot;&quot;&quot;&gt; &gt; 权限表&gt; &gt; 有关联Menu的二级菜单&gt; &gt; 没有关联Menu的不是二级菜单，是不可以做菜单的权限&gt; &gt; &quot;&quot;&quot;&gt; &gt; title = models.CharField(max_length=32, verbose_name=&apos;标题&apos;)&gt; &gt; url = models.CharField(max_length=32, verbose_name=&apos;权限&apos;)&gt; &gt; menu = models.ForeignKey(&apos;Menu&apos;, null=True, blank=True, verbose_name=&apos;菜单&apos;)&gt; &gt; # 该权限关联的其他权限是否也是在当前url上展示&gt; &gt; parent = models.ForeignKey(to=&apos;Permission&apos;, null=True, blank=True, verbose_name=&apos;父权限&apos;)&gt; &gt;&gt; &gt; name = models.CharField(max_length=32, null=True, blank=True, unique=True, verbose_name=&apos;权限的别名&apos;)&gt; &gt;&gt; &gt; class Meta:&gt; &gt; verbose_name_plural = &apos;权限表&apos;&gt; &gt; verbose_name = &apos;权限表&apos;&gt; &gt;&gt; &gt; def __str__(self):&gt; &gt; return self.title&gt; &gt;&gt; &gt;&gt; &gt;class Role(models.Model):&gt; &gt; name = models.CharField(max_length=32, verbose_name=&apos;角色名称&apos;)&gt; &gt; permissions = models.ManyToManyField(to=&apos;Permission&apos;, verbose_name=&apos;角色所拥有的权限&apos;, blank=True)&gt; &gt;&gt; &gt; def __str__(self):&gt; &gt; return self.name&gt; &gt;&gt; &gt;&gt; &gt;class User(models.Model):&gt; &gt; &quot;&quot;&quot;&gt; &gt; 用户表&gt; &gt; &quot;&quot;&quot;&gt; &gt; name = models.CharField(max_length=32, verbose_name=&apos;用户名&apos;)&gt; &gt; password = models.CharField(max_length=32, verbose_name=&apos;密码&apos;)&gt; &gt; roles = models.ManyToManyField(to=&apos;Role&apos;, verbose_name=&apos;用户所拥有的角色&apos;, blank=True)&gt; &gt;&gt; &gt; def __str__(self):&gt; &gt; return self.name&gt; &gt;&gt; &gt; 流程梳理 12345678910111213&gt; - 当一个url回车发出这个请求后，给到server端先判断这个请求url是不是有访问的权限&gt; 这个时候我们设置了白名单(在中间件这里(因为一开始就要判断身份))，如果是白名单&gt; 谁都可以访问&gt; eg：&gt; PERMISSION_SESSION_KEY = &apos;permissions&apos;&gt; MENU_SESSION_KEY = &apos;menus&apos;&gt; WHITE_URL_LIST = [&gt; r&apos;^/login/$&apos;,&gt; r&apos;^/logout/$&apos;,&gt; r&apos;^/reg/$&apos;,&gt; r&apos;^/admin/.*&apos;,&gt; ]&gt; 123&gt; - 这时用户登录，如果登录成功&gt; 不同的用户对应不同的权限，也就是可以访问不同的url&gt; 1234567891011121314151617181920212223242526272829303132&gt; - 登录成功，(权限信息的初始化)&gt; 我们该做的就是拿到这个用户对应的权限信息 - ORM(用户信息-角色-权限-菜单)&gt; # user = models.User.objects.filter(name=username, password=pwd).first()&gt; permission_query = user.roles.filter(permissions__url__isnull=False).values(&gt; &apos;permissions__url&apos;, # 权限url&gt; &apos;permissions__title&apos;, # 权限的标题&gt; &apos;permissions__id&apos;, # 权限的id&gt; &apos;permissions__name&apos;, # 权限的别名&gt; &apos;permissions__parent_id&apos;, # 此权限对应的父权限的id&gt; &apos;permissions__parent__name&apos;, # 次权限对应的父权限的别名&gt; &apos;permissions__menu_id&apos;, # 此权限对应的菜单id&gt; &apos;permissions__menu__title&apos;, # 此权限对应的菜单标题&gt; &apos;permissions__menu__icon&apos;, # 此权限对应的菜单的图标&gt; &apos;permissions__menu__weight&apos;, # 表单排序用的&gt; ).distinct()&gt; 数据结构(字典)&gt; permission_dict来存储此权限信息&gt; menu_dict来存储菜单信息&gt; permission_dict = &#123;&gt; &apos;URL的别名&apos;：&#123;&apos;url&apos;,&apos;title&apos;,&apos;id&apos;,&apos;pid&apos;,&apos;pname&apos; &#125;&gt; &#125;&gt; menu_list = &#123;&gt; &apos;菜单ID&apos;：&#123;&gt; &apos;title&apos;: 一级菜单的标题，&gt; &apos;icon&apos;: 一级菜单的图标，&gt; &apos;weight&apos;: 权重，&gt; &apos;children&apos;: [&gt; &#123;&apos;url&apos;,&apos;title&apos;,&apos;id&apos;,&#125;&gt; ]&gt; &#125;&gt; &#125;&gt; 123456789&gt; 权限信息存的就是：&gt; 当前这个权限的是谁，他的id多少，他的标题是什么，他的父权限是谁(id)，他的父权限的别名是什么&gt; 菜单信息存的就是：&gt; 这个权限(url)对应的菜单的标题是什么，菜单的图标是什么，权重是多少，他对应的二级菜单是哪些&gt; 二级菜单(children)也就是，对应的权限信息&gt; 这里面存的也就是他的权限信息(他的title，url，id，parent_id)&gt; 将所有的权限遍历一遍后，将这些信息存入session中&gt; 为什么存入session，是因为session可以配置(放入缓存，访问次数比较多，所有存到缓存比较好)&gt; 123456789101112131415161718192021222324252627282930313233343536&gt; # 遍历此用户对应的权限信息&gt; for item in permission_query:&gt; # 首先是权限信息，以权限的别名为键&gt; permission_dict[item[&apos;permissions__name&apos;]] = (&#123;&gt; &apos;url&apos;: item[&apos;permissions__url&apos;],&gt; &apos;id&apos;: item[&apos;permissions__id&apos;],&gt; &apos;parent_id&apos;: item[&apos;permissions__parent_id&apos;],&gt; &apos;parent_name&apos;: item[&apos;permissions__parent__name&apos;],&gt; &apos;title&apos;: item[&apos;permissions__title&apos;],&gt; &#125;)&gt; menu_id = item.get(&apos;permissions__menu_id&apos;)&gt; if not menu_id:&gt; continue&gt; if menu_id not in menu_dict:&gt; menu_dict[menu_id] = &#123;&gt; &apos;title&apos;: item[&apos;permissions__menu__title&apos;],&gt; &apos;icon&apos;: item[&apos;permissions__menu__icon&apos;],&gt; &apos;weight&apos;: item[&apos;permissions__menu__weight&apos;],&gt; &apos;children&apos;: [&gt; &#123;&gt; &apos;title&apos;: item[&apos;permissions__title&apos;],&gt; &apos;url&apos;: item[&apos;permissions__url&apos;],&gt; &apos;id&apos;: item[&apos;permissions__id&apos;],&gt; &apos;parent_id&apos;: item[&apos;permissions__parent_id&apos;],&gt; &#125;&gt; ]&gt; &#125;&gt; else:&gt; menu_dict[menu_id][&apos;children&apos;].append(&gt; &#123;&gt; &apos;title&apos;: item[&apos;permissions__title&apos;],&gt; &apos;url&apos;: item[&apos;permissions__url&apos;],&gt; &apos;id&apos;: item[&apos;permissions__id&apos;],&gt; &apos;parent_id&apos;: item[&apos;permissions__parent_id&apos;],&gt; &#125;)&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&gt; - 登录成功后，信息存入session后，这时给服务器发送一个请求，这时就会走中间件进行权限的校验&gt; &gt; - 走中间件process_request(self, request):&gt; - 先获取这个请求的url request.path_info&gt; 刚开始也先判断白名单， 白名单不符合从session中获取这个用户存的权限信息&gt; permission_dict = request.session.get(settings.PERMISSION_SESSION_KEY)&gt; - 导航栏可以存这里 - 写了一个inclution_tag来处理&gt; request.breadcrumd_list = [&gt; &#123;&quot;title&quot;: &apos;首页&apos;, &apos;url&apos;: &apos;#&apos;&#125;,&gt; ]&gt; @register.inclusion_tag(&apos;rbac/breadcrumbs.html&apos;)&gt; def breadcrumb(request):&gt; return &#123;&quot;breadcrumd_list&quot;: request.breadcrumd_list&#125;&gt; - 遍历这个权限信息&gt; 可以通过正则匹配，匹配他是不是该用户的权限&gt; 如果匹配成功看他是否由parent_id有是子权限没有是父权限&gt; &gt; if parent_id:&gt; # 表示当前权限是子权限，让父权限是展开&gt; request.current_menu_id = parent_id&gt; request.breadcrumd_list.extend([&gt; &#123;&gt; &quot;title&quot;: permission_dict[parent_name][&apos;title&apos;],&gt; &apos;url&apos;: permission_dict[parent_name][&apos;url&apos;]&gt; &#125;,&gt; &#123;&quot;title&quot;: item[&apos;title&apos;], &apos;url&apos;: item[&apos;url&apos;]&#125;,&gt; ])&gt; else:&gt; # 表示当前权限是父权限，要展开的二级菜单&gt; request.current_menu_id = id&gt; # 添加面包屑导航&gt; request.breadcrumd_list.append(&#123;&gt; &quot;title&quot;: item[&apos;title&apos;], &gt; &apos;url&apos;: item[&apos;url&apos;]&gt; &#125;)&gt; &gt; - request.current_menu_id&gt; 这个就是用来展示菜单和展示该权限的子权限为了选中同一个二级菜单的时候用的&gt; -写一个includtion_tag&gt; - &gt; @register.inclusion_tag(&apos;rbac/menu.html&apos;)&gt; def menu(request):&gt; menu_list = request.session.get(settings.MENU_SESSION_KEY)&gt; order_dict = OrderedDict()&gt; for key in sorted(menu_list, key=lambda x: menu_list[x][&apos;weight&apos;], reverse=True):&gt; order_dict[key] = menu_list[key]&gt; item = order_dict[key]&gt; item[&apos;class&apos;] = &apos;hide&apos;&gt; &gt; for i in item[&apos;children&apos;]:&gt; &gt; if i[&apos;id&apos;] == request.current_menu_id:&gt; i[&apos;class&apos;] = &apos;active&apos;&gt; item[&apos;class&apos;] = &apos;&apos;&gt; return &#123;&quot;menu_list&quot;: order_dict&#125;&gt; &gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&gt; from django.utils.deprecation import MiddlewareMixin&gt; from django.conf import settings&gt; from django.shortcuts import HttpResponse&gt; import re&gt; &gt; &gt; class PermissionMiddleware(MiddlewareMixin):&gt; def process_request(self, request):&gt; # 对权限进行校验&gt; # 1. 当前访问的URL&gt; current_url = request.path_info&gt; &gt; # 白名单的判断&gt; for i in settings.WHITE_URL_LIST:&gt; if re.match(i, current_url):&gt; return&gt; &gt; # 2. 获取当前用户的所有权限信息&gt; &gt; permission_dict = request.session.get(settings.PERMISSION_SESSION_KEY)&gt; &gt; request.breadcrumd_list = [&gt; &#123;&quot;title&quot;: &apos;首页&apos;, &apos;url&apos;: &apos;#&apos;&#125;,&gt; ]&gt; &gt; # 3. 权限的校验&gt; print(current_url)&gt; &gt; for item in permission_dict.values():&gt; print(permission_dict)&gt; url = item[&apos;url&apos;]&gt; if re.match(&quot;^&#123;&#125;$&quot;.format(url), current_url):&gt; parent_id = item[&apos;parent_id&apos;]&gt; id = item[&apos;id&apos;]&gt; parent_name = item[&apos;parent_name&apos;]&gt; if parent_id:&gt; # 表示当前权限是子权限，让父权限是展开&gt; request.current_menu_id = parent_id&gt; request.breadcrumd_list.extend([&gt; &#123;&quot;title&quot;: permission_dict[parent_name][&apos;title&apos;],&gt; &apos;url&apos;: permission_dict[parent_name][&apos;url&apos;]&#125;,&gt; &#123;&quot;title&quot;: item[&apos;title&apos;], &apos;url&apos;: item[&apos;url&apos;]&#125;,&gt; ])&gt; else:&gt; # 表示当前权限是父权限，要展开的二级菜单&gt; request.current_menu_id = id&gt; # 添加面包屑导航&gt; request.breadcrumd_list.append(&#123;&quot;title&quot;: item[&apos;title&apos;], &apos;url&apos;: item[&apos;url&apos;]&#125;)&gt; return&gt; else:&gt; return HttpResponse(&apos;没有权限&apos;)&gt; &gt; 123456789&gt; - 权限力度控制到按钮级别&gt; 一个filter&gt; 一个url的反向解析&gt; @register.filter&gt; def has_permission(request, permission):&gt; # session中存的就是权限的别名，别名就是反向解析的那个字符串&gt; if permission in request.session.get(settings.PERMISSION_SESSION_KEY):&gt; return True&gt; 12345678910&gt; &#123;% if request|has_permission:&apos;web:customer_edit&apos; or request|has_permission:&apos;web:customer_del&apos; %&#125;&gt; &lt;td&gt;&gt; &#123;% if request|has_permission:&apos;web:customer_edit&apos; %&#125;&gt; &lt;a style=&quot;color: #333333;&quot; href=&quot;&#123;% url &apos;web:customer_edit&apos; row.id %&#125;&quot;&gt;&gt; &lt;i class=&quot;fa fa-edit&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/a&gt;&gt; &#123;% endif %&#125;&gt; &#123;% if request|has_permission:&apos;web:customer_del&apos; %&#125;&gt; &lt;a style=&quot;color: #d9534f;&quot; href=&quot;&#123;% url &apos;web:customer_del&apos; row.id %&#125;&quot;&gt;&lt;i class=&quot;fa fa-trash-o&quot;&gt;&lt;/i&gt;&lt;/a&gt;&gt; &#123;% endif %&#125;&gt; 菜单和权限的展示在一个页面 123456789101112131415161718192021222324252627282930313233343536&gt;# 菜单和权限的展示&gt;# 点击每一个菜单出现对应的权限信息&gt;def menu_list(request):&gt; all_menu = models.Menu.objects.all()&gt; # 拿到菜单对应的菜单id&gt; mid = request.GET.get('mid')&gt; # 如果拿到菜单id代表着有子权限&gt; if mid:&gt; # 从子权限出发 拿到 父权限对应的菜单id对应的权限 或者 菜单对应的权限（也就是二级菜单） 因为自己关联自己（从父亲和儿子两方面出发）&gt; permission_query = models.Permission.objects.filter(Q(menu_id=mid) | Q(parent__menu_id=mid))&gt; # 如果没有菜单id则输出所有的权限信息&gt; else:&gt; permission_query = models.Permission.objects.all()&gt; # 拿到查询出的权限对应的信息&gt; all_permission = permission_query.values('id', 'url', 'title', 'name', 'menu_id', 'parent_id', 'menu__title')&gt; all_permission_dict = &#123;&#125;&gt; for item in all_permission:&gt; menu_id = item.get('menu_id')&gt; # 找到有菜单id的权限，将其存入字典，键为权限的id&gt; if menu_id:&gt; all_permission_dict[item['id']] = item&gt; # 可以改都是引用&gt; # 得到所有有菜单的权限后，将每一个权限都设置一个children键值对，用来存储子权限信息&gt; item['children'] = []&gt; for item in all_permission:&gt; pid = item.get('parent_id')&gt; # 如果有父id代表的是子权限&gt; if pid:&gt; # 如果是子权限，就将子权限的信息存入多上一步做的处理（有菜单的父权限）children中&gt; all_permission_dict[pid]['children'].append(item)&gt; return render(request, 'rbac/menu_list.html', &#123;&gt; "mid": mid,&gt; "all_menu": all_menu,&gt; "all_permission_dict": all_permission_dict,&gt; &#125;)&gt; 权限系统的应用 拷贝rbac App到新项目中 注册APP 以及配置信息 12345678910&gt; # ###### 权限相关的配置 ######&gt; PERMISSION_SESSION_KEY = &apos;permissions&apos;&gt; MENU_SESSION_KEY = &apos;menus&apos;&gt; WHITE_URL_LIST = [&gt; r&apos;^/login/$&apos;,&gt; r&apos;^/logout/$&apos;,&gt; r&apos;^/reg/$&apos;,&gt; r&apos;^/admin/.*&apos;,&gt; ]&gt; 数据库迁移命令 删除rbac所有的迁移文件 执行两条命令 路由相关 url(r’rbac/‘,include(‘rbac.urls’,namespace=’rbac’)) 给所有的URL起名字 layout 模板注意 block css js content 权限的管理 添加角色 添加菜单 添加权限 分配权限 用户关联—修改原系统的用户表 跟rbac的UserInfouser = models.OneToOneField(UserInfo,null=True,blank=True) 给用户分角色 给角色分权限 登录应用权限 登录成功后 12345&gt; auth.login(request, obj)&gt; ret = init_permission(request, obj)&gt; if ret:&gt; return ret&gt; 初始化权限信息init_permission函数中修改 user -&gt; user.user permission_query = user.user.roles.filter 应用权限校验中间件 12&gt; &apos;rbac.middleware.rbac.PermissionMiddleware&apos;,&gt; 应用左侧菜单和面包屑导航 在layout模板中，引用CSS和JS 二级菜单 123&gt; &#123;% load rbac %&#125;&gt; &#123;% menu request %&#125;&gt; 应用路径导航 12&gt; &#123;% breadcrumb request %&#125;&gt; 权限控制到按钮级别 12345678&gt; &#123;% load rbac %&#125;&gt; 判断 filter 判断里面只能用filter 只能一个一个判断&gt; &#123;% load rbac %&#125;&gt; &gt; &#123;% if request|has_permission:&apos;add_customer&apos; %&#125;&gt; &lt;a href=&quot;&#123;% url &apos;add_customer&apos; %&#125;?&#123;&#123; query_params &#125;&#125;&quot; class=&quot;btn btn-primary btn-sm&quot;&gt;添加&lt;/a&gt;&gt; &#123;% endif %&#125;&gt; 使用注意事项 用户注册后 对应在rbac中的UserInfo创建用户 和 原系统的用户做一对一关联 菜单 父权限 子权限 的层级关系]]></content>
      <categories>
        <category>RBAC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django之中间件]]></title>
    <url>%2F2018%2F07%2F15%2FDjango%E4%B9%8B%E4%B8%AD%E9%97%B4%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[中间件 中间件的概念 中间件顾名思义，是介于request与response处理之间的一道处理过程，相对比较轻量级，并且在全局 上改变django的输入与输出。因为改变的是全局，所以需要谨慎实用，用不好会影响到性能。 Django的中间件的定义： Middleware is` `a framework of hooks into Django’s request/response processing. &lt;br&gt;It’s a light, low-level “plugin” systemforglobally altering Django’s input or output. 应用： 如果想修改请求，例如被传送到view中的HttpRequest对象。 或者想修改view返回的HttpResponse对象，这些都可以通过中间件来实现。 可能还想在view执行之前做一些操作，这种情况就可以用 middleware来实现。 我们可能频繁在view使用request.user吧。 Django想在每个view执行之前把user设置request 的属性，于是就用了一个中间件来实现这个目标。所以Django提供了可以修改request 对象的中间 件 AuthenticationMiddleware。 Django默认的Middleware： 12345678910&gt; MIDDLEWARE = [&gt; 'django.middleware.security.SecurityMiddleware',&gt; 'django.contrib.sessions.middleware.SessionMiddleware',&gt; 'django.middleware.common.CommonMiddleware',&gt; 'django.middleware.csrf.CsrfViewMiddleware',&gt; 'django.contrib.auth.middleware.AuthenticationMiddleware',&gt; 'django.contrib.messages.middleware.MessageMiddleware',&gt; 'django.middleware.clickjacking.XFrameOptionsMiddleware',&gt; ]&gt; 每一个中间件都有具体的功能 自定义中间件 中间件一共有四种方法 12345678&gt; # process_request&gt; &gt; # process_view&gt; &gt; # process_exception&gt; &gt; # process_response&gt; process_request,process_response 当用户发起请求的时候会依次经过所有的的中间件，这个时候的请求时process_request,最后到达views的函数中，views函数处理后，在依次穿过中间件，这个时候是process_response,最后返回给请求者。 我们也可以自己定义一个中间件，我们可以自己写一个类，但是必须继承MiddlewareMixin 需要导入 12&gt; &gt; from django.utils.deprecation import MiddlewareMixin&gt; &gt; in views: 12345&gt; &gt; &gt;def index(request):&gt; &gt; &gt;&gt; &gt; &gt; print("view函数...")&gt; &gt; &gt; return HttpResponse("OK")&gt; &gt; &gt; in Mymiddlewares.py： 123456789101112131415161718192021&gt; &gt; &gt;from django.utils.deprecation import MiddlewareMixin&gt; &gt; &gt;from django.shortcuts import HttpResponse&gt; &gt; &gt;&gt; &gt; &gt;class Md1(MiddlewareMixin):&gt; &gt; &gt;&gt; &gt; &gt; def process_request(self,request):&gt; &gt; &gt; print("Md1请求")&gt; &gt; &gt; &gt; &gt; &gt; def process_response(self,request,response):&gt; &gt; &gt; print("Md1返回")&gt; &gt; &gt; return response&gt; &gt; &gt;&gt; &gt; &gt;class Md2(MiddlewareMixin):&gt; &gt; &gt;&gt; &gt; &gt; def process_request(self,request):&gt; &gt; &gt; print("Md2请求")&gt; &gt; &gt; #return HttpResponse("Md2中断")&gt; &gt; &gt; def process_response(self,request,response):&gt; &gt; &gt; print("Md2返回")&gt; &gt; &gt; return response&gt; &gt; &gt; 结果： 123456&gt; &gt; &gt;Md1请求&gt; &gt; &gt;Md2请求&gt; &gt; &gt;view函数...&gt; &gt; &gt;Md2返回&gt; &gt; &gt;Md1返回&gt; &gt; &gt; 注意：如果当请求到达请求2的时候直接不符合条件返回，即return HttpResponse(“Md2中断”)，程序将把请求直接发给中间件2返回，然后依次返回到请求者，结果如下： 返回Md2中断的页面，后台打印如下： 12345&gt; &gt; &gt;Md1请求&gt; &gt; &gt;Md2请求&gt; &gt; &gt;Md2返回&gt; &gt; &gt;Md1返回&gt; &gt; &gt; 流程图如下： process_view 12&gt; &gt;process_view(self, request, callback, callback_args, callback_kwargs)&gt; &gt; Mymiddlewares.py修改如下 123456789101112131415161718192021222324252627&gt; &gt;from django.utils.deprecation import MiddlewareMixin&gt; &gt;from django.shortcuts import HttpResponse&gt; &gt;&gt; &gt;class Md1(MiddlewareMixin):&gt; &gt;&gt; &gt; def process_request(self,request):&gt; &gt; print("Md1请求")&gt; &gt; #return HttpResponse("Md1中断")&gt; &gt; def process_response(self,request,response):&gt; &gt; print("Md1返回")&gt; &gt; return response&gt; &gt;&gt; &gt; def process_view(self, request, callback, callback_args, callback_kwargs):&gt; &gt; print("Md1view")&gt; &gt;&gt; &gt;class Md2(MiddlewareMixin):&gt; &gt;&gt; &gt; def process_request(self,request):&gt; &gt; print("Md2请求")&gt; &gt; return HttpResponse("Md2中断")&gt; &gt; def process_response(self,request,response):&gt; &gt; print("Md2返回")&gt; &gt; return response&gt; &gt;&gt; &gt; def process_view(self, request, callback, callback_args, callback_kwargs):&gt; &gt; print("Md2view")&gt; &gt; 结果如下： 12345678&gt; &gt;Md1请求&gt; &gt;Md2请求&gt; &gt;Md1view&gt; &gt;Md2view&gt; &gt;view函数...&gt; &gt;Md2返回&gt; &gt;Md1返回&gt; &gt; 下图进行分析上面的过程： 当最后一个中间的process_request到达路由关系映射之后，返回到中间件1的process_view，然后 依次往下，到达views函数，最后通过process_response依次返回到达用户。 process_view可以用来调用视图函数： 12345678910111213141516&gt; &gt;class Md1(MiddlewareMixin):&gt; &gt;&gt; &gt; def process_request(self,request):&gt; &gt; print("Md1请求")&gt; &gt; #return HttpResponse("Md1中断")&gt; &gt; def process_response(self,request,response):&gt; &gt; print("Md1返回")&gt; &gt; return response&gt; &gt;&gt; &gt; def process_view(self, request, callback, callback_args, callback_kwargs):&gt; &gt;&gt; &gt; # return HttpResponse("hello")&gt; &gt;&gt; &gt; response=callback(request,*callback_args,**callback_kwargs)&gt; &gt; return response&gt; &gt; 结果如下： 123456&gt; &gt;Md1请求&gt; &gt;Md2请求&gt; &gt;view函数...&gt; &gt;Md2返回&gt; &gt;Md1返回&gt; &gt; 注意：process_view如果有返回值，会越过其他的process_view以及视图函数，但是所有的 process_response都还会执行。 process_exception 12&gt; &gt;process_exception(self, request, exception)&gt; &gt; 示例修改如下： 123456789101112131415161718192021222324252627282930313233343536&gt; &gt;class Md1(MiddlewareMixin):&gt; &gt;&gt; &gt; def process_request(self,request):&gt; &gt; print("Md1请求")&gt; &gt; #return HttpResponse("Md1中断")&gt; &gt; def process_response(self,request,response):&gt; &gt; print("Md1返回")&gt; &gt; return response&gt; &gt;&gt; &gt; def process_view(self, request, callback, callback_args, callback_kwargs):&gt; &gt;&gt; &gt; # return HttpResponse("hello")&gt; &gt;&gt; &gt; # response=callback(request,*callback_args,**callback_kwargs)&gt; &gt; # return response&gt; &gt; print("md1 process_view...")&gt; &gt;&gt; &gt; def process_exception(self):&gt; &gt; print("md1 process_exception...")&gt; &gt;&gt; &gt;&gt; &gt;&gt; &gt;class Md2(MiddlewareMixin):&gt; &gt;&gt; &gt; def process_request(self,request):&gt; &gt; print("Md2请求")&gt; &gt; # return HttpResponse("Md2中断")&gt; &gt; def process_response(self,request,response):&gt; &gt; print("Md2返回")&gt; &gt; return response&gt; &gt; def process_view(self, request, callback, callback_args, callback_kwargs):&gt; &gt; print("md2 process_view...")&gt; &gt;&gt; &gt; def process_exception(self):&gt; &gt; print("md1 process_exception...")&gt; &gt; 结果如下： 123456789&gt; &gt;Md1请求&gt; &gt;Md2请求&gt; &gt;md1 process_view...&gt; &gt;md2 process_view...&gt; &gt;view函数...&gt; &gt;&gt; &gt;Md2返回&gt; &gt;Md1返回&gt; &gt; 流程图如下： 当views出现错误时： 将md2的process_exception修改如下： 12345&gt; &gt; def process_exception(self,request,exception):&gt; &gt;&gt; &gt; print("md2 process_exception...")&gt; &gt; return HttpResponse("error")&gt; &gt; 结果如下： 123456789&gt; &gt;Md1请求&gt; &gt;Md2请求&gt; &gt;md1 process_view...&gt; &gt;md2 process_view...&gt; &gt;view函数...&gt; &gt;md2 process_exception...&gt; &gt;Md2返回&gt; &gt;Md1返回&gt; &gt;]]></content>
      <categories>
        <category>Django</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python之Linux下的virtualenv&&virtualenvwrapper]]></title>
    <url>%2F2018%2F06%2F03%2FPython%E4%B9%8BLinux%E4%B8%8B%E7%9A%84virtualenv-virtualenvwrapper%2F</url>
    <content type="text"><![CDATA[virtualenv 可以在系统中建立多个不同并且相互不干扰的虚拟环境。 #指定清华源下载pip的包 pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple virtualenv #升级pip工具 pip3 install --upgrade pip 一、Linux下安装、配置、使用virtualenv1.安装virtualenv pip3 install virtualenv 2.创建目录 mkdir Myproject cd Myproject 3.创建独立运行环境-命名 virtualenv --no-site-packages --python=python3 venv#得到独立第三方包的环境，并且指定解释器是python3 4.进入虚拟环境 source venv/bin/activate#此时进入虚拟环境(venv)Myproject 5.安装第三方包 (venv)Myproject: pip3 install django==1.9.8 #此时pip的包都会安装到venv环境下，venv是针对Myproject创建的 6.退出venv环境 deactivate命令 7.virtualenv是如何创建“独立”的Python运行环境的呢？ 原理很简单，就是把系统Python复制一份到virtualenv的环境， 用命令source venv/bin/activate进入一个virtualenv环境时， virtualenv会修改相关环境变量， 让命令python和pip均指向当前的virtualenv环境。 二、确保开发环境的一致性1.假设我们在本地开发环境，准备好了项目+依赖包环境 2.现在需要将项目上传至服务器，上线发布 3.那么就要保证服务器的python环境一致性 解决方案： 1.通过命令保证环境的一致性，导出当前python环境的包 pip3 freeze &gt; requirements.txt 这将会创建一个 requirements.txt 文件，其中包含了当前环境中所有包及 各自的版本的简单列表。 可以使用 “pip list”在不产生requirements文件的情况下， 查看已安装包的列表。 2.上传至服务器后，在服务器下创建virtualenv，在venv中导入项目所需的模块依赖 pip3 install -r requirements.txt 三、虚拟环境之virtualenvwrappervirtualenv 的一个最大的缺点就是： 每次开启虚拟环境之前要去虚拟环境所在目录下的 bin 目录下 source 一下 activate，这就需要我们记住每个虚拟环境所在的目录。 并且还有可能你忘记了虚拟环境放在哪。。。 一种可行的解决方案是，将所有的虚拟环境目录全都集中起来，例如/opt/all_venv/，并且针对不同的目录做不同的事。 使用virtualenvwrapper管理你的虚拟环境（virtualenv），其实他就是统一管理虚拟环境的目录，并且省去了source的步骤。 步骤1：安装virtualenvwrapperpip3 install virtualenvwrapper 步骤2：设置Linux的环境变量，每次启动就加载virtualenvwrapper把下面两行代码添加到 ~/.bashrc文件中 打开文件 vim ~/.bashrc 写入以下两行代码 export WORKON_HOME=~/Envs #设置virtualenv的统一管理目录 export VIRTUALENVWRAPPER_VIRTUALENV_ARGS=&apos;--no-site-packages&apos; #添加virtualenvwrapper的参数，生成干净隔绝的环境 export VIRTUALENVWRAPPER_PYTHON=/opt/python347/bin/python3 #指定python解释器 source /opt/python34/bin/virtualenvwrapper.sh #执行virtualenvwrapper安装脚本 读取文件，使得生效，此时已经可以使用virtalenvwrapper source ~/.bashrc 步骤3：基本使用virtualenvwrapper创建一个虚拟环境： $ mkvirtualenv my_django115 这会在 ~/Envs 中创建 my_django115 文件夹。 在虚拟环境上工作：激活虚拟环境my_django115 $ workon my_django115 再创建一个新的虚拟环境 $ mkvirtualenv my_django2 virtualenvwrapper 提供环境名字的tab补全功能。 当有很多环境， 并且很难记住它们的名字时，这就显得很有用。  workon还可以任意停止你当前的环境，可以在多个虚拟环境中来回切换 workon django1.15 workon django2.0 也可以手动停止虚拟环境 deactivate 删除虚拟环境，需要先退出虚拟环境 rmvirtualenv my_django115 步骤四：常用其他命令lsvirtualenv 列举所有的环境。 cdvirtualenv 导航到当前激活的虚拟环境的目录中，比如说这样您就能够浏览它的 site-packages 。 cdsitepackages 和上面的类似，但是是直接进入到 site-packages 目录中。 lssitepackages 显示 site-packages 目录中的内容。 完整官网介绍：https://virtualenvwrapper.readthedocs.io/en/latest/command_ref.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql主从复制]]></title>
    <url>%2F2018%2F05%2F05%2Fmysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[数据库备份与恢复备份 mysqldump -u root -p --all-databases &gt; /tmp/mysql.dump 恢复 mysql -uroot -p &lt; /tmp/mysql.dump mysql 主从复制1234主从机制实现原理：(1) master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）； (2) slave将master的binary log events拷贝到它的中继日志(relay log)； (3) slave重做中继日志中的事件，将改变反映它自己的数据。 master 主库配置： 修改配置文件my.cnf，在[mysqld]节点增加两行内容123[mysqld] server-id=1 # 服务的唯一标识，主从之间要不同 log-bin=mysql-bin # master将改变保存到二进制文件的名称 master 主库添加从库账号： 新建用于主从同步的用户 123create user &apos;gandoufu&apos;@&apos;%&apos; identified by &apos;123&apos;;如果提示密码太简单不复合策略加在前面加这句mysql&gt; set global validate_password_policy=0; 给从库账号授权，给上一步新建的用户gandoufu从库复制的权限 123grant replication slave on *.* to &apos;ganfoufu&apos;@&apos;%&apos;;检查授权账号的权限： show grants for &apos;ganfoufu&apos;@&apos;%&apos;; 实现对主数据库锁表只读，防止数据写入，数据复制失败 flush table with read lock; 检查主库的状态 1234567MariaDB [(none)]&gt; show master status; │+-------------------+----------+--------------+------------------+ │| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | │+-------------------+----------+--------------+------------------+ │| master-bin.000001 | 473 | | | │+-------------------+----------+--------------+------------------+ │1 row in set (0.00 sec) File是二进制日志文件名，Position 是日志开始的位置。后面配置从库时会用到。 锁表后，导出数据库的所有数据 1mysqldump -uroot -p --all-databases &gt; /tmp/mysql.dump 导出数据完毕后，解锁主库，恢复可写； 1unlock tables; 将备份导出的数据scp至Slave数据库 1scp /tmp/mysql.dump root@slave_server_ip:/tmp/ slave 从库配置：从库我用的是centos6 设置server-id值并关闭binlog功能参数 数据库的server-id在主从复制体系内是唯一的，Slave的server-id要与主库和其他从库不同，并且注释掉Slave的binlog参数。 修改Slave的/etc/my.cnf，写入一行内容： 12[mysqld]server-id=6 重启数据库 1/etc/init.d/mysqld restart 检查slave从数据库的参数 1show variables like &apos;server_id&apos;; 恢复主库Master的数据导入到Slave库 1source /tmp/mysql.dump; 配置复制的参数，Slave从库连接Master主库的配置 12345mysql &gt; change master to master_host=&apos;192.168.12.99&apos;,master_user=&apos;jia&apos;,master_password=&apos;1234&apos;,master_log_file=&apos;master1.000001&apos;,master_log_pos=564; 启动从库的同步开关，测试主从复制的情况 1start slave; 查看复制情况 1show slave status\G; 检查两条参数，如果都是yes，即主从ok12Slave_IO_Running: YesSlave_SQL_Running: Yes 这时在主服务器中修改数据，都会自动同步到从服务器。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[nginx_uWSGI_django_virtualenv_supervisor发布web服务器]]></title>
    <url>%2F2018%2F05%2F03%2Fnginx-uWSGI-django-virtualenv-supervisor%E5%8F%91%E5%B8%83web%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[导论12345678910111213141516171819202122232425262728WSGI是Web服务器网关接口。它是一个规范，描述了Web服务器如何与Web应用程序通信，以及Web应用程序如何链接在一起以处理一个请求，（接收请求，处理请求，响应请求）基于wsgi运行的框架有bottle,DJango,Flask,用于解析动态HTTP请求支持WSGI的服务器 wsgiref python自带的web服务器 Gunicorn 用于linux的 python wsgi Http服务器，常用于各种django，flask结合部署服务器。 mode_wsgi 实现了Apache与wsgi应用程序的结合 uWSGI C语言开发，快速，自我修复，开发人员友好的WSGI服务器，用于Python Web应用程序的专业部署和开发。在部署python程序web应用程序时，可以根据性能的需求，选择合适的wsgi server，不同的wsgi server区别在于并发支持上，有单线程，多进程，多线程，协程的区别，其功能还是近似，无非是请求路由，执行对应的函数，返回处理结果。Django部署Django的主要部署平台是 WSGI，这是用于Web服务器和应用程序的Python标准。Django的 startproject管理命令设置一个简单的默认WSGI配置，可以根据需要为您的项目进行调整，并指示任何符合WSGI的应用程序服务器使用。application 使用WSGI部署的关键概念是应用程序服务器用于与代码通信的 application 可调用。它通常在服务器可访问的Python模块中作为名为 application 的对象提供。startproject 命令创建包含这样的 application 可调用的文件 &lt;project_name&gt;/wsgi.py. ，它被Django的开发服务器和生产WSGI部署使用。WSGI服务器从其配置中获取 application 可调用的路径。 Django的内置服务器，即 runserver 命令，从 WSGI_APPLICATION 设置读取它。 为什么用nginx和uwsgi12345678910111213141516171、首先nginx 是对外的服务接口，外部浏览器通过url访问nginx,2、nginx 接收到浏览器发送过来的http请求，将包进行解析，分析url，如果是静态文件请求就直接访问用户给nginx配置的静态文件目录，直接返回用户请求的静态文件，如果不是静态文件，而是一个动态的请求，那么nginx就将请求转发给uwsgi,uwsgi 接收到请求之后将包进行处理，处理成wsgi可以接受的格式，并发给wsgi,wsgi 根据请求调用应用程序的某个文件，某个文件的某个函数，最后处理完将返回值再次交给wsgi,wsgi将返回值进行打包，打包成uwsgi能够接收的格式，uwsgi接收wsgi 发送的请求，并转发给nginx,nginx最终将返回值返回给浏览器。1、要知道第一级的nginx并不是必须的，uwsgi完全可以完成整个的和浏览器交互的流程，但是要考虑到某些情况安全问题，程序不能直接被浏览器访问到，而是通过nginx,nginx只开放某个接口，uwsgi本身是内网接口，这样运维人员在nginx上加上安全性的限制，可以达到保护程序的作用。2、负载均衡问题，一个uwsgi很可能不够用，即使开了多个work也是不行，毕竟一台机器的cpu和内存都是有限的，有了nginx做代理，一个nginx可以代理多台uwsgi完成uwsgi的负载均衡。3、静态文件问题，用django或是uwsgi这种东西来负责静态文件的处理是很浪费的行为，而且他们本身对文件的处理也不如nginx好，所以整个静态文件的处理都直接由nginx完成，静态文件的访问完全不去经过uwsgi以及其后面的东西。为什么要用nginx,uwsgi nginx有关nginx官网 http://nginx.org/en/ nginx有关uwsgi模块介绍 http://nginx.org/en/docs/http/ngx_http_uwsgi_module.html nginx、WSGI、uwsgi、uWSGI、django这几个关系 wsgi 全称web server gateway interface，wsgi不是服务器，也不是python模块，只是一种协议， 描述web server如何和web application通信的规则。运行在wsgi上的web框架有bottle，flask，djangouwsgi 和wsgi一样是通信协议，是uWSGI服务器的单独协议，用于定义传输信息的类型uWSGI 是一个web服务器，实现了WSGI协议，uwsgi协议。anginx web服务器，更加安全，更好的处理处理静态资源，缓存功能，负载均衡，因此nginx的强劲性能，配合uWSGI服务器会更加安全，性能有保障。django 高级的python web框架，用于快速开发，解决web开发的大部分麻烦，程序员可以更专注业务逻辑，无须重新造轮子 Django Nginx+uwsgi安装配置以前我们使用 python manage.py runserver 来运行服务器。 这只适用测试环境中使用。正式发布的服务，需要一个可以稳定而持续的服务器。 基础开发环境配置yum groupinstall &quot;Development tools&quot; yum install zlib-devel bzip2-devel pcre-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel 提前安装好python3环境 virtualenv django1.11.11 安装django1.11pip3 install django==1.11 创建django项目mysitedjango-admin startproject mysite 创建app01python3 manage.py startapp app01 mysite/settings.py settings.py设置ALLOWED_HOSTS = [&apos;*&apos;] install app01 mysite/urls.py from app01 import views urlpatterns = [ url(r&apos;^admin/&apos;, admin.site.urls), url(r&apos;^hello_django/&apos;, views.hello), ] app01/views.pyfrom django.shortcuts import render,HttpResponse # Create your views here. def hello(request): print(&apos;request is :&apos;,request) return HttpResponse(&apos;django is ok &apos;) 安装uWSGI进入虚拟环境venv，安装uwsgi (venv) [root@slave 192.168.11.64 /opt]$pip3 install uwsgi 检查uwsgi版本 (venv) [root@slave 192.168.11.64 /opt]$uwsgi --version 2.0.17.1 检查uwsgi python版本uwsgi --python-version 运行简单的uWSGI 启动一个python uwsgi --http :8000 --wsgi-file test.py http :8000: 使用http协议，端口8000 wsgi-file test.py: 加载指定的文件，test.py #test.py def application(env, start_response): start_response(&apos;200 OK&apos;, [(&apos;Content-Type&apos;,&apos;text/html&apos;)]) return [b&quot;Hello World&quot;] # python3 uWsgi热加载python程序123456在启动命令后面加上参数uwsgi --http :8088 --module mysite.wsgi --py-autoreload=1 #发布命令command= /home/venv/bin/uwsgi --uwsgi 0.0.0.0:8000 --chdir /opt/mysite --home=/home/venv --module mysite.wsgi#此时修改django代码，uWSGI会自动加载django程序，页面生效复制代码 运行django程序 #mysite/wsgi.py 确保找到这个文件 uwsgi --http :8000 --module mysite.wsgi module mysite.wsgi: 加载指定的wsgi模块 uwsgi配置文件 uwsgi支持ini、xml等多种配置方式，本文以 ini 为例， 在/etc/目录下新建uwsgi_nginx.ini，添加如下配置： # mysite_uwsgi.ini file [uwsgi] # Django-related settings # the base directory (full path) chdir = /opt/mysite # Django&apos;s wsgi file module = mysite.wsgi # the virtualenv (full path) home = /opt/venv # process-related settings # master master = true # maximum number of worker processes processes = 1 # the socket (use the full path to be safe socket = 0.0.0.0:8000 # ... with appropriate permissions - may be needed # chmod-socket = 664 # clear environment on exit vacuum = true 指定配置文件启动命令uwsgi --ini /etc/uwsgi_nginx.ini 配置nginx结合uWSGI1234567891011121314151617181920212223242526272829303132333435363738394041worker_processes 1;error_log logs/error.log;pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log logs/access.log main; sendfile on; keepalive_timeout 65; #nginx反向代理uwsgi server &#123; listen 80; server_name 192.168.11.64; location / &#123; #nginx自带ngx_http_uwsgi_module模块，起到nginx和uwsgi交互作用 #通过uwsgi_pass设置服务器地址和协议，讲动态请求转发给uwsgi处理 include /opt/nginx1-12/conf/uwsgi_params; uwsgi_pass 0.0.0.0:8000; root html; index index.html index.htm; &#125; #nginx处理静态页面资源 location /static&#123; alias /opt/nginx1-12/static; &#125; #nginx处理媒体资源 location /media&#123; alias /opt/nginx1-12/media; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; http { include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log logs/access.log main; sendfile on; keepalive_timeout 65; upstream crm_django { server 192.168.12.77:8000; } # 虚拟主机一 server { listen 80; server_name www.xx.com; location / { uwsgi_pass crm_django; include /opt/nginx1-12/conf/uwsgi_params; } location /static { alias /opt/static/; } } 以上配置完启动nginxsupervisorsupervisor 是基于 python 的任务管理工具，用来自动运行各种后台任务，当然你也能直接利用 nohup 命令使任务自动后台运行，但如果要重启任务，每次都自己手动 kill 掉任务进程，这样很繁琐，而且一旦程序错误导致进程退出的话，系统也无法自动重载任务。 这里要配置基于virtualenv的supervisor 由于supervisor在python3下无法使用，因此只能用python2去下载！！！！！！ #注意此时已经退出虚拟环境了！！！！！ yum install python-setuptools easy_install supervisor 通过命令生成supervisor的配支文件 echo_supervisord_conf &gt; /etc/supervisord.conf 然后再/etc/supervisord.conf末尾添加上如下代码！！！！！！ 123456789101112131415161718supervisord.conf配置文件参数解释[program:xx]是被管理的进程配置参数，xx是进程的名称[program:xx]command=/opt/apache-tomcat-8.0.35/bin/catalina.sh run ; 程序启动命令autostart=true ; 在supervisord启动的时候也自动启动startsecs=10 ; 启动10秒后没有异常退出，就表示进程正常启动了，默认为1秒autorestart=true ; 程序退出后自动重启,可选值：[unexpected,true,false]，默认为unexpected，表示进程意外杀死后才重启startretries=3 ; 启动失败自动重试次数，默认是3user=tomcat ; 用哪个用户启动进程，默认是rootpriority=999 ; 进程启动优先级，默认999，值小的优先启动redirect_stderr=true ; 把stderr重定向到stdout，默认falsestdout_logfile_maxbytes=20MB ; stdout 日志文件大小，默认50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数，默认是10; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile=/opt/apache-tomcat-8.0.35/logs/catalina.outstopasgroup=false ;默认为false,进程被杀死时，是否向这个进程组发送stop信号，包括子进程killasgroup=false ;默认为false，向进程组发送kill信号，包括子进程 1234[program:my]#command=/opt/venv/bin/uwsgi --ini /etc/uwsgi_nginx.ini #这里是结合virtualenv的命令 和supervisor的精髓！！！！command= /home/venv/bin/uwsgi --uwsgi 0.0.0.0:8000 --chdir /opt/mysite --home=/home/venv --module mysite.wsgi#--home指的是虚拟环境目录 --module找到 mysite/wsgi.py 最后启动supervisor，完成uWSGI启动django，nginx反向代理 supervisord -c /etc/supervisord.conf #启动supervisorsupervisorctl -c /etxc/supervisord.conf restart my #重启my项目supervisorctl -c /etc/supervisord.conf [start|stop|restart] [program-name|all] 重新加载supervisor 一、添加好配置文件后 二、更新新的配置到supervisord supervisorctl update 三、重新启动配置中的所有程序 supervisorctl reload 四、启动某个进程(program_name=你配置中写的程序名称) supervisorctl start program_name 五、查看正在守候的进程 supervisorctl 六、停止某一进程 (program_name=你配置中写的程序名称) pervisorctl stop program_name 七、重启某一进程 (program_name=你配置中写的程序名称) supervisorctl restart program_name 八、停止全部进程 supervisorctl stop all 注意：显示用stop停止掉的进程，用reload或者update都不会自动重启。 django的静态文件与nginx配置 重点django的静态文件与nginx配置 mysite/settings.py STATIC_ROOT=&apos;/opt/nginx1-12/static&apos; STATIC_URL = &apos;/static/&apos; STATICFILES_DIRS=[ os.path.join(BASE_DIR,&quot;static&quot;), ] 上述的参数STATIC_ROOT用在哪？ 通过python3 manage.py collectstatic 收集所有你使用的静态文件保存到STATIC_ROOT！ STATIC_ROOT 文件夹 是用来将所有STATICFILES_DIRS中所有文件夹中的文件，以及各app中static中的文件都复制过来 # 把这些文件放到一起是为了用nginx等部署的时候更方便 总结linux基本管理命令服务器上安装服务,python3.6(宿主机上的物理解释器) 1.虚拟解释器 virtualenv 虚拟出多个干净、隔离的python解释器环境 问题：管理上较为麻烦，需要找到venv的路径，并且source activate 才能激活虚拟环境 2. virtualenvwrapper工具 更为方便的使用以及管理virtualenv 1.配置好环境变量之后，每次开机就加载这个软件 2.workon 激活并且切换多个虚拟环境 mkvirtualenv 创建 lsvirtualenv cdvirtualenv rmvirtualenv mariadbmariadb(mysql)，与django连接，存储数据(yum install mariadb-server mariadb-client) 初始化连接数据库 __init.py__ import pymysql pymysql.install() 本地django连接linux上的数据库注意事项： 1.防火墙问题，需配置规则，或者关闭防火墙 使用云服务器的同学，需要注意开通3306端口（安全组功能） 2.远程连接mysql，需要授权，远程连接 grant all privileges ..... edisimport redis 准备django项目准备django项目 &gt; crm 在服务器上运行crm 1.把本地代码，传至linux -scp(linux与linux网络传输) -xshell(yum install lrzsz) (windows) lrzsz 可以通过如下俩命令管理文件，也可以直接拖拽文件 rz 接收 sz 发送 lrzsz只适用于小文件，大文件，请用xftp -xftp (更为高效的企业级文件传输协议软件) 2.django项目需要配置allow_hosts=[‘*’]，允许所有主机访问 debug=True #返回给项目一个debug信息，暴露了项目配置信息，因此在线上要关闭 Nginx1.web服务器，用户的统一入口， 我们的想法是，让用户通过nginx这个入口，就能访问到我们的应用服务器的功能 www.pythonav.cn 入口 &lt; 80端口 端口转发，反向代理 80端口的请求 &gt; 8000的端口应用 server{}虚拟主机 2.反向代理服务器 proxy_pass 后端应用服务器的ip:port (转发给一个单点机器) proxy_pass upstream负载均衡池 3.负载均衡服务器 nginx接收到了基于wsgi协议的动态请求，然后通过uwsgi_pass转发给uwsgi服务器 uwsgi_pass mydjango; upstream mydjango { server 192.168.12.1:8000 weight=1; server 192.168.12.2:8000 weight=5; server 192.168.12.3:8000 weight=10; } 4.处理静态文件，者是nginx的天然优势，处理静态文件的高并发性性能 www.python.com/static/xxx.js 文件存放目录/data/static/xxx.js www.python.com/static/xxx.css 文件存放目录/data/static/xxx.css www.python.com/static/xxx.jpg 文件存放目录/data/static/xxx.jpg location /static { alias /data/static; } uwsgi uwsgi服务器： 通过uwsgi这个软件启动crm项目，且是一个支持高并发，多进程的一个应用服务器 uwsgi --module crm python3 manage.py runserver 0.0.0.0:8000 ×× 不再用这种单机形式启动crm django-admin startproject crm django-admin startapp app01 crm -crm -wsgi.py (重点级的文件，django启动，实现wsgi协议的文件) -manage.py 常见问题：uwsgi 启动crm的时候，非常有可能报错一个 no application(找不到应用) uwsgi找不到你的crm的wsgi.py 其实uwsgi是通过这个application对象加载crm的 application = get_wsgi_application() 进程管理工具：启动进程后，通过命令 手动管理 ps -ef |grep uwsgi #启停uwsgi kill -9 pid pkill uwsgi killall uwsgi #管理nginx ps -ef kill #管理mysql ps -ef kill #进程管理工具 supervisor 服务启动后 supervisorctl ，可以通过这个命令，非常方便的管理进程，也可以统一启动，停止所有的进程 批量管理进程 mysql : running/stop nginx : running/stop uwsgi:running/stop 项目发布配置手册： (更换不同的服务器环境，首先就要解决环境依赖的问题) 1.pip3 frezz &gt; requirements.py 2. pip3 install -r requirements.py 3.docker 1.准备python环境，准备虚拟环境，激活了虚拟环境 mkvirtualenv nbcrm 检测是否虚拟环境正常 which pip3 which python3 2.安装django模块（此时的操作都是在nbcrm这个虚拟环境下了） pip3 install django==1.11.11 3.安装pymysql连接mysql数据库 pip3 install pymysql 4.安装django的一个django-multiselectfield pip3 install django-multiselectfield 5.解决项目的数据库连接问题，修改settings.py 1.启动linux的数据库，创建对应的数据库，密码设置等等 create database nb_crm; 2.更改settings.py DATABASES = { ‘default’: { ‘ENGINE’: ‘django.db.backends.mysql’, ‘NAME’: ‘nb_crm’, #数据库名 ‘HOST’: ‘127.0.0.1’, #这里服务器的ip地址 ‘PORT’: 3306, #端口 ‘USER’: ‘root’, #用户名 ‘PASSWORD’: ‘redhat123’, #用户密码 } } 3.更改允许主机 ALLOWED_HOSTS = [‘*’] 4.线上关闭debug(肖锋的这个nb_crm先别改debug了)，默认先用True debug=True 使用uwsgi启动django1.安装uwsgi pip3 install -i https://pypi.douban.com/simple uwsgi 2.通过uwsgi命令启动python应用 uwsgi --http 0.0.0.0:8888 --wsgi-file test1.py --http 指明是http协议 --socket 启动一个socket 链接 --wsgi-file 指明一个python应用文件 3.通过uwsgi启动django项目(问题是，uwsgi不处理static静态文件的配置) uwsgi –http :8888 –module Nb_crm.wsgi 4.uwsgi可以热加载项目 uwsgi --http :9999 --module mycrm.wsgi --py-autoreload=1 --py-autoreload是告诉uwsgi自动重启加载django项目 5.通过uwsgi的配置文件启动项目 1.手动创建uwsgi.ini文件 touch uwsgi.ini 2.写入如下配置 [uwsgi] #项目的绝对路径，定位到项目的第一层 chdir = /opt/NB_crm #指明项目的wsgi文件路径 module = NB_crm.wsgi #指明你的虚拟解释器的第一层路径 home = /root/Envs/nbcrm #指明通过uwsgi，启动多少个进程 processes = 5 #非常重要 #非常重要 #非常重要 #如果你已经配置了nginx(启动了nginx服务，配置了uwsgi_pass)，请用这个socket连接 #socket = 0.0.0.0:8000 #如果你没用nginx，想通过uwsgi直接启动web服务，指明http协议 http = 0.0.0.0:9999 #在退出uwsgi环境后，清空环境变量 vacuum = true 6.通过配置文件启动NB_crm（注意uwsgi不会处理静态文件，如果有，也是浏览器的缓存！！！！） uwsgi –ini uwsgi.ini 7.配置django的settings.py，收集所有NB_crm项目所需的静态文件 1.#通过命令，收集整个项目所有的静态文件，放入到/opt/static/ STATIC_ROOT=’/opt/static/‘ 2.执行命令 python3 manage.py collectstatic 3.此时NB_crm的所有静态文件，都跑到/opt/static/底下了 (nbcrm) [root@node1 /opt/NB_crm 11:09:33]#ls /opt/static/ admin css imgs js plugins 8.配置nginx 1.配置一个网站入口，当用户访问192.168.12.96:80 这个web应用时，自动将请求转发给uwsgi，uwsgi处理后，返回给nginx，返回给用户 当请求是192.168.12.96:80的时候，其实访问的是192.168.12.96:9999 这是动态请求，因为我是找到的uwsgi #匹配度最低的写法，因此就是任何的请求都访问到这里 2.通过nginx去处理静态文件 3.nginx.conf配置如下 #定义负载均衡池，里面放入uwsgi的地址 upstream nbcrm { server 127.0.0.1:8000; } server { listen 80; server_name www.xx.com; #讲nginx入口的请求，直接反向代理给uwsgi location / { uwsgi_pass nbcrm; include /opt/nginx1-12/conf/uwsgi_params; } #通过nginx处理nbcrm的静态文件 location /static { alias /opt/static/; } } 9.更改uwsgi.ini ，指明socket连接，结合uwsgi 和nginx #如果你已经配置了nginx，请用这个socket连接 socket = 0.0.0.0:8000 10.启动uwsgi.ini uwsgi –ini uwsgi.ini 启动nginx ./nginx 并且访问nginx的域名入口，查看是否能访问到uwsgi项目，并且静态文件是否正常 www.xx.com 查看浏览器状态 11.配置supversior，管理uwsgi进程 注意，请退出虚拟环境，在宿主机环境下，安装supvervisor 1.安装easy_install ，python2的软件包管理工具 ，如果有了可以忽略 yum install python-setuptools #安装软件 easy_install supervisor 2.使用supervisor命令,常用命令如下 生成配置文件 echo_supervisord_conf &gt; /etc/supervisord.conf 3.修改配置文件，添加任务，按照自己的机器环境修改此命令 [program:crm_project] #启动uwsgi的命令就是这个 command=/root/Envs/nbcrm/bin/uwsgi --ini /opt/NB_crm/uwsgi.ini #自动启动uwsgi，挂了之后自动加载 autorestart=true 4.启动supvervisord服务，启动uwsgi #服务端命令，用于启动这个服务 supervisord -c /etc/supervisord.conf 5.通过命令管理uwsgi supervisorctl 直接回车，进入交互式管理状态 [root@node1 ~ 11:53:32]#supervisorctl crm_project RUNNING pid 2008, uptime 0:01:56 也可以通过命令交互式的管理uwsgi #服务端启动后，通过命令管理软件 supervisorctl start crm_project supervisorctl stop crm_project supervisorctl status crm_project]]></content>
      <categories>
        <category>nginx</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[nginx入门与实践]]></title>
    <url>%2F2018%2F05%2F02%2Fnginx%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[网站服务 想必我们大多数人都是通过访问网站而开始接触互联网的吧。我们平时访问 的网站服务 就是 Web 网络服务，一般是指允许用户通过浏览器访问到互 联网中各种资源的服务。 Web 网络服务是一种被动访问的服务程序，即只有接收到互联网中其他主 机发出的 请求后才会响应，最终用于提供服务程序的 Web 服务器会通 过 HTTP(超文本传输协议)或 HTTPS(安全超文本传输协议)把请求的内容 传送给用户。 目前能够提供 Web 网络服务的程序有 IIS、Nginx 和 Apache 等。其 中，IIS(Internet Information Services，互联网信息服务)是 Windows 系统中默认的 Web 服务程序 2004 年 10 月 4 日，为俄罗斯知名门户站点而开发的 Web 服务程序 Nginx 横空出世。 Nginx 程序作为一款轻量级的网站服务软件，因其 稳定性和丰富的功能而快速占领服务器市 场，但 Nginx 最被认可的还 当是系统资源消耗低且并发能力强，因此得到了国内诸如新浪、 网易、 腾讯等门户站的青睐。 web服务器和web框架的关系web服务器（nginx）： 接收HTTP请求（www.xiaoxuedi.top）并返回数据 web框架（django，flask）： 开发web应用程序，处理接收到的数据 NGINXnginx是什么nginx是一个开源的，支持高性能，高并发的www服务和代理服务软件。 它是一个俄罗斯人lgor sysoev开发的，作者将源代码开源出来供全球使用。 nginx比它大哥apache性能改进许多，nginx占用的系统资源更少， 支持更高的并发连接，有更高的访问效率。 nginx不但是一个优秀的web服务软件， 还可以作为反向代理，负载均衡，以及缓存服务使用。 安装更为简单，方便，灵活。 支持高并发，能支持几万并发连接 资源消耗少，在3万并发连接下开启10个nginx线程消耗的内存不到200M 可以做http反向代理和负载均衡 支持异步网络i/o事件模型epoll Tengine是由淘宝网发起的Web服务器项目。它在Nginx的基础上，针对大 访问量网站的需求，添加了很多高级功能和特性。Tengine的性能和稳定 性已经在大型的网站如淘宝网，天猫商城等得到了很好的检验。它的最终目 标是打造一个高效、稳定、安全、易用的Web平台。 安装环境准备一. gcc 安装 安装 nginx 需要先将官网下载的源码进行编译，编译依赖 gcc 环境，如果没有 gcc 环境，则需要安装： yum install gcc-c++ 二. PCRE pcre-devel 安装 PCRE(Perl Compatible Regular Expressions) 是一个Perl库，包括 perl 兼容的正则表达式库。nginx 的 http 模块使用 pcre 来解析正则表达式，所以需要在 linux 上安装 pcre 库，pcre-devel 是使用 pcre 开发的一个二次开发库。nginx也需要此库。命令： yum install -y pcre pcre-devel 三. zlib 安装 zlib 库提供了很多种压缩和解压缩的方式， nginx 使用 zlib 对 http 包的内容进行 gzip ，所以需要在 Centos 上安装 zlib 库。 yum install -y zlib zlib-devel 四. OpenSSL 安装 OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。 nginx 不仅支持 http 协议，还支持 https（即在ssl协议上传输http），所以需要在 Centos 安装 OpenSSL 库。 yum install gcc patch libffi-devel python-devel zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel openssl openssl-devel -y 安装，启动nginx1.下载源码包 wget -c https://nginx.org/download/nginx-1.12.0.tar.gz 2.解压缩源码 tar -zxvf nginx-1.12.0.tar.gz 3.配置，编译安装 开启nginx状态监测功能 ./configure --prefix=/opt/nginx1-12/ --with-http_ssl_module --with-http_stub_status_module make &amp;&amp; make install 4.启动nginx，进入sbin目录,找到nginx启动命令 cd sbin ./nginx #启动 ./nginx -s stop #关闭 ./nginx -s reload #重新加载 安装完成后检查服务netstat -tunlp |grep 80 curl -I 127.0.0.1 #如果访问不了，检查selinux，iptables 部署一个web站点nginx默认站点是Nginx目录下的html文件夹，这里可以从nginx.conf中查到 location /{ root html; #这里是默认的站点html文件夹，也就是 /opt/nginx1-12/html/文件夹下的内容 index index.html index.htm; #站点首页文件名是index.html } 如果要部署网站业务数据，只需要把开发好的程序全放到html目录下即可 [root@python /tmp 11:34:52]#ls /opt/nginx1-12/html/ index.html jssts.jpeg lhy.mp4 man.jpg wget-log 因此只需要通过域名/资源，即可访问 Nginx的目录结构client_body_temp conf fastcgi_temp html logs proxy_temp sbin scgi_temp static uwsgi_temp conf 存放nginx所有配置文件的目录,主要nginx.conf html 存放nginx默认站点的目录，如index.html、error.html等 logs 存放nginx默认日志的目录，如error.log access.log sbin 存放nginx主命令的目录,sbin/nginx Nginx主配置文件解析Nginx主配置文件/etc/nginx/nginx.conf是一个纯文本类型的文件， 整个配置文件是以区块的形式组织的。一般，每个区块以一对大括号{}来 表示开始与结束。 nginx.conf详解######Nginx配置文件nginx.conf中文详解##### #定义Nginx运行的用户和用户组 user www www; #nginx进程数，建议设置为等于CPU总核心数。 worker_processes 8; #全局错误日志定义类型，[ debug | info | notice | warn | error | crit ] error_log /usr/local/nginx/logs/error.log info; #进程pid文件 pid /usr/local/nginx/logs/nginx.pid; #指定进程可以打开的最大描述符：数目 #工作模式与连接数上限 #这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。 #现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。 #这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。 worker_rlimit_nofile 65535; events { #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型 #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。 #补充说明： #与apache相类，nginx针对不同的操作系统，有不同的事件模型 #A）标准事件模型 #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll #B）高效事件模型 #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。 #Epoll：使用于Linux内核2.6版本及以后的系统。 #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。 #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。 use epoll; #单个进程最大连接数（最大连接数=连接数*进程数） #根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cpu跑到100%就行。每个进程允许的最多连接数，理论上每台nginx服务器的最大连接数为。 worker_connections 65535; #keepalive超时时间。 keepalive_timeout 60; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。 #分页大小可以用命令getconf PAGESIZE 取得。 #[root@web001 ~]# getconf PAGESIZE #4096 #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。 client_header_buffer_size 4k; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。 open_file_cache max=65535 inactive=60s; #这个是指多长时间检查一次缓存的有效信息。 #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息. open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。 #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态. open_file_cache_min_uses 1; #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误. open_file_cache_errors on; } #设定http服务器，利用它的反向代理功能提供负载均衡支持 http { #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #默认编码 #charset utf-8; #服务器名字的hash表大小 #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小. server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。 client_header_buffer_size 32k; #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。 large_client_header_buffers 4 64k; #设定通过nginx上传文件的大小 client_max_body_size 8m; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。 sendfile on; #开启目录列表访问，合适下载服务器，默认关闭。 autoindex on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nopush on; tcp_nodelay on; #长连接超时时间，单位是秒 keepalive_timeout 120; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩等级 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。 gzip_vary on; #开启限制IP连接数的时候需要使用 #limit_zone crawler $binary_remote_addr 10m; #负载均衡配置 upstream jh.w3cschool.cn { #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 server 192.168.80.121:80 weight=3; server 192.168.80.122:80 weight=2; server 192.168.80.123:80 weight=3; #nginx的upstream目前支持4种方式的分配 #1、轮询（默认） #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 #2、weight #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 #例如： #upstream bakend { # server 192.168.0.14 weight=10; # server 192.168.0.15 weight=10; #} #2、ip_hash #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 #例如： #upstream bakend { # ip_hash; # server 192.168.0.14:88; # server 192.168.0.15:80; #} #3、fair（第三方） #按后端服务器的响应时间来分配请求，响应时间短的优先分配。 #upstream backend { # server server1; # server server2; # fair; #} #4、url_hash（第三方） #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法 #upstream backend { # server squid1:3128; # server squid2:3128; # hash $request_uri; # hash_method crc32; #} #tips: #upstream bakend #在需要使用负载均衡的server中增加 proxy_pass http://bakend/; #每个设备的状态设置为: #1.down表示单前的server暂时不参与负载 #2.weight为weight越大，负载的权重就越大。 #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误 #4.fail_timeout:max_fails次失败后，暂停的时间。 #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。 #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug #client_body_temp_path设置记录文件的目录 可以设置最多3层目录 #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡 } #虚拟主机的配置 server { #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name www.w3cschool.cn w3cschool.cn; index index.html index.htm index.php; root /data/www/w3cschool; #对******进行负载均衡 location ~ .*.(php|php5)?$ { fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; } #图片缓存时间设置 location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$ { expires 10d; } #JS和CSS缓存时间设置 location ~ .*.(js|css)?$ { expires 1h; } #日志格式设定 #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址； #$remote_user：用来记录客户端用户名称； #$time_local： 用来记录访问时间与时区； #$request： 用来记录请求的url与http协议； #$status： 用来记录请求状态；成功是200， #$body_bytes_sent ：记录发送给客户端文件主体内容大小； #$http_referer：用来记录从那个页面链接访问过来的； #$http_user_agent：记录客户浏览器的相关信息； #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。 log_format access &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; $http_x_forwarded_for&apos;; #定义本虚拟主机的访问日志 access_log /usr/local/nginx/logs/host.access.log main; access_log /usr/local/nginx/logs/host.access.404.log log404; #对 &quot;/&quot; 启用反向代理 location / { proxy_pass http://127.0.0.1:88; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。 proxy_set_header Host $host; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数， #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。 #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误 client_body_buffer_size 128k; #表示使nginx阻止HTTP应答代码为400或者更高的应答。 proxy_intercept_errors on; #后端服务器连接的超时时间_发起握手等候响应超时时间 #nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 90; #后端服务器数据回传时间(代理发送超时) #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据 proxy_send_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_read_timeout 90; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小 proxy_buffer_size 4k; #proxy_buffers缓冲区，网页平均在32k以下的设置 #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长 #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k; } #设定查看Nginx状态的地址 location /NginxStatus { stub_status on; access_log on; auth_basic &quot;NginxStatus&quot;; auth_basic_user_file confpasswd; #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。 } #本地动静分离反向代理配置 #所有jsp的页面均交由tomcat或resin处理 location ~ .(jsp|jspx|do)?$ { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; } #所有静态文件由nginx直接读取不经过tomcat或resin location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt| pdf|xls|mp3|wma)$ { expires 15d; } location ~ .*.(js|css)?$ { expires 1h; } } } ######Nginx配置文件nginx.conf中文详解##### nginx.conf详解 CoreModule核心模块user www; #Nginx进程所使用的用户 worker_processes 1; #Nginx运行的work进程数量(建议与CPU数量一致或auto) error_log /log/nginx/error.log #Nginx错误日志存放路径 pid /var/run/nginx.pid #Nginx服务运行后产生的pid进程号 events事件模块events { worker_connections //每个worker进程支持的最大连接数 use epool; //事件驱动模型, epoll默认 } http内核模块//公共的配置定义在http{} http { //http层开始 ... //使用Server配置网站, 每个Server{}代表一个网站(简称虚拟主机) &apos;server&apos; { listen 80; //监听端口, 默认80 server_name localhost; //提供服务的域名或主机名 access_log host.access.log //访问日志 //控制网站访问路径 &apos;location&apos; / { root /usr/share/nginx/html; //存放网站代码路径 index index.html index.htm; //服务器返回的默认页面文件 } //指定错误代码, 统一定义错误页面, 错误代码重定向到新的Locaiton error_page 500 502 503 504 /50x.html; } ... //第二个虚拟主机配置 &apos;server&apos; { ... } include /etc/nginx/conf.d/*.conf; //包含/etc/nginx/conf.d/目录下所有以.conf结尾的文件 } //http层结束 Nginx虚拟主机 如果每台linux服务器只运行了一个小网站，那么人气低，流量小的草根站 长需要承担高额的服务器租赁费，也造成了硬件资源浪费。 虚拟主机就是将一台服务器分割成多个“虚拟服务器”，每个站点使用各自 的硬盘空间，由于省资源，省钱，众多网站都使用虚拟主机来部署网站。 虚拟主机的概念就是在web服务里的一个独立的网站站点，这个站点对应独 立的域名（IP），具有独立的程序和资源目录，可以独立的对外提供服 务。 这个独立的站点配置是在nginx.conf中使用server{}代码块标签来表示 一个虚拟主机。 Nginx支持多个server{}标签，即支持多个虚拟主机站点。 虚拟主机类型基于域名的虚拟主机 通过不同的域名区分不同的虚拟主机，是企业应用最广的虚拟主机。 基于端口的虚拟主机 通过不同的端口来区分不同的虚拟主机，一般用作企业内部网站，不对外直接提供服务的后台，例如www.pythonav.cn:9000 基于IP的虚拟主机 通过不同的IP区分不同的虚拟主机，此类比较少见，一般业务需要多IP的常见都会在负载均衡中绑定VIP Nginx状态信息（status）配置Nginx状态信息（status）配置及信息详解 nginx与php-fpm一样内建了一个状态页，对于想了解nginx的状态以及 监控nginx非常有帮助。为了后续的zabbix监控，我们需要先了解一下 nginx的状态页。 Nginx状态信息（status）介绍 Nginx软件在编译时又一个with-http_stub_status_module模 块，这个模块功能是记录Nginx的基本访问状态信息，让使用者了解 Nginx的工作状态。 要想使用状态模块，在编译时必须增加 --with-http_stub_status_module参数。 监测你的nginx是否安装了status模块 1234[root@master conf]# /opt/nginx/sbin/nginx -Vnginx version: nginx/1.12.0built by gcc 4.8.5 20150623 (Red Hat 4.8.5-28) (GCC)configure arguments: --prefix=/opt/nginx/ --with-http_stub_status_module 启动status状态功能，修改配置文件 1234location /status &#123; #开启nginx状态功能 stub_status on;&#125; 平滑重启nginx 1./sbin/nginx -s reload 访问status页面 http://192.168.119.10/status 通过ab压测命令检测 -n requests #执行的请求数，即一共发起多少请求。 -c concurrency #请求并发数。 -k #启用HTTP KeepAlive功能，即在一个HTTP会话中执行多个请求。 ab -kc 1000 -n 100000 http://192.168.119.10/ status页面解析 基于域名的多虚拟主机实战nginx可以自动识别用户请求的域名，根据不同的域名请求服务器传输不同的内容，只需要保证服务器上有一个可用的ip地址，配置好dns解析服务。 /etc/hosts是linux系统中本地dns解析的配置文件，同样可以达到域名访问效果 修改nginx.conf1234567891011121314151617181920212223[root@python ~ 14:33:16]#egrep -v &apos;#|^$&apos; /opt/nginx1-12/conf/nginx.confworker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log logs/access.log main; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name www.pyyuc.cn; location /&#123; root html/pyyuc; index index.html index.htm; &#125; &#125;&#125; 虚拟主机的部分就是server{}里的内容 创建pyyuc.cn的站点目录和文件1234[root@python /opt/nginx1-12/html 14:36:08]#mkdir pyyuc[root@python /opt/nginx1-12/html 14:36:18]#echo &quot;&lt;meta charset=utf8&gt;我是pyyuc站点&quot; &gt; pyyuc/index.html[root@python /opt/nginx1-12/html 14:37:21]#cat pyyuc/index.html&lt;meta charset=utf8&gt;我是pyyuc站点 上述作用创建了一个html/pyyuc站点目录，对应于虚拟主机配置文件里的root根目录的设置html/pyyuc 然后生成一个首页文件index.html，内容是“我是pyyuc站点” 检查nginx语法重新加载nginx1234567[root@python /opt/nginx1-12/html 14:37:28]#../sbin/nginx -tnginx: the configuration file /opt/nginx1-12/conf/nginx.conf syntax is oknginx: configuration file /opt/nginx1-12/conf/nginx.conf test is successful#平滑重启nginx[root@python /opt/nginx1-12/html 14:39:18]#../sbin/nginx -s reload 检查nginx端口，进程，访问pyyuc虚拟站点 1234567[root@python /opt/nginx1-12/html 14:40:02]#netstat -tunlp|grep nginx[root@python /opt/nginx1-12/html 14:40:29]#ps -ef|grep nginx#我这里是有dns解析，没有的话则需要/etc/hosts解析#成功配置了pyyuc虚拟主机站点[root@oldboy_python /opt/nginx1-12/html 14:41:37]#curl www.pyyuc.cn&lt;meta charset=utf8&gt;我是pyyuc站点 配置多个域名的虚拟主机其实就是新增一个server{}虚拟主机 12345678910111213141516171819202122232425262728293031egrep -v &apos;#|^$&apos; /opt/nginx1-12/conf/nginx.confworker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log logs/access.log main; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name www.pyyuc.cn; location /&#123; root html/pyyuc; index index.html index.htm; &#125;&#125; server &#123; listen 80; server_name www.pythonav.cn; location /&#123; root html/pythonav; index index.html index.htm; &#125;&#125; &#125; 创建pythonav虚拟主机站点的目录和文件 123456[root@python /opt/nginx1-12 14:47:21]#mkdir -p /opt/nginx1-12/html/pythonav[root@python /opt/nginx1-12 14:49:33]#echo &quot;&lt;meta charset=utf8&gt;我是pythonav，未成年禁止入内&quot;&gt; /opt/nginx1-12/html/pythonav/index.html[root@python /opt/nginx1-12 14:50:44]#./sbin/nginx -tnginx: the configuration file /opt/nginx1-12/conf/nginx.conf syntax is oknginx: configuration file /opt/nginx1-12/conf/nginx.conf test is successful[root@python /opt/nginx1-12 14:51:32]#./sbin/nginx -s reload 大功告成，基于域名的虚拟主机实战搞定[root@python /opt/nginx1-12 14:52:12]#curl www.pythonav.cn &lt;meta charset=utf8&gt;我是pythonav，未成年禁止入内 [root@python /opt/nginx1-12 14:52:40]#curl www.pyyuc.cn &lt;meta charset=utf8&gt;我是pyyuc站点 nginx访问日志（access_log）日志功能对每个用户访问网站的日志信息记录到指定的日志文件里，开发运 维人员可以分析用户的浏览器行为，此功能由ngx_http_log_module模 块负责，官网地址是： http://nginx.org/en/docs/http/ngx_http_log_module.html 控制日志的参数 123456log_format 记录日志的格式，可定义多种格式accsss_log 指定日志文件的路径以及格式 log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; 对应参数解析 123456789$remote_addr 记录客户端ip$remote_user 远程用户，没有就是 “-”$time_local 对应[14/Aug/2018:18:46:52 +0800]$request 对应请求信息&quot;GET /favicon.ico HTTP/1.1&quot;$status 状态码$body_bytes_sent 571字节 请求体的大小$http_referer 对应“-” 由于是直接输入浏览器就是 -$http_user_agent 客户端身份信息$http_x_forwarded_for 记录客户端的来源真实ip 97.64.34.118 日志效果如下12366.102.6.6 - - [14/Aug/2018:18:46:52 +0800] &quot;GET /favicon.ico HTTP/1.1&quot; 404 571 &quot;-&quot; &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.75 Safari/537.36 Google Favicon&quot; &quot;97.64.34.118&quot; nginx.conf默认配置12345log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;access_log logs/access.log main; 日志格式配置定义12log_format是日志关键字参数，不能变main是日志格式指定的标签，记录日志时通过main标签选择指定的格式。 nginx限制网站来源IP访问如果哪天发现你的nginx很慢，或者检查access.log时候，有一个some body疯狂请求你的nginx server，那么可以禁止这个IP访问 限制ip或ip段访问 禁止访问/av/底下的资源 location /av { deny 122.71.240.254; #alias /opt/nginx1-12/html/av; allow 10.1.1.0/16; } Nginx错误页面优化在网站运行过程中，可能因为页面不存在等原因，导致网站无法正常响应请求，此时web服务会返回系统的错误码，但是默认的错误页面很不友好。 因此我们可以将404，403等页面的错误信息重定向到网站首页或者其他指定的页面，提升用户访问体验。 12345678910server &#123; listen 80; server_name www.pythonav.cn; root html/pythonav; location /&#123; index index.html index.htm; &#125; #在pythonav路径下的40x.html错误页面 error_page 400 403 404 405 /40x.html; &#125; 40x.html1&lt;img style=&apos;width:100%;height:100%;&apos; src=https://pic1.zhimg.com/80/v2-77a9281a2bebc7a2ea5e02577af266a8_hd.png&gt; 此时访问www.pythonav.cn/asdasd错误页面已经优化了 nginx与locationlocation指令的作用是根据用户请求的URL来执行不同的应用。 location语法 12345678location [ = | ~ | ~* | ^~ | @ ] url &#123;&#125;指令 匹配标识 匹配网站路径 匹配url后的配置= 开头表示精确匹配^~ 开头表示uri以某个常规字符串开头，理解为匹配 url路径即可。nginx不对url做编码，因此请求为/static/20%/aa，可以被规则^~ /static/ /aa匹配到（注意是空格）。~ 开头表示区分大小写的正则匹配~* 开头表示不区分大小写的正则匹配!~和!~*分别为区分大小写不匹配及不区分大小写不匹配 的正则/ 通用匹配，任何请求都会匹配到。 123456location匹配顺序1.location = /&#123;&#125; 精确匹配2.location ^~ /images/ 匹配常规串，不做正则检查3.location ~* \.(gif|jpg|jpeg) 正则匹配4. location /av/ 匹配常规字符，有正则优先正则5.location / &#123;&#125; 所有的location都不匹配后，默认匹配 12345678910111213141516171819 location / &#123;return 401;&#125; location =/ &#123;return 402; &#125; location /documents/ &#123;return 403; &#125; location ^~ /images/ &#123;return 404; &#125; location ~* \.(gif|jpg|jpeg)$ &#123;return 500; &#125; Nginx代理 正向代理正向代理，也就是传说中的代理,他的工作原理就像一个跳板（VPN），简单的说： 我是一个用户，我访问不了某网站，但是我能访问一个代理服务器，这个代 理服务器呢，他能访问那个我不能访问的网站，于是我先连上代理服务器， 告诉他我需要那个无法访问网站的内容，代理服务器去取回来，然后返回给 我。 反向代理对于客户端而言，代理服务器就像是原始服务器。 nginx实现负载均衡的组件ngx_http_proxy_module proxy代理模块，用于把请求抛给服务器节点或者upstream服务器池 实现一个简单的反反向代理机器准备，两台服务器 master 192.168.11.63 主负载 slave 192.168.11.64 web1 主负载均衡节点的配置文件 1234567891011121314151617181920212223242526272829303132worker_processes 1;error_log logs/error.log;pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log logs/access.log main; sendfile on; keepalive_timeout 65; upstream slave_pools&#123; server 192.168.11.64:80 weight=1;&#125; server &#123; listen 80; server_name localhost; location / &#123; proxy_pass http://slave_pools; root html; index index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; 检查语法并启动nginx123[root@master 192.168.11.63 /opt/nginx1-12]$/opt/nginx1-12/sbin/nginx -tnginx: the configuration file /opt/nginx1-12/conf/nginx.conf syntax is oknginx: configuration file /opt/nginx1-12/conf/nginx.conf test is successful 12345#启动nginx[root@master 192.168.11.63 /opt/nginx1-12]$/opt/nginx1-12/sbin/nginx#检查端口[root@master 192.168.11.63 /opt/nginx1-12]$netstat -tunlp|grep nginxtcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 8921/nginx: master 此时访问master的服务器192.168.11.63:80地址，已经会将请求转发给slave的80端口 除了页面效果的展示以外，还可以通过log(access.log)查看代理效果 master端日志 slave端日志 Keepalived高可用软件什么是keepalived 12345678Keepalived是一个用C语言编写的路由软件。该项目的主要目标是为Linux系统和基于Linux的基础架构提供简单而强大的负载均衡和高可用性设施。 还可以作为其他服务（nginx，mysql）的高可用软件keepalived主要通过vrrp协议实现高可用功能。vrrp叫（virtual router redundancy protocol）虚拟路由器冗余协议，目的为了解决单点故障问题，他可以保证个别节点宕机时。整个网络可以不间断的运行。 高可用故障切换原理123456789在keepalived工作时，主master节点会不断的向备节点发送心跳消息，告诉备节点自己还活着，当master节点故障时，就无法发送心跳消息，备节点就无法检测到来自master的心跳了，于是调用自身的接管程序，接管master节点的ip资源以及服务，当master主节点恢复时，备backup节点又会释放接管的ip资源和服务，回复到原本的备节点角色。1.硬件环境准备实验环境应该最好是4台虚拟机，环境有限因此用2台机器masterslave2.centos系统和nginx代理环境]]></content>
      <categories>
        <category>nginx</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[redis之python使用手册]]></title>
    <url>%2F2018%2F03%2F23%2Fredis%E4%B9%8Bpython%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[Redis for Python开发手册 redis基本命令 StringSetset(name, value, ex=None, px=None, nx=False, xx=False) 在Redis中设置值，默认，不存在则创建，存在则修改 参数说明： ex，过期时间（秒） px，过期时间（毫秒） nx，如果设置为True，则只有name不存在时，当前set操作才执行 xx，如果设置为True，则只有name存在时，当前set操作才执行 1.ex，过期时间（秒） 这里过期时间是3秒，3秒后p，键food的值就变成None import redis pool = redis.ConnectionPool(host=&apos;127.0.0.1&apos;, port=6379, decode_responses=True) r = redis.Redis(connection_pool=pool) r.set(&apos;food&apos;, &apos;mutton&apos;, ex=3) # key是&quot;food&quot; value是&quot;mutton&quot; 将键值对存入redis缓存 print(r.get(&apos;food&apos;)) # mutton 取出键food对应的值 2.px，过期时间（豪秒） 这里过期时间是3豪秒，3毫秒后，键foo的值就变成None import redis pool = redis.ConnectionPool(host=&apos;127.0.0.1&apos;, port=6379, decode_responses=True) r = redis.Redis(connection_pool=pool) r.set(&apos;food&apos;, &apos;beef&apos;, px=3) print(r.get(&apos;food&apos;)) 3.nx，如果设置为True，则只有name不存在时，当前set操作才执行 （新建） import redis pool = redis.ConnectionPool(host=&apos;127.0.0.1&apos;, port=6379, decode_responses=True) r = redis.Redis(connection_pool=pool) print(r.set(&apos;fruit&apos;, &apos;watermelon&apos;, nx=True)) # True--不存在 # 如果键fruit不存在，那么输出是True；如果键fruit已经存在，输出是None 4.xx，如果设置为True，则只有name存在时，当前set操作才执行 （修改） print((r.set(&apos;fruit&apos;, &apos;watermelon&apos;, xx=True))) # True--已经存在 # 如果键fruit已经存在，那么输出是True；如果键fruit不存在，输出是None 5.setnx(name, value) 设置值，只有name不存在时，执行设置操作（添加） print(r.setnx(&apos;fruit1&apos;, &apos;banana&apos;)) # fruit1不存在，输出为True setexsetex(name, value, time) 设置值 参数： time，过期时间（数字秒 或 timedelta对象） import redis import time pool = redis.ConnectionPool(host=&apos;127.0.0.1&apos;, port=6379, decode_responses=True) r = redis.Redis(connection_pool=pool) r.setex(&quot;fruit2&quot;, &quot;orange&quot;, 5) time.sleep(5) print(r.get(&apos;fruit2&apos;)) # 5秒后，取值就从orange变成None psetexpsetex(name, time_ms, value) 设置值 参数： time_ms，过期时间（数字毫秒 或 timedelta对象） r.psetex(&quot;fruit3&quot;, 5000, &quot;apple&quot;) time.sleep(5) print(r.get(&apos;fruit3&apos;)) # 5000毫秒后，取值就从apple变成None msetmset(args, *kwargs) 批量设置值 如： r.mget({&apos;k1&apos;: &apos;v1&apos;, &apos;k2&apos;: &apos;v2&apos;}) r.mset(k1=&quot;v1&quot;, k2=&quot;v2&quot;) # 这里k1 和k2 不能带引号 一次设置对个键值对 print(r.mget(&quot;k1&quot;, &quot;k2&quot;)) # 一次取出多个键对应的值 print(r.mget(&quot;k1&quot;)) mgetmget(keys, *args) 批量获取 如： print(r.mget(&apos;k1&apos;, &apos;k2&apos;)) print(r.mget([&apos;k1&apos;, &apos;k2&apos;])) print(r.mget(&quot;fruit&quot;, &quot;fruit1&quot;, &quot;fruit2&quot;, &quot;k1&quot;, &quot;k2&quot;)) # 将目前redis缓存中的键对应的值批量取出来 getsetgetset(name, value) 设置新值并获取原来的值 print(r.getset(&quot;food&quot;, &quot;barbecue&quot;)) # 设置的新值是barbecue 设置前的值是beef1 getrange getrange(key, start, end) 获取子序列（根据字节获取，非字符） 参数： name，Redis 的 name start，起始位置（字节） end，结束位置（字节） 如： “君惜大大” ，0-3表示 “君” r.set(&quot;cn_name&quot;, &quot;君惜大大&quot;) # 汉字 print(r.getrange(&quot;cn_name&quot;, 0, 2)) # 取索引号是0-2 前3位的字节 君 切片操作 （一个汉字3个字节 1个字母一个字节 每个字节8bit） print(r.getrange(&quot;cn_name&quot;, 0, -1)) # 取所有的字节 君惜大大 切片操作 r.set(&quot;en_name&quot;,&quot;junxi&quot;) # 字母 print(r.getrange(&quot;en_name&quot;, 0, 2)) # 取索引号是0-2 前3位的字节 jun 切片操作 （一个汉字3个字节 1个字母一个字节 每个字节8bit） print(r.getrange(&quot;en_name&quot;, 0, -1)) # 取所有的字节 junxi 切片操作 setrangesetrange(name, offset, value) 修改字符串内容，从指定字符串索引开始向后替换（新值太长时，则向后添加） 参数： offset，字符串的索引，字节（一个汉字三个字节） value，要设置的值 r.setrange(&quot;en_name&quot;, 1, &quot;ccc&quot;) print(r.get(&quot;en_name&quot;)) # jccci 原始值是junxi 从索引号是1开始替换成ccc 变成 jccci2 setbitsetbit(name, offset, value) 对name对应值的二进制表示的位进行操作 参数： name，redis的name offset，位的索引（将值变换成二进制后再进行索引） value，值只能是 1 或 0 注：如果在Redis中有一个对应： n1 = &quot;foo&quot;， 那么字符串foo的二进制表示为：01100110 01101111 01101111 所以，如果执行 setbit(&apos;n1&apos;, 7, 1)，则就会将第7位设置为1， 那么最终二进制则变成 01100111 01101111 01101111，即：&quot;goo&quot; 扩展，转换二进制表示： source = &quot;郭加磊&quot; source = &quot;foo&quot; for i in source: num = ord(i) print bin(num).replace(&apos;b&apos;,&apos;&apos;) 特别的，如果source是汉字 &quot;郭加磊&quot;怎么办？ 答：对于utf-8，每一个汉字占 3 个字节，那么 &quot;郭加磊&quot; 则有 9个字节 对于汉字，for循环时候会按照 字节 迭代，那么在迭代时，将每一个字节转换 十进制数，然后再将十进制数转换成二进制 11100110 10101101 10100110 11100110 10110010 10011011 11101001 10111101 10010000 getbitgetbit(name, offset) 获取name对应的值的二进制表示中的某位的值 （0或1） print(r.getbit(&quot;foo1&quot;, 0)) # 0 foo1 对应的二进制 4个字节 32位 第0位是0还是1 bitcount bitcount(key, start=None, end=None) 获取name对应的值的二进制表示中 1 的个数 参数： key，Redis的name start 字节起始位置 end，字节结束位置 print(r.get(&quot;foo&quot;)) # goo1 01100111 print(r.bitcount(&quot;foo&quot;,0,1)) # 11 表示前2个字节中，1出现的个数 bittopbitop(operation, dest, *keys) 获取多个值，并将值做位运算，将最后的结果保存至新的name对应的值 参数： operation,AND（并） 、 OR（或） 、 NOT（非） 、 XOR（异或） dest, 新的Redis的name *keys,要查找的Redis的name 如： bitop(&quot;AND&quot;, &apos;new_name&apos;, &apos;n1&apos;, &apos;n2&apos;, &apos;n3&apos;) 获取Redis中n1,n2,n3对应的值，然后讲所有的值做位运算（求并集），然后将结果保存 new_name 对应的值中 r.set(&quot;foo&quot;,&quot;1&quot;) # 0110001 r.set(&quot;foo1&quot;,&quot;2&quot;) # 0110010 print(r.mget(&quot;foo&quot;,&quot;foo1&quot;)) # [&apos;goo1&apos;, &apos;baaanew&apos;] print(r.bitop(&quot;AND&quot;,&quot;new&quot;,&quot;foo&quot;,&quot;foo1&quot;)) # &quot;new&quot; 0 0110000 print(r.mget(&quot;foo&quot;,&quot;foo1&quot;,&quot;new&quot;)) source = &quot;12&quot; for i in source: num = ord(i) print(num) # 打印每个字母字符或者汉字字符对应的ascii码值 f-102-0b100111-01100111 print(bin(num)) # 打印每个10进制ascii码值转换成二进制的值 0b1100110（0b表示二进制） print bin(num).replace(&apos;b&apos;,&apos;&apos;) # 将二进制0b1100110替换成01100110 strlenstrlen(name) 返回name对应值的字节长度（一个汉字3个字节） print(r.strlen(&quot;foo&quot;)) # 4 &apos;goo1&apos;的长度是4 incr incr(self, name, amount=1) 自增 name对应的值，当name不存在时，则创建name＝amount，否则，则自增。 参数： name,Redis的name amount,自增数（必须是整数） 注：同incrby r.set(&quot;foo&quot;, 123) print(r.mget(&quot;foo&quot;, &quot;foo1&quot;, &quot;foo2&quot;, &quot;k1&quot;, &quot;k2&quot;)) r.incr(&quot;foo&quot;, amount=1) print(r.mget(&quot;foo&quot;, &quot;foo1&quot;, &quot;foo2&quot;, &quot;k1&quot;, &quot;k2&quot;)) 应用场景 – 页面点击数 假定我们对一系列页面需要记录点击次数。例如论坛的每个帖子都要记录点击次数，而点击次数比回帖的次数的多得多。如果使用关系数据库来存储点击，可能存在大量的行级锁争用。所以，点击数的增加使用redis的INCR命令最好不过了。 当redis服务器启动时，可以从关系数据库读入点击数的初始值（12306这个页面被访问了34634次） r.set(&quot;visit:12306:totals&quot;, 34634) print(r.get(&quot;visit:12306:totals&quot;)) 每当有一个页面点击，则使用INCR增加点击数即可。 r.incr(&quot;visit:12306:totals&quot;) r.incr(&quot;visit:12306:totals&quot;) 页面载入的时候则可直接获取这个值 print(r.get(&quot;visit:12306:totals&quot;)) incrfloatincrbyfloat(self, name, amount=1.0) 自增 name对应的值，当name不存在时，则创建name＝amount，否则，则自增。 参数： name,Redis的name amount,自增数（浮点型） r.set(&quot;foo1&quot;, &quot;123.0&quot;) r.set(&quot;foo2&quot;, &quot;221.0&quot;) print(r.mget(&quot;foo1&quot;, &quot;foo2&quot;)) r.incrbyfloat(&quot;foo1&quot;, amount=2.0) r.incrbyfloat(&quot;foo2&quot;, amount=3.0) print(r.mget(&quot;foo1&quot;, &quot;foo2&quot;)) decrdecr(self, name, amount=1) 自减 name对应的值，当name不存在时，则创建name＝amount，否则，则自减。 参数： name,Redis的name amount,自减数（整数) r.decr(&quot;foo4&quot;, amount=3) # 递减3 r.decr(&quot;foo1&quot;, amount=1) # 递减1 print(r.mget(&quot;foo1&quot;, &quot;foo4&quot;)) appendappend(key, value) 在redis name对应的值后面追加内容 参数： key, redis的name value, 要追加的字符串 r.append(&quot;name&quot;, &quot;haha&quot;) # 在name对应的值junxi后面追加字符串haha print(r.mget(&quot;name&quot;)) hash操作hset1.单个增加–修改(单个取出)–没有就新增，有的话就修改hset(name, key, value) name对应的hash中设置一个键值对（不存在，则创建；否则，修改） 参数： name，redis的name key，name对应的hash中的key value，name对应的hash中的value 注： hsetnx(name, key, value),当name对应的hash中不存在当前key时则创建（相当于添加） import redis import time pool = redis.ConnectionPool(host=&apos;127.0.0.1&apos;, port=6379, decode_responses=True) r = redis.Redis(connection_pool=pool) r.hset(&quot;hash1&quot;, &quot;k1&quot;, &quot;v1&quot;) r.hset(&quot;hash1&quot;, &quot;k2&quot;, &quot;v2&quot;) print(r.hkeys(&quot;hash1&quot;)) # 取hash中所有的key print(r.hget(&quot;hash1&quot;, &quot;k1&quot;)) # 单个取hash的key对应的值 print(r.hmget(&quot;hash1&quot;, &quot;k1&quot;, &quot;k2&quot;)) # 多个取hash的key对应的值 r.hsetnx(&quot;hash1&quot;, &quot;k2&quot;, &quot;v3&quot;) # 只能新建 print(r.hget(&quot;hash1&quot;, &quot;k2&quot;)) hmset批量增加（取出） hmset(name, mapping) 在name对应的hash中批量设置键值对 参数： name，redis的name mapping，字典，如：{‘k1’:’v1’, ‘k2’: ‘v2’} 如： r.hmset(&quot;hash2&quot;, {&quot;k2&quot;: &quot;v2&quot;, &quot;k3&quot;: &quot;v3&quot;}) hget(name,key) 在name对应的hash中获取根据key获取value hmget hmget(name, keys, *args) 在name对应的hash中获取多个key的值 参数： name，reids对应的name keys，要获取key集合，如：[‘k1’, ‘k2’, ‘k3’] *args，要获取的key，如：k1,k2,k3 如： print(r.hget(&quot;hash2&quot;, &quot;k2&quot;)) # 单个取出&quot;hash2&quot;的key-k2对应的value print(r.hmget(&quot;hash2&quot;, &quot;k2&quot;, &quot;k3&quot;)) # 批量取出&quot;hash2&quot;的key-k2 k3对应的value --方式1 print(r.hmget(&quot;hash2&quot;, [&quot;k2&quot;, &quot;k3&quot;])) # 批量取出&quot;hash2&quot;的key-k2 k3对应的value hgetall取出所有的键值对 hgetall(name) 获取name对应hash的所有键值 print(r.hgetall(&quot;hash1&quot;)) hlen得到所有键值对的格式 hash长度 hlen(name)获取name对应的hash中键值对的个数 print(r.hlen(&quot;hash1&quot;)) hkeys得到所有的keys（类似字典的取所有keys） hkeys(name)获取name对应的hash中所有的key的值 print(r.hkeys(&quot;hash1&quot;)) hvals得到所有的value（类似字典的取所有value） hvals(name)获取name对应的hash中所有的value的值 print(r.hvals(&quot;hash1&quot;)) hexists判断成员是否存在（类似字典的in） hexists(name, key)检查name对应的hash是否存在当前传入的key print(r.hexists(&quot;hash1&quot;, &quot;k4&quot;)) # False 不存在 print(r.hexists(&quot;hash1&quot;, &quot;k1&quot;)) # True 存在 hdel删除键值对 hdel(name,*keys) 将name对应的hash中指定key的键值对删除 print(r.hgetall(&quot;hash1&quot;)) r.hset(&quot;hash1&quot;, &quot;k2&quot;, &quot;v222&quot;) # 修改已有的key k2 r.hset(&quot;hash1&quot;, &quot;k11&quot;, &quot;v1&quot;) # 新增键值对 k11 r.hdel(&quot;hash1&quot;, &quot;k1&quot;) # 删除一个键值对 print(r.hgetall(&quot;hash1&quot;)) hincrby自增自减整数(将key对应的value–整数 自增1或者2，或者别的整数 负数就是自减) hincrby(name, key, amount=1) 自增name对应的hash中的指定key的值，不存在则创建key=amount 参数： name，redis中的name key， hash对应的key amount，自增数（整数） r.hset(&quot;hash1&quot;, &quot;k3&quot;, 123) r.hincrby(&quot;hash1&quot;, &quot;k3&quot;, amount=-1) print(r.hgetall(&quot;hash1&quot;)) r.hincrby(&quot;hash1&quot;, &quot;k4&quot;, amount=1) # 不存在的话，value默认就是1 print(r.hgetall(&quot;hash1&quot;)) hincrbyfloat自增自减浮点数(将key对应的value–浮点数 自增1.0或者2.0，或者别的浮点数 负数就是自减) hincrbyfloat(name, key, amount=1.0) 自增name对应的hash中的指定key的值，不存在则创建key=amount 参数： name，redis中的name key， hash对应的key amount，自增数（浮点数） 自增name对应的hash中的指定key的值，不存在则创建key=amount r.hset(&quot;hash1&quot;, &quot;k5&quot;, &quot;1.0&quot;) r.hincrbyfloat(&quot;hash1&quot;, &quot;k5&quot;, amount=-1.0) # 已经存在，递减-1.0 print(r.hgetall(&quot;hash1&quot;)) r.hincrbyfloat(&quot;hash1&quot;, &quot;k6&quot;, amount=-1.0) # 不存在，value初始值是-1.0 每次递减1.0 print(r.hgetall(&quot;hash1&quot;)) hscan取值查看–分片读取 hscan(name, cursor=0, match=None, count=None) 增量式迭代获取，对于数据大的数据非常有用，hscan可以实现分片的获取数据，并非一次性将数据全部获取完，从而放置内存被撑爆 参数： name，redis的name cursor，游标（基于游标分批取获取数据） match，匹配指定key，默认None 表示所有的key count，每次分片最少获取个数，默认None表示采用Redis的默认分片个数 如： 第一次：cursor1, data1 = r.hscan(‘xx’, cursor=0, match=None, count=None) 第二次：cursor2, data1 = r.hscan(‘xx’, cursor=cursor1, match=None, count=None) … 直到返回值cursor的值为0时，表示数据已经通过分片获取完毕 print(r.hscan(&quot;hash1&quot;)) hscan_iterhscan_iter(name, match=None, count=None) 利用yield封装hscan创建生成器，实现分批去redis中获取数据 参数： match，匹配指定key，默认None 表示所有的key count，每次分片最少获取个数，默认None表示采用Redis的默认分片个数 如： for item in r.hscan_iter(&apos;hash1&apos;): print(item) print(r.hscan_iter(&quot;hash1&quot;)) # 生成器内存地址 list列表操作lpush增加（类似于list的append，只是这里是从左边新增加）–没有就新建 lpush(name,values) 在name对应的list中添加元素，每个新的元素都添加到列表的最左边 如： import redis import time pool = redis.ConnectionPool(host=&apos;127.0.0.1&apos;, port=6379, decode_responses=True) r = redis.Redis(connection_pool=pool) r.lpush(&quot;list1&quot;, 11, 22, 33) print(r.lrange(&apos;list1&apos;, 0, -1)) 保存顺序为: 33,22,11 扩展： r.rpush(&quot;list2&quot;, 11, 22, 33) # 表示从右向左操作 print(r.llen(&quot;list2&quot;)) # 列表长度 print(r.lrange(&quot;list2&quot;, 0, 3)) # 切片取出值，范围是索引号0-3 rpush增加（从右边增加）–没有就新建 r.rpush(&quot;list2&quot;, 44, 55, 66) # 在列表的右边，依次添加44,55,66 print(r.llen(&quot;list2&quot;)) # 列表长度 print(r.lrange(&quot;list2&quot;, 0, -1)) # 切片取出值，范围是索引号0到-1(最后一个元素) lpushx 往已经有的name的列表的左边添加元素，没有的话无法创建 lpushx(name,value)在name对应的list中添加元素，只有name已经存在时，值添加到列表的最左边 更多： r.lpushx(&quot;list10&quot;, 10) # 这里list10不存在 print(r.llen(&quot;list10&quot;)) # 0 print(r.lrange(&quot;list10&quot;, 0, -1)) # [] r.lpushx(&quot;list2&quot;, 77) # 这里&quot;list2&quot;之前已经存在，往列表最左边添加一个元素，一次只能添加一个 print(r.llen(&quot;list2&quot;)) # 列表长度 print(r.lrange(&quot;list2&quot;, 0, -1)) # 切片取出值，范围是索引号0到-1(最后一个元素 rpushx往已经有的name的列表的右边添加元素，没有的话无法创建 r.rpushx(&quot;list2&quot;, 99) # 这里&quot;foo_list1&quot;之前已经存在，往列表最右边添加一个元素，一次只能添加一个 print(r.llen(&quot;list2&quot;)) # 列表长度 print(r.lrange(&quot;list2&quot;, 0, -1)) # 切片取出值，范围是索引号0到-1(最后一个元素) linsert新增（固定索引号位置插入元素） linsert(name, where, refvalue, value)) 在name对应的列表的某一个值前或后插入一个新值 参数： name，redis的name where，BEFORE或AFTER refvalue，标杆值，即：在它前后插入数据 value，要插入的数据 r.linsert(&quot;list2&quot;, &quot;before&quot;, &quot;11&quot;, &quot;00&quot;) # 往列表中左边第一个出现的元素&quot;11&quot;前插入元素&quot;00&quot; print(r.lrange(&quot;list2&quot;, 0, -1)) # 切片取出值，范围是索引号0-最后一个元素 lset修改（指定索引号进行修改） r.lset(name, index, value) 对name对应的list中的某一个索引位置重新赋值 参数： name，redis的name index，list的索引位置 value，要设置的值 r.lset(&quot;list2&quot;, 0, -11) # 把索引号是0的元素修改成-11 print(r.lrange(&quot;list2&quot;, 0, -1)) lrem删除（指定值进行删除） r.lrem(name, value, num) 在name对应的list中删除指定的值 参数： name，redis的name value，要删除的值 num， num=0，删除列表中所有的指定值； num=2,从前到后，删除2个； num=1,从前到后，删除左边第1个 num=-2,从后向前，删除2个 r.lrem(&quot;list2&quot;, &quot;11&quot;, 1) # 将列表中左边第一次出现的&quot;11&quot;删除 print(r.lrange(&quot;list2&quot;, 0, -1)) r.lrem(&quot;list2&quot;, &quot;99&quot;, -1) # 将列表中右边第一次出现的&quot;99&quot;删除 print(r.lrange(&quot;list2&quot;, 0, -1)) r.lrem(&quot;list2&quot;, &quot;22&quot;, 0) # 将列表中所有的&quot;22&quot;删除 print(r.lrange(&quot;list2&quot;, 0, -1)) lpop删除并返回 lpop(name) 在name对应的列表的左侧获取第一个元素并在列表中移除，返回值则是第一个元素 更多： rpop(name) 表示从右向左操作 r.lpop(&quot;list2&quot;) # 删除列表最左边的元素，并且返回删除的元素 print(r.lrange(&quot;list2&quot;, 0, -1)) r.rpop(&quot;list2&quot;) # 删除列表最右边的元素，并且返回删除的元素 print(r.lrange(&quot;list2&quot;, 0, -1)) ltrim删除索引之外的值 ltrim(name, start, end) 在name对应的列表中移除没有在start-end索引之间的值 参数： name，redis的name start，索引的起始位置 end，索引结束位置 r.ltrim(&quot;list2&quot;, 0, 2) # 删除索引号是0-2之外的元素，值保留索引号是0-2的元素 print(r.lrange(&quot;list2&quot;, 0, -1)) lindex取值（根据索引号取值） lindex(name, index) 在name对应的列表中根据索引获取列表元素 print(r.lindex(&quot;list2&quot;, 0)) # 取出索引号是0的值 rpoplpush移动 元素从一个列表移动到另外一个列表 rpoplpush(src, dst) 从一个列表取出最右边的元素，同时将其添加至另一个列表的最左边 参数： src，要取数据的列表的name dst，要添加数据的列表的name r.rpoplpush(&quot;list1&quot;, &quot;list2&quot;) print(r.lrange(&quot;list2&quot;, 0, -1)) brpoplpush 移动 元素从一个列表移动到另外一个列表 可以设置超时 brpoplpush(src, dst, timeout=0) 从一个列表的右侧移除一个元素并将其添加到另一个列表的左侧 参数： src，取出并要移除元素的列表对应的name dst，要插入元素的列表对应的name timeout，当src对应的列表中没有数据时，阻塞等待其有数据的超时时间（秒），0 表示永远阻塞 r.brpoplpush(&quot;list1&quot;, &quot;list2&quot;, timeout=2) print(r.lrange(&quot;list2&quot;, 0, -1)) ##blpop 一次移除多个列表 blpop(keys, timeout) 将多个列表排列，按照从左到右去pop对应列表的元素 参数： keys，redis的name的集合 timeout，超时时间，当元素所有列表的元素获取完之后，阻塞等待列表内有数据的时间（秒）, 0 表示永远阻塞 更多：r.brpop(keys, timeout) 同blpop，将多个列表排列,按照从右像左去移除各个列表内的元素 r.lpush(&quot;list10&quot;, 3, 4, 5) r.lpush(&quot;list11&quot;, 3, 4, 5) while True: r.blpop([&quot;list10&quot;, &quot;list11&quot;], timeout=2) print(r.lrange(&quot;list10&quot;, 0, -1), r.lrange(&quot;list11&quot;, 0, -1)) 自定义增量迭代 由于redis类库中没有提供对列表元素的增量迭代，如果想要循环name对应的列表的所有元素，那么就需要： 获取name对应的所有列表 循环列表 但是，如果列表非常大，那么就有可能在第一步时就将程序的内容撑爆，所有有必要自定义一个增量迭代的功能： def list_iter(name): &quot;&quot;&quot; 自定义redis列表增量迭代 :param name: redis中的name，即：迭代name对应的列表 :return: yield 返回 列表元素 &quot;&quot;&quot; list_count = r.llen(name) for index in range(list_count): yield r.lindex(name, index) # 使用 for item in list_iter(&apos;list2&apos;): # 遍历这个列表 print(item) 集合set操作sadd新增 sadd(name,values) name对应的集合中添加元素 r.sadd(&quot;set1&quot;, 33, 44, 55, 66) # 往集合中添加元素 print(r.scard(&quot;set1&quot;)) # 集合的长度是4 print(r.smembers(&quot;set1&quot;)) # 获取集合中所有的成员 scard获取元素个数 类似于len scard(name) 获取name对应的集合中元素个数 print(r.scard(&quot;set1&quot;)) # 集合的长度是4 smembers获取集合中所有的成员 smembers(name) 获取name对应的集合的所有成员 print(r.smembers(&quot;set1&quot;)) # 获取集合中所有的成员 获取集合中所有的成员–元组形式 sscan(name, cursor=0, match=None, count=None) print(r.sscan(&quot;set1&quot;)) 1 获取集合中所有的成员–迭代器的方式 sscan_iter(name, match=None, count=None) 同字符串的操作，用于增量迭代分批获取元素，避免内存消耗太大 for i in r.sscan_iter(&quot;set1&quot;): print(i)2 sdiff差集 sdiff(keys, *args) 在第一个name对应的集合中且不在其他name对应的集合的元素集合 r.sadd(&quot;set2&quot;, 11, 22, 33) print(r.smembers(&quot;set1&quot;)) # 获取集合中所有的成员 print(r.smembers(&quot;set2&quot;)) print(r.sdiff(&quot;set1&quot;, &quot;set2&quot;)) # 在集合set1但是不在集合set2中 print(r.sdiff(&quot;set2&quot;, &quot;set1&quot;)) # 在集合set2但是不在集合set1中 sdiffstore差集–差集存在一个新的集合中 sdiffstore(dest, keys, *args) 获取第一个name对应的集合中且不在其他name对应的集合，再将其新加入到dest对应的集合中 r.sdiffstore(&quot;set3&quot;, &quot;set1&quot;, &quot;set2&quot;) # 在集合set1但是不在集合set2中 print(r.smembers(&quot;set3&quot;)) # 获取集合3中所有的成员 sinter交集 sinter(keys, *args) 获取多一个name对应集合的交集 print(r.sinter(&quot;set1&quot;, &quot;set2&quot;)) # 取2个集合的交集 sinterstore交集–交集存在一个新的集合中 sinterstore(dest, keys, *args) 获取多一个name对应集合的并集，再将其加入到dest对应的集合中 print(r.sinterstore(&quot;set3&quot;, &quot;set1&quot;, &quot;set2&quot;)) # 取2个集合的交集 print(r.smembers(&quot;set3&quot;)) ## sunion 并集 sunion(keys, *args) 获取多个name对应的集合的并集 print(r.sunion(&quot;set1&quot;, &quot;set2&quot;)) # 取2个集合的并集1 并集–并集存在一个新的集合 sunionstore(dest,keys, *args) 获取多一个name对应的集合的并集，并将结果保存到dest对应的集合中 print(r.sunionstore(&quot;set3&quot;, &quot;set1&quot;, &quot;set2&quot;)) # 取2个集合的并集 print(r.smembers(&quot;set3&quot;)) sismember判断是否是集合的成员 类似in sismember(name, value) 检查value是否是name对应的集合的成员，结果为True和False print(r.sismember(&quot;set1&quot;, 33)) # 33是集合的成员 print(r.sismember(&quot;set1&quot;, 23)) # 23不是集合的成员 smove移动 smove(src, dst, value) 将某个成员从一个集合中移动到另外一个集合 r.smove(&quot;set1&quot;, &quot;set2&quot;, 44) print(r.smembers(&quot;set1&quot;)) print(r.smembers(&quot;set2&quot;)) spop删除–随机删除并且返回被删除值 spop(name) 从集合移除一个成员，并将其返回,说明一下，集合是无序的，所有是随机删除的 print(r.spop(&quot;set2&quot;)) # 这个删除的值是随机删除的，集合是无序的 print(r.smembers(&quot;set2&quot;)) srem11.删除–指定值删除 srem(name, values) 在name对应的集合中删除某些值 print(r.srem(&quot;set2&quot;, 11)) # 从集合中删除指定值 11 print(r.smembers(&quot;set2&quot;)) 有序集合sort set操作redis基本命令 有序set Set操作，Set集合就是不允许重复的列表，本身是无序的 有序集合，在集合的基础上，为每元素排序；元素的排序需要根据另外一个值来进行比较， 所以，对于有序集合，每一个元素有两个值，即：值和分数，分数专门用来做排序。 zadd新增 zadd(name, args, *kwargs) 在name对应的有序集合中添加元素 如： import redis import time pool = redis.ConnectionPool(host=&apos;127.0.0.1&apos;, port=6379, decode_responses=True) r = redis.Redis(connection_pool=pool) r.zadd(&quot;zset1&quot;, n1=11, n2=22) r.zadd(&quot;zset2&quot;, &apos;m1&apos;, 22, &apos;m2&apos;, 44) print(r.zcard(&quot;zset1&quot;)) # 集合长度 print(r.zcard(&quot;zset2&quot;)) # 集合长度 print(r.zrange(&quot;zset1&quot;, 0, -1)) # 获取有序集合中所有元素 print(r.zrange(&quot;zset2&quot;, 0, -1, withscores=True)) # 获取有序集合中所有元素和分数2 zcard获取有序集合元素个数 类似于len zcard(name) 获取name对应的有序集合元素的数量 print(r.zcard(&quot;zset1&quot;)) # 集合长度1 zrange获取有序集合的所有元素 r.zrange( name, start, end, desc=False, withscores=False, score_cast_func=float) 按照索引范围获取name对应的有序集合的元素 参数： name，redis的name start，有序集合索引起始位置（非分数） end，有序集合索引结束位置（非分数） desc，排序规则，默认按照分数从小到大排序 withscores，是否获取元素的分数，默认只获取元素的值 score_cast_func，对分数进行数据转换的函数 zrevrange3-1 从大到小排序(同zrange，集合是从大到小排序的) zrevrange(name, start, end, withscores=False, score_cast_func=float) print(r.zrevrange(&quot;zset1&quot;, 0, -1)) # 只获取元素，不显示分数 print(r.zrevrange(&quot;zset1&quot;, 0, -1, withscores=True)) # 获取有序集合中所有元素和分数,分数倒序 zrangebyscore3-2 按照分数范围获取name对应的有序集合的元素 zrangebyscore(name, min, max, start=None, num=None, withscores=False, score_cast_func=float) for i in range(1, 30): element = &apos;n&apos; + str(i) r.zadd(&quot;zset3&quot;, element, i) print(r.zrangebyscore(&quot;zset3&quot;, 15, 25)) # # 在分数是15-25之间，取出符合条件的元素 print(r.zrangebyscore(&quot;zset3&quot;, 12, 22, withscores=True)) # 在分数是12-22之间，取出符合条件的元素（带分数） zrevrangebyscore3-3 按照分数范围获取有序集合的元素并排序（默认从大到小排序） zrevrangebyscore(name, max, min, start=None, num=None, withscores=False, score_cast_func=float) print(r.zrevrangebyscore(&quot;zset3&quot;, 22, 11, withscores=True)) # 在分数是22-11之间，取出符合条件的元素 按照分数倒序1 zscan3-4 获取所有元素–默认按照分数顺序排序 zscan(name, cursor=0, match=None, count=None, score_cast_func=float) print(r.zscan(&quot;zset3&quot;))1 zscan_iter3-5 获取所有元素–迭代器 zscan_iter(name, match=None, count=None,score_cast_func=float) for i in r.zscan_iter(&quot;zset3&quot;): # 遍历迭代器 print(i) ## zcount zcount(name, min, max) 获取name对应的有序集合中分数 在 [min,max] 之间的个数 print(r.zrange(&quot;zset3&quot;, 0, -1, withscores=True)) print(r.zcount(&quot;zset3&quot;, 11, 22)) zincrby自增 zincrby(name, value, amount) 自增name对应的有序集合的 name 对应的分数 r.zincrby(&quot;zset3&quot;, &quot;n2&quot;, amount=2) # 每次将n2的分数自增2 print(r.zrange(&quot;zset3&quot;, 0, -1, withscores=True)) zrank获取值的索引号 zrank(name, value) 获取某个值在 name对应的有序集合中的索引（从 0 开始） 更多： zrevrank(name, value)，从大到小排序 print(r.zrank(&quot;zset3&quot;, &quot;n1&quot;)) # n1的索引号是0 这里按照分数顺序（从小到大） print(r.zrank(&quot;zset3&quot;, &quot;n6&quot;)) # n6的索引号是1 print(r.zrevrank(&quot;zset3&quot;, &quot;n1&quot;)) # n1的索引号是29 这里安照分数倒序（从大到小） zrem删除–指定值删除 zrem(name, values) 删除name对应的有序集合中值是values的成员 r.zrem(&quot;zset3&quot;, &quot;n3&quot;) # 删除有序集合中的元素n3 删除单个 print(r.zrange(&quot;zset3&quot;, 0, -1)) zremrangebyrank删除–根据排行范围删除，按照索引号来删除 zremrangebyrank(name, min, max) 根据排行范围删除 r.zremrangebyrank(&quot;zset3&quot;, 0, 1) # 删除有序集合中的索引号是0, 1的元素 print(r.zrange(&quot;zset3&quot;, 0, -1)) zremrangebyscore(name, min, max) 根据分数范围删除 r.zremrangebyscore(&quot;zset3&quot;, 11, 22) # 删除有序集合中的分数是11-22的元素 print(r.zrange(&quot;zset3&quot;, 0, -1)) zscore获取值对应的分数 zscore(name, value) 获取name对应有序集合中 value 对应的分数 print(r.zscore(&quot;zset3&quot;, &quot;n27&quot;)) # 获取元素n27对应的分数271 其他常用操作deletedelete (*names) 根据删除redis中的任意数据类型（string、hash、list、set、有序set） r.delete(&quot;gender&quot;) # 删除key为gender的键值对1 exists检查名字是否存在 exists(name) 检测redis的name是否存在，存在就是True，False 不存在 print(r.exists(&quot;zset1&quot;))1 keys 模糊匹配 keys(pattern=’‘) 根据模型获取redis的name 更多： KEYS 匹配数据库中所有 key 。 KEYS h?llo 匹配 hello ， hallo 和 hxllo 等。 KEYS h*llo 匹配 hllo 和 heeeeello 等。 KEYS h[ae]llo 匹配 hello 和 hallo ，但不匹配 hillo print(r.keys(&quot;foo*&quot;)) 1 expire设置超时时间 expire(name ,time) 为某个redis的某个name设置超时时间 r.lpush(&quot;list5&quot;, 11, 22) r.expire(&quot;list5&quot;, time=3) print(r.lrange(&quot;list5&quot;, 0, -1)) time.sleep(3) print(r.lrange(&quot;list5&quot;, 0, -1)) rname重命名 rename(src, dst) 对redis的name重命名 r.lpush(&quot;list5&quot;, 11, 22) r.rename(&quot;list5&quot;, &quot;list5-1&quot;) randomkey 随机获取name randomkey() 随机获取一个redis的name（不删除） print(r.randomkey()) 1 type获取类型 type(name) 获取name对应值的类型 print(r.type(&quot;set1&quot;)) print(r.type(&quot;hash2&quot;)) scan查看所有元素 scan(cursor=0, match=None, count=None) print(r.hscan(&quot;hash2&quot;)) print(r.sscan(&quot;set3&quot;)) print(r.zscan(&quot;zset2&quot;)) print(r.getrange(&quot;foo1&quot;, 0, -1)) print(r.lrange(&quot;list2&quot;, 0, -1)) print(r.smembers(&quot;set3&quot;)) print(r.zrange(&quot;zset3&quot;, 0, -1)) print(r.hgetall(&quot;hash1&quot;)) scan_iter查看所有元素–迭代器 scan_iter(match=None, count=None) for i in r.hscan_iter(&quot;hash1&quot;): print(i) for i in r.sscan_iter(&quot;set3&quot;): print(i) for i in r.zscan_iter(&quot;zset3&quot;): print(i)8 other 方法print(r.get(&apos;name&apos;)) # 查询key为name的值 r.delete(&quot;gender&quot;) # 删除key为gender的键值对 print(r.keys()) # 查询所有的Key print(r.dbsize()) # 当前redis包含多少条数据 r.save() # 执行&quot;检查点&quot;操作，将数据写回磁盘。保存时阻塞 # r.flushdb() # 清空r中的所有数据 管道（pipeline） redis默认在执行每次请求都会创建（连接池申请连接）和断开（归还连接池）一次连接操作， 如果想要在一次请求中指定多个命令，则可以使用pipline实现一次请求指定多个命令，并且默认情况下一次pipline 是原子性操作。 管道（pipeline）是redis在提供单个请求中缓冲多条服务器命令的基类的子类。它通过减少服务器-客户端之间反复的TCP数据库包，从而大大提高了执行批量命令的功能。 import redis import time pool = redis.ConnectionPool(host=&apos;127.0.0.1&apos;, port=6379, decode_responses=True) r = redis.Redis(connection_pool=pool) # pipe = r.pipeline(transaction=False) # 默认的情况下，管道里执行的命令可以保证执行的原子性，执行pipe = r.pipeline(transaction=False)可以禁用这一特性。 # pipe = r.pipeline(transaction=True) pipe = r.pipeline() # 创建一个管道 pipe.set(&apos;name&apos;, &apos;jack&apos;) pipe.set(&apos;role&apos;, &apos;sb&apos;) pipe.sadd(&apos;faz&apos;, &apos;baz&apos;) pipe.incr(&apos;num&apos;) # 如果num不存在则vaule为1，如果存在，则value自增1 pipe.execute() print(r.get(&quot;name&quot;)) print(r.get(&quot;role&quot;)) print(r.get(&quot;num&quot;)) 管道的命令可以写在一起，如： pipe.set(&apos;hello&apos;, &apos;redis&apos;).sadd(&apos;faz&apos;, &apos;baz&apos;).incr(&apos;num&apos;).execute() print(r.get(&quot;name&quot;)) print(r.get(&quot;role&quot;)) print(r.get(&quot;num&quot;))]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux基本系统优化]]></title>
    <url>%2F2018%2F03%2F18%2FLinux%E5%9F%BA%E6%9C%AC%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Linux的网络功能相当强悍，一时之间我们无法了解所有的网络命令， 在配置服务器基础环境时，先了解下网络参数设定命令。 ifconfig 查询、设置网卡和ip等参数 ifup,ifdown 脚本命令，更简单的方式启动关闭网络 ip 符合指令，直接修改上述功能 在我们刚装好linux的时候，需要用xshell进行远程连接，那就得获取ip地址，有时 候网卡默认是没启动的，Linux也就拿不到ip地址，因此我们得手动启动网卡 #编辑网卡配置文件 vim /etc/sysconfig/network-scripts/ifcfg-eth0 #修改配置参数 ONBOOT=yes 网卡配置文件详细网络配置文件： /etc/sysconfig/network 网络接口配置文件： /etc/sysconfig/network-scripts/ifcfg-INTERFACE_NAME DEVICE=: 关联的设备名称，要与文件名的后半部“INTERFACE_NAME”保持一致; BOOTPROTO={static|none|dhcp|bootp}: 引导协议；要使用静态地址，使用static或none；dhcp表示使用DHCP服务器获取地址； IPADDR=: IP地址 NETMASK=：子网掩码 GATEWAY=：设定默认网关； ONBOOT=：开机时是否自动激活此网络接口； HWADDR=： 硬件地址，要与硬件中的地址保持一致；可省； USERCTL={yes|no}: 是否允许普通用户控制此接口； PEERDNS={yes|no}: 是否在BOOTPROTO为dhcp时接受由DHCP服务器指定的DNS地址； ifup，ifdown启动/关闭一块网卡 ifup eth0（网卡名） ifdown eth0（网卡名） --- 如果关闭网卡，xshell会怎样? 会卡主不动啊 ifconfigifconfig 查看网卡的ip地址 直接输入ifconfig会列出已经启动的网卡，也可以输入ifconfig eth0单独显示eth0的信息 各选项解释是： eth0 网卡的代号 lo 回环地址loopback inet IPv4的Ip地址 netmask 子网掩码 broadcast 广播地址 RX/TX 流量发/收情况 tx是发送（transport），rx是接收(receive) packets 数据包数 errors 数据包错误数 dropped 数据包有问题被丢弃的数量 collisions 数据包碰撞情况，数值太多代表网络状况差 ifup,ifdown命令ifup和ifdown是直接连接到/etc/sysconfig/network-scripts目录下搜索对应的网卡文件， 例如ifcfg-eth0然后加以设置 ip命令ip是一个命令，不是TCP/IP那个ip，这个ip命令是结合了ifconfig和route两个命令的功能。 ip addr show #查看ip信息 了解了如何查看网卡信息，接下来查看系统信息。系统是什么版本？ #查看系统版本信息 cat /etc/redhat-release CentOS Linux release 7.4.1708 (Core) #查看内核版本号 uname -r 3.10.0-693.el7.x86_64 #查看系统多少位 uname -m x86_64 #查看内核所有信息 uname -a 用户管理与文件权限现代操作系统一般属于多用户的操作系统，也就是说，同一台机器可以为多个用户建立 账户，一般这些用户都是为普通用户，这些普通用户能同时登录这台计算机，计算机对 这些用户分配一定的资源。 普通用户在所分配到的资源内进行各自的操作，相互之间不受影响。但是这些普通用户 的权限是有限制的，且用户太多的话，管理就不便，从而引入root用户。 此用户是唯一的，且拥有系统的所有权限。root用户所在的组称为root组。“组”是具 有相似权限的多个用户的集合。 root的权利 Linux系统的特性就是可以满足多个用户，同时工作，因此Linux系统必须具备很好的 安全性。 在安装RHEL7时设置的root管理员密码，这个root管理员就是所有UNIX系统中的超级 用户，它拥有最高的系统所有权，能够管理系统的各项功能，如添加/删除用户，启动/ 关闭进程，开启/禁用硬件设备等等。 因此“能力越大，责任越大”，root权限必须很好的掌握，否则一个错误的命令可能会 摧毁整个系统。 root为什么叫root？ 在Linux系统中，用户也有自己的UID身份账号且唯一 系统管理员UID为0 系统用户UID为1~999 Linux安装的服务程序都会创建独有的用户负责运行。 普通用户UID从1000开始：由管理员创建 用户组GID 为了方便管理属于同一组的用户，Linux 系统中还引入了用户组的概念。通过使用用 户组号码(GID，Group IDentification)，我们可以把多个用户加入到同一个组 中，从而方 便为组中的用户统一规划权限或指定任务。 假设有一个公司中有多个部门，每个部门中又 有很多员工。如果只想让员工访问本部 门内的资源，则可以针对部门而非具体的员工来设 置权限。 例如，可以通过对技术部门设置权限，使得只有技术部门的员工可以访问公司的 数据库信息等。 Linux管理员在创建用户时，将自动创建一个与其同名的用户组，这个用户组只有该用户一个人 Linux/unix是一个多用户、多任务的操作系统。 root：默认在Unix/linux操作系统中拥有最高的管理权限。可以理解为qq群的群主 普通用户：是管理员或者具备管理权限的用户所创建的，只能读、看，不能增、删、改。 创建普通用户#添加用户 useradd haiyan #设置密码 passwd redhat root用户可以修改其他所有人的密码，且不需要验证 切换用户su命令su命令可以切换用户身份的需求， su - username su命令中间的-号很重要，意味着完全切换到新的用户，即环境变量信息也变更为新用户的信息 #先看下当前用户（我是谁） whoami #切换用户 su - oldboy #退出用户登录 logout ctrl + d 一般情况下，在生产环境避免直接用root用户，除非有特殊系统维护需求，使用完立刻退回 普通用户 非交互式设置密码(echo &quot;redhat&quot;|passwd --stdin haiyan &amp;&amp; history -c) Tip: 1.超级用户root切换普通用户无需密码,例如“群主”想踢谁就踢谁 2.普通用户切换root，需要输入密码 3.普通用户权限较小，只能基本查看信息 4.$符号是普通用户命令提示符，#是超级管理员的提示符 root是当前用户，oldboyedu是主机名，~代表当前路径，也是家目录 groupadd命令group命令用于创建用户组，为了更加高效的指派系统中各个用户的权限，在工作中常 常添加几个用户到一个组里面，这样可以针对一类用户安排权限。 例如在公司里，就负责添加openLDAP用户管理，偶尔台湾，美国的同事去上 海协作，我就得给他们添加到it部门组里面，以至于他们有对服务器操作的权限。 groupadd it_dep userdel删除用户-f 强制删除用户 -r 同事删除用户以及家目录 userdel -r pyyu sudo命令sudo命令用来以其他身份来执行命令，预设的身份为root。在/etc/sudoers中设置 了可执行sudo指令的用户。若其未经授权的用户企图使用sudo，则会发出警告的邮件 给管理员。用户使用sudo时，必须先输入密码，之后有5分钟的有效期限，超过期限则 必须重新输入密码。 语法 sudo 【选项】【参数】 -b：在后台执行指令； -h：显示帮助； -H：将HOME环境变量设为新身份的HOME环境变量； -k：结束密码的有效期限，也就是下次再执行sudo时便需要输入密码；。 -l：列出目前用户可执行与无法执行的指令； -p：改变询问密码的提示符号； -s&lt;shell&gt;：执行指定的shell； -u&lt;用户&gt;：以指定的用户作为新的身份。若不加上此参数，则预设以root作为新的身份； -v：延长密码有效期限5分钟； -V ：显示版本信息。 实例： 权限不够，这时候需要sudo ls /root 以root身份去运行，haiyan权利小，root 总可以了吧!! 这是由于配置sudo必须编辑/etc/sudoers文件，并且只有root才能修改，可以通过visudo命令直接编辑sudoers文件，使用这个命令还可以检查语法，比直接编辑 vim/etc/sudoers更安全 visudo 编辑sudoers文件 写入 ## Allow root to run any commands anywhere root ALL=(ALL) ALL chaoge ALL=(ALL) ALL #允许chaoge在任何地方，执行任何命令 此时切换chaoge用户 #su命令用于切换当前用户身份到其他用户身份，变更时须输入所要变更的用户帐号与密码。 su - chaoge 已经可以使用sudo ls /root 命令 文件与目录权限Linux权限的目的是（保护账户的资料） Linux权限主要依据三种身份来决定： user/owner 文件使用者,文件属于哪个用户 group 属组,文件属于哪个组 others 既不是user，也不再group，就是other，其他人 什么是权限在Linux中，每个文件都有所属的所有者，和所有组，并且规定了文件的所有者，所有 组以及其他人对文件的，可读，可写，可执行等权限。 对于目录的权限来说，可读是读取目录文件列表，可写是表示在目录内新增，修改，删 除文件。可执行表示可以进入目录 Linux权限的观察使用一条命令查看权限 ls -l /var/log/mysqld.log 权限，第一个字母为文件类型，后续9个字母，每3个一组，是三种身份的权限 文件链接数 文件拥有者-属主 文件拥有组-属组 文件大小 最后一次被修改的时间日期 文件名 先来分析一下文件的类型 - 一般文件 d 文件夹 l 软连接（快捷方式） b 块设备，存储媒体文件为主 c 代表键盘,鼠标等设备 文件权限r read可读，可以用cat等命令查看 w write写入，可以编辑或者删除这个文件 x executable 可以执行 目录权限权限这里测试不要用root实验！！！！root太牛逼了 请用普通用户执行！！！！！测试文件、文件夹权限操作，请用普通用户！ r 可以对此目录执行ls列出所有文件w 可以在这个目录创建文件x 可以cd进入这个目录，或者查看详细信息 权限与数字转化 ls -l /var/log/mysqld.log -rw-r--r-- 1 mysql mysql 6735642 3月 11 14:19 /var/log/mysqld.log 这个就代表mysqld.log文件属主是mysql，属组是mysql，只有mysql用户可以读取编写这个文件，其他人只能读此文件。 查看用户权限命令id指令查看用户所属群主 [root@haiyan ~ 16:34:52]#id root uid=0(root) gid=0(root) 组=0(root) 修改文件权限属性普通用户只能修改自己的文件名，时间与权限（注意） 因此修改其他用户权限，只能用最nb的root用户 #切换root用户 [pyyu@haiyan root]$ su - 当前/tmp/py.txt文件以存在，且信息是 -rw-rw-r-- 1 pyyu pyyu 0 3月 11 16:41 py.txt 修改属主为root chown [root@haiyan /tmp 16:43:12]#chown root py.txt 查看信息 [root@haiyan /tmp 16:43:42]#ll py.txt -rw-rw-r-- 1 root py 0 3月 11 16:41 py.txt 修改属组 chgrp [root@haiyan /tmp 16:43:42]#ll py.txt -rw-rw-r-- 1 root pyyu 0 3月 11 16:41 py.txt [root@haiyan /tmp 16:44:59]#chgrp root py.txt [root@haiyan /tmp 16:45:51]#ll py.txt -rw-rw-r-- 1 root root 0 3月 11 16:41 py.txt 文件权限我们已知三种身份权限（属主，属组，其他人），每种身份都有rwx的三种权限，系统还提供了数字计算权限。 r read 4 w write 2 x execute 1 每种身份最低是0分，最高是r+w+x 7分 因此三种身份，最高权限是777，最低是000 -rw-rw-r-- 1 root root 0 3月 11 16:41 py.txt 因此可知py.txt的权限是 属主是6 r+w(4+2) 属组是6 r+w(4+2) 其他人是4 r(4) 修改权限的命令chmod chmod [身份] [参数] [文件] u(user) +(添加) g(group) -(减去) o(other) =(赋值) a(all) 例如 当前权限 -rw-rw-r-- 1 root root 0 3月 11 16:41 py.txt 方法1 减去属主的写权限 chmod u-w py.txt 查看权限 -r--rw-r-- 1 root root 0 8月 11 16:41 py.txt 方法2 属主添加可读可写可执行权限 chmod 700 py.txt 属主可读可写可执行 属组可读可执行 其他人可读可执行 chmod 755 py.txt 修改文件名，修改文件更改日期 mv py.txt haiyan.txt #触摸，修改时间 touch haiyan.txt 软连接连接也叫做符号链接，类似于windows的快捷方式。 常用于安装软件的快捷方式配置，如python，nginx等 ln -s 目标文件 软连接名 1.存在文件/tmp/test.txt [root@master tmp]# ls -l -rw-r--r-- 1 root root 10 3月 15 21:23 test.txt 2.在/home目录中建立软连接，指向/tmp/test.txt文件 ln -s /tmp/test.txt my_test 3.查看软连接信息 lrwxrwxrwx 1 root root 13 3月 15 21:35 my_test -&gt; /tmp/test.txt 4.通过软连接查看文件 cat my_test my_test只是/tmp/test.txt的一个别名，因此删除my_test不会影响/tmp/test.txt，但是删除了本尊， 快捷方式就无意义不存在了 PS1变量 Linux命令提示符由PS1环境变量控制 [root@haiyan ~]# echo $PS1 [\u@\h \W]\$ 可以自行调整全局变量/etc/profile文件用于永久生效 PS1=&apos;[\u@\h \W\t]\$&apos; \d 日期 \H 完整主机名 \h 主机名第一个名字 \t 时间24小时制HHMMSS \T 时间12小时制 \A 时间24小时制HHMM \u 当前用户账号名 \v BASH的版本 \w 完整工作目录 \W 利用basename取得工作目录名 \# 下达的第几个命令 \$ 提示字符，root为#，普通用户为$ PS1 &gt; 变量名 $PS1 &gt; 查看变量内容 PS1=新内容 重新赋值 变量赋值，查看 name=&apos;chaoge&apos; echo $name PS1显示ip地址 export PS1=&quot;[\u@\h `/sbin/ifconfig ens33 | sed -nr &apos;s/.*inet (addr:)?(([0-9]*\.){3}[0-9]*).*/\2/p&apos;` \w]\$&quot; tar解压命令人们发明了各种各样的包，无论是双肩包，或者是装在口袋，都是为了让“文件”更方便携带。linux的文件打包工具最出名的是tar。 tar 命令：用来压缩和解压文件。tar本身不具有压缩功能。他是调用压缩功能实现的 语法 tar(选项)(参数) -A或--catenate：新增文件到以存在的备份文件； -B：设置区块大小； -c或--create：建立新的备份文件； -C &lt;目录&gt;：这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项。 -d：记录文件的差别； -x或--extract或--get：从备份文件中还原文件； -t或--list：列出备份文件的内容； -z或--gzip或--ungzip：通过gzip指令处理备份文件； -Z或--compress或--uncompress：通过compress指令处理备份文件； -f&lt;备份文件&gt;或--file=&lt;备份文件&gt;：指定备份文件； -v或--verbose：显示指令执行过程； -r：添加文件到已经压缩的文件； -u：添加改变了和现有的文件到已经存在的压缩文件； -j：支持bzip2解压文件； -v：显示操作过程； -l：文件系统边界设置； -k：保留原有文件不覆盖； -m：保留文件不被覆盖； -w：确认压缩文件的正确性； -p或--same-permissions：用原来的文件权限还原文件； -P或--absolute-names：文件名使用绝对名称，不移除文件名称前的“/”号； -N &lt;日期格式&gt; 或 --newer=&lt;日期时间&gt;：只将较指定日期更新的文件保存到备份文件里； --exclude=&lt;范本样式&gt;：排除符合范本样式的文件 实例 tar -zxvf Python-3.7.0b3.tgz #解压 tar -czvf haiyan.txt.tar.gz haiyan.txt #压缩haiyan.txt 上述命令等于 tar -cvf haiyan.tar haiyan.txt gzip haiyan.tar tar -cf all_pic.tar *.jpg #压缩当前目录所有jpg结尾的文件 tar -xjf xx.tar.bz2 #解压缩bz2结尾的文件 gzip命令gzip用来压缩文件，是个使用广泛的压缩程序，被压缩的以&quot;.gz&quot;扩展名 gzip可以压缩较大的文件，以60%~70%压缩率来节省磁盘空间 语法 -d或--decompress或----uncompress：解开压缩文件； -f或——force：强行压缩文件。 -h或——help：在线帮助； -l或——list：列出压缩文件的相关信息； -L或——license：显示版本与版权信息； -r或——recursive：递归处理，将指定目录下的所有文件及子目录一并处理； -v或——verbose：显示指令执行过程； 实例 压缩当前目录所有文件为.gz文件 gzip * 把上例中每个压缩的文件解压，并列出详细的信息 gzip -dv * 显示压缩文件的信息，并不解压 gzip -l * 压缩一个tar备份文件，扩展名是tar.gz tar -cf my.tar my_first.py gzip -r my.tar netstat命令netstat命令用来打印Linux中网络系统的状态信息，可让你得知整个Linux系统的网络情况。 语法【选项】 netstat [选项] -t或--tcp：显示TCP传输协议的连线状况； -u或--udp：显示UDP传输协议的连线状况； -n或--numeric：直接使用ip地址，而不通过域名服务器； -l或--listening：显示监控中的服务器的Socket； -p或--programs：显示正在使用Socket的程序识别码和程序名称； -a或--all：显示所有连线中的Socket； 实例 [root@haiyan ~ 10:21:59]#netstat -tunlp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN 1/systemd tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 814/sshd tcp6 0 0 :::111 :::* LISTEN 2703/rpcbind tcp6 0 0 :::3306 :::* LISTEN 29269/mysqld udp 0 0 0.0.0.0:758 0.0.0.0:* 2703/rpcbind udp 0 0 0.0.0.0:111 0.0.0.0:* 2703/rpcbind udp 0 0 10.141.32.137:123 0.0.0.0:* 484/ntpd udp 0 0 127.0.0.1:123 0.0.0.0:* 484/ntpd udp 0 0 0.0.0.0:123 0.0.0.0:* 484/ntpd udp6 0 0 :::758 :::* 2703/rpcbind udp6 0 0 :::111 :::* 2703/rpcbind udp6 0 0 :::123 :::* 484/ntpd ps命令ps 命令用于查看系统中的进程状态，格式为“ps [参数]”。 ps 命令常用参数 -a 显示所有进程 -u 用户以及其他详细信息 -x 显示没有控制终端的进程 kill命令kill命令用来删除执行中的程序或工作。kill可将指定的信息送至程序。 选项 -a：当处理当前进程时，不限制命令名和进程号的对应关系； -l &lt;信息编号&gt;：若不加&lt;信息编号&gt;选项，则-l参数会列出全部的信息名称； -p：指定kill 命令只打印相关进程的进程号，而不发送任何信号； -s &lt;信息名称或编号&gt;：指定要送出的信息； -u：指定用户。 只有第9种信号(SIGKILL)才可以无条件终止进程，其他信号进程都有权利忽略，下面是常用的信号： HUP 1 终端断线 INT 2 中断（同 Ctrl + C） QUIT 3 退出（同 Ctrl + \） TERM 15 终止 KILL 9 强制终止 CONT 18 继续（与STOP相反， fg/bg命令） STOP 19 暂停（同 Ctrl + Z） 实例 先用ps查找进程，然后用kill杀掉： ps -ef | grep vim root 3268 2884 0 16:21 pts/1 00:00:00 vim install.log root 3370 2822 0 16:21 pts/0 00:00:00 grep vim kill 3268 killall命令通常来讲，复杂软件的服务程序会有多个进程协同为用户提供服务，如果逐个去结束 这 些进程会比较麻烦，此时可以使用 killall 命令来批量结束某个服务程序带有的 全部进程。 例如nginx启动后有2个进程 killall nginx SELinux功能SELinux(Security-Enhanced Linux) 是美国国家安全局（NSA）对于强制访问控制的实现，这个功能管理员又爱又恨，大多数生产环境也是关闭的做法，安全手段使用其他方法。 大多数ssh连接不上虚拟机，都是因为防火墙和selinux阻挡了 永久关闭方式： 1.修改配置文件，永久生效关闭selinux cp /etc/selinux/config /etc/selinux/config.bak #修改前备份 2.修改方式可以vim编辑,找到 # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=disabled 3.用sed替换 sed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/&apos; /etc/selinux/config 4.检查状态 grep &quot;SELINUX=disabled&quot; /etc/selinux/config #出现结果即表示修改成功 临时关闭selinux(命令行修改，重启失效)： getenforce #获取selinux状态 #修改selinux状态 setenforce usage: setenforce [ Enforcing | Permissive | 1 | 0 ] 数字0 表示permissive，给出警告，不会阻止，等同disabled 数字1表示enforcing，表示开启 Tip: 修改selinux配置后，想要生效还得重启系统，技巧就是（修改配置文件+命令行修改，达到立即生效） 生产环境的服务器是禁止随意重启的！！！！ iptables防火墙在学习阶段，关闭防火墙可以更方便的学习，在企业环境中，一般只有配置外网ip的linux 服务器才会开启防火墙，但是对于高并发流量的业务服务器仍然是不能开启的，会有很大性 能损失，因此需要更nb的硬件防火墙。 关闭防火墙具体操作如下： centos7默认已经使用firewall作为防火墙了 1.关闭防火墙 systemctl status firewalld #查看防火墙状态 systemctl stop firewalld #关闭防火墙 systemctl disable firewalld#关闭防火墙开机启动 systemctl is-enabled firewalld.service#检查防火墙是否启动 Linux中文显示设置（防止中文乱码）此项优化为可选项，根据个人情况选择是否调整Linux系统的字符集，字符集就是一套文字符号以及编码。 Linux下常用字符集有： GBK 实际企业应用较少 UTF-8 广泛支持，MYSQL也使用UTF-8，企业广泛使用 #查看系统当前字符集 echo $LANG #检查xshell crt的字符集 #命令修改字符集 export LANG=en_US.utf8 1.修改配置文件/etc/locale.conf LANG=&quot;zh_CN.UTF-8&quot; 2.更改后查看系统语言变量 locale 乱码核心解决办法 1.系统字符集utf8 2.xshell字符集utf8 3.文件字符集一致zh_CN.UTF-8 df命令 df命令用于显示磁盘分区上的可使用的磁盘空间。默认显示单位为KB。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 语法 df(选项)(参数) -h或--human-readable：以可读性较高的方式来显示信息； -k或--kilobytes：指定区块大小为1024字节； -T或--print-type：显示文件系统的类型； --help：显示帮助； --version：显示版本信息。 示例 查看系统磁盘设备，默认是KB为单位： df 使用-h选项以KB以上的单位来显示，可读性高： df -h tree命令tree命令以树状图列出目录的内容。tree参数 -a：显示所有文件和目录； -A：使用ASNI绘图字符显示树状图而非以ASCII字符组合； -C：在文件和目录清单加上色彩，便于区分各种类型； -d：先是目录名称而非内容； -D：列出文件或目录的更改时间； -f：在每个文件或目录之前，显示完整的相对路径名称； -F：在执行文件，目录，Socket，符号连接，管道名称名称，各自加上”*”，”/“，”@”，”|”号； -g：列出文件或目录的所属群组名称，没有对应的名称时，则显示群组识别码； -i：不以阶梯状列出文件和目录名称； -l：&lt;范本样式&gt; 不显示符号范本样式的文件或目录名称； -l：如遇到性质为符号连接的目录，直接列出该连接所指向的原始目录； -n：不在文件和目录清单加上色彩； -N：直接列出文件和目录名称，包括控制字符； -p：列出权限标示； -P：&lt;范本样式&gt; 只显示符合范本样式的文件和目录名称； -q：用“？”号取代控制字符，列出文件和目录名称； -s：列出文件和目录大小； -t：用文件和目录的更改时间排序； -u：列出文件或目录的拥有者名称，没有对应的名称时，则显示用户识别码； -x：将范围局限在现行的文件系统中，若指定目录下的某些子目录，其存放于另一个文件系统上，则将该目录予以排除在寻找范围外。 设置主键名[root@haiyan /tmp 11:04:42]#hostnamectl set-hostname ward [root@ward ~ 11:05:12]#hostname ward DNSDNS（Domain Name System，域名系统），万维网上作为域名和IP地址相互映射的 一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读 取的IP数串。 通过域名，最终得到该域名对应的IP地址的过程叫做域名解析（或主机名解析）。 查看Linux的dns，唯一配置文件配置文件 cat /etc/resolv.conf #dns服务器地址 nameserver 119.29.29.29 nameserver 223.5.5.5 本地强制dns解析文件/etc/hosts指定本地解析： /etc/hosts 主机IP 主机名 主机别名 127.0.0.1 www.xiaoxuedi.top nslookuo命令nslookup命令是常用域名查询工具，就是查DNS信息用的命令。 nslookup4有两种工作模式，即“交互模式”和“非交互模式”。在“交互模式”下，用户 可以向域名服务器查询各类主机、域名的信息，或者输出域名中的主机列表。而在“非 交互模式”下，用户可以针对一个主机或域名仅仅获取特定的名称或所需信息。 进入交互模式，直接输入nslookup命令，不加任何参数，则直接进入交互模式，此时 nslookup会连接到默认的域名服务器（即/etc/resolv.conf的第一个dns地址）。 或者输入nslookup -nameserver/ip。进入非交互模式，就直接输入nslookup 域 名就可以了。 #解析 nslookup www.xiaoxuedi.top 计划任务crond服务你每天是怎么起床的？有的人有女朋友，，或是男朋友，，而我是被穷醒的，，， 什么是计划任务： 后台运行，到了预定的时间就会自动执行的任务，前提是：事先手动将计划任务设定好。这就用到了crond服务 crond服务相关的软件包 [root@MiWiFi-R3-srv ~]# rpm -qa |grep cron cronie-anacron-1.4.11-14.el7.x86_64 crontabs-1.11-6.20121102git.el7.noarch cronie-1.4.11-14.el7.x86_64 这些包在最小化安装系统时就已经安装了，并且会开机自启动crond服务，并为我们提供好编写计划任务的crontab命令。 crontab命令被用来提交和管理用户的需要周期性执行的任务，与windows下的计划任务类似 语法 crontab （选项）（参数） -e：编辑该用户的计时器设置； -l：列出该用户的计时器设置； -r：删除该用户的计时器设置； -u&lt;用户名称&gt;：指定要设定计时器的用户名称。 存放定时任务的文件 /var/spool/cron 注意： 1 查看计划任务的执行：tail -f /var/log/cron 2 写计划任务时，命令必须加上绝对路径，否则会出现这种情况：从日志中看，确实触 发了计划任务的执行，但是命令却没有执行成功，比如* * * * * reboot就会 出现这种情况，需要将reboot写成/usr/sbin/reboot 3. 计划任务执行的命令 是否存在，软件是否安装 4. 确保crontab服务运行 systemctl status cron ps -ef|grep crond 5. 检测crontab是否开机启动 systemctl is-enabled crond crontab配置文件 在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件 SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root # For details see man 4 crontabs # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed 分 时 日 月 周 crontab任务配置基本格式： * * * * * command 分钟(0-59) 小时(0-23) 日期(1-31) 月份(1-12) 星期(0-6,0代表星期天) 命令 第1列表示分钟1～59 每分钟用*或者 */1表示 第2列表示小时1～23（0表示0点） 第3列表示日期1～31 第4列表示月份1～12 第5列标识号星期0～6（0表示星期天） 第6列要运行的命令 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 30 08 * * * 每天8.30去上班 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 */3 * * * * /usr/sbin/ntpdate ntp1.aliyun.com 每隔三分钟执行下时间同步 每天8.30上班 30 08 * * * 去上班 每天12下班回家睡觉 00 00 * * * 回家睡觉 实例 所有命令一定要用绝对路径来写！ #每分钟执行一次命令 * * * * * 命令 #每小时的3,15分组执行命令 3,15 * * * * 命令 #在上午8-11点的第3和第15分钟执行 3,15 8-11 * * * 命令 #每晚21:30执行命令 30 21 * * * 命令 #没周六、日的1：30执行命令 30 1 * * 6,0 命令 #每周一到周五的凌晨1点，清空/tmp目录的所有文件 0 1 * * 1-5 /usr/bin/rm -rf /tmp/* #每晚的21:30重启nginx 30 21 * * * /opt/nginx/sbin/nginx -s reload #每月的1,10,22日的4:45重启nginx 45 4 1,1,10,22 * * /opt/nginx/sbin/nginx -s reload #每个星期一的上午8点到11点的第3和15分钟执行命令 3,15 8-11 * * 1 command 软件包管理软件包是什么程序(软件)组成部分： 二进制程序 可执行命令 库 .so文件 配置文件 .conf 帮助文件 readme /usr/share/man 软件包顾名思义就是将应用程序、配置文件和数据打包的产物，所有的linux发行版都 采用了某种形式的软件包系统，这使得linux软件管理和在windows下一样方便， suse、red hat、fedora等发行版都是用rpm包，Debian和Ubuntu则使用.deb格 式的软件包。 mysql-5-3-4.rpm redis-3-4-3.rpm nginx2-3-2.rpm 在早期系统运维中，安装软件是一件非常费事费力的事情。系统管理员不得不下载软件 源代码编译软件，并且为了系统做各种调整。 尽管源代码编译形式的软件增强了用户定制的自由度，但是在小软件上耗费精力是缺乏 效率的，于是软件包应运而生。 软件包管理可以将管理员从无休止的兼容问题中释放。yum工具就可以自动搜索依赖关 系，并执行安装。 RPM软件包管理软件包管理器核心功能 1.制作软件包 .rpm 2.安装、卸载、升级、查询、校验 在 RPM(红帽软件包管理器)公布之前，要想在 Linux 系统中安装软件只能采取源码包 的方式安装。早期在 Linux 系统中安装程序是一件非常困难、耗费耐心的事情，而且大多数 的服务程序仅仅提供源代码，需要运维人员自行编译代码并解决许多的软件依赖关系，因此 要安装好一个服务程序，运维人员需要具备丰富知识、高超的技能，甚至良好的耐心。而且在 安装、升级、卸载服务程序时还要考虑到其他程序、库的依赖关系，所以在进行校验、安装、 卸载、查询、升级等管理软件操作时难度都非常大。 RPM 机制则为解决这些问题而设计的。RPM 有点像 Windows 系统中的控制面板，会建 立统一的数据库文件，详细记录软件信息并能够自动分析依赖关系 实例 #现在要安装mysql #下载地址 https://dev.mysql.com/downloads/mysql/ 安装软件的命令格式 rpm -ivh filename.rpm # i表示安装 v显示详细过程 h以进度条显示 升级软件的命令格式 rpm -Uvh filename.rpm 卸载软件的命令格式 rpm -e filename.rpm 查询软件描述信息的命令格式 rpm -qpi filename.rpm 列出软件文件信息的命令格式 rpm -qpl filename.rpm 查询文件属于哪个 RPM 的命令格式 rpm -qf filename rpm安装软件#下载软件包 wget https://rpmfind.net/linux/centos/7.5.1804/os/x86_64/Packages/lrzsz-0.12.20-36.el7.x86_64.rpm #安装软件包 [root@haiyan /tmp 11:03:42]#rpm -ivh lrzsz-0.12.20-36.el7.x86_64.rpm Preparing... ################################# [100%] Updating / installing... 1:lrzsz-0.12.20-36.el7 ################################# [100%] rpm查询软件rpm -q lrzsz #查询lrzsz是否安装 rpm -qi lrzsz #查询lrzsz包的说明信息 rpm -ql lrzsz #查询lrzsz包生成的文件列表 rpm -qc nginx #查询nginx安装生成后的配置文件路径 rpm -qf /etc/nginx/fastcgi.conf #查看这个文件由哪个rpm包安装 rpm升级软件rpm -Uvh /PATH/TO/NEW_PACKAGE_FILE: 如果装有老版本的，则升级；否则，则安装； rpm -Fvh /PATH/TO/NEW_PACKAGE_FILE：如果装有老版本的，则升级；否则，退出； rpm卸载软件rpm -e PACKAGE_NAME 需要手动解决依赖 不如 yum remove rpm的依赖问题，因此不太好用其一，难以删除 [root@haiyan /tmp 11:42:01]#rpm -e nginx error: Failed dependencies: nginx is needed by (installed) nginx-mod-mail-1:1.12.2-2.el7.x86_64 nginx is needed by (installed) nginx-mod-http-perl-1:1.12.2-2.el7.x86_64 nginx is needed by (installed) nginx-mod-http-xslt-filter-1:1.12.2-2.el7.x86_64 nginx is needed by (installed) nginx-mod-http-image-filter-1:1.12.2-2.el7.x86_64 nginx is needed by (installed) nginx-mod-stream-1:1.12.2-2.el7.x86_64 nginx is needed by (installed) nginx-mod-http-geoip-1:1.12.2-2.el7.x86_64 其二，难以安装 [root@haiyan /tmp 11:45:07]#rpm -ivh zsh-5.6.2-9.6.2.aarch64.rpm warning: zsh-5.6.2-9.6.2.aarch64.rpm: Header V3 RSA/SHA256 Signature, key ID 3dbdc284: NOKEY error: Failed dependencies: ld-linux-aarch64.so.1()(64bit) is needed by zsh-5.6.2-9.6.2.aarch64 ld-linux-aarch64.so.1(GLIBC_2.17)(64bit) is needed by zsh-5.6.2-9.6.2.aarch64 libdl.so.2(GLIBC_2.17)(64bit) is needed by zsh-5.6.2-9.6.2.aarch64 libm.so.6(GLIBC_2.17)(64bit) is needed by zsh-5.6.2-9.6.2.aarch64 libncursesw.so.6()(64bit) is needed by zsh-5.6.2-9.6.2.aarch64 libtinfo.so.6()(64bit) is needed by zsh-5.6.2-9.6.2.aarch64 yum命令yum命令是在Fedora和RedHat以及SUSE中基于rpm的软件包管理器，它可以使系统 管理人员交互和自动化地更细与管理RPM软件包，能够从指定的服务器自动下载RPM包 并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地 一次次下载、安装。 尽管 RPM 能够帮助用户查询软件相关的依赖关系，但问题还是要运维人员自己来解 决， 而有些大型软件可能与数十个程序都有依赖关系，在这种情况下安装软件会是非 常痛苦的。 Yum 软件仓库便是为了进一步降低软件安装难度和复杂度而设计的技 术。Yum 软件仓库可以 根据用户的要求分析出所需软件包及其相关的依赖关系，然 后自动从服务器下载软件包并安 装到系统。 Yum 软件仓库中的 RPM 软件包可以是由红帽官方发布的，也可以是第三方发布的， 当 然也可以是自己编写的 yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。 yum(选项)(参数) -h：显示帮助信息； -y：对所有的提问都回答“yes”； -c：指定配置文件； -q：安静模式； -v：详细模式； -d：设置调试等级（0-10）； -e：设置错误等级（0-10）； -R：设置yum处理一个命令的最大等待时间； -C：完全从缓存中运行，而不去下载或者更新任何头文件。 实例 部分常用的命令包括： 自动搜索最快镜像插件 yum install yum-fastestmirror yum配置什么是yum源？ Yum（全称为 Yellow dog Updater, Modified）是一个在Fedora和RedHat以 及CentOS中的Shell前端软件包管理器。基于RPM包管理，能够从指定的服务器自动 下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包，无 须繁琐地一次次下载、安装。 说到yum源就必须说到linux系统中特有的依赖关系问题，yum就是为了解决依赖关系 而存在的。yum源就相当是一个目录项，当我们使用yum机制安装软件时，若需要安装 依赖软件，则yum机制就会根据在yum源中定义好的路径查找依赖软件，并将依赖软件 安装好。 YUM是“Yellow dog Updater, Modified”的缩写，是一个软件包管理器，YUM从 指定的地方（相关网站的rpm包地址或本地的rpm路径）自动下载RPM包并且安装，能 够很好的解决依赖关系问题。 YUM的基本工作机制如下： 服务器端：在服务器上面存放了所有的RPM软件包，然后以相关的功能去分析每个RPM 文件的依赖性关系，将这些数据记录成文件存放在服务器的某特定目录内。 客户端：如果需要安装某个软件时，先下载服务器上面记录的依赖性关系文件(可通过 WWW或FTP方式)，通过对服务器端下载的纪录数据进行分析，然后取得所有相关的软 件，一次全部下载下来进行安装。 yum源的目录 #进入yum源目录 cd /etc/yum.repos.d/ #查看yum源文件 ls -l 配置阿里云yum源1.好习惯，备份yum源 mkdir repo_bak mv *.repo repo_bak/ 2.下载阿里云repo文件 wget http://mirrors.aliyun.com/repo/Centos-7.repo 3.清空yum缓存并且生成新的yum缓存 yum clean all yum makecache 4.安装软件扩展源 yum install -y epel-release 复制代码 复制代码 yum repolist all 列出所有仓库 yum list all 列出仓库所有软件包 yum info 软件包名 查看软件包信息 yum install 软件包名 安装软件包 yum reinstall 软件包名 重新安装软件包 yum update 软件包名 升级软件包 yum remove 软件包名 移除软件包 yum clean all 清楚所有仓库缓存 yum check-update 检查可以更新的软件包 yum grouplist 查看系统中已安装的软件包 yum groupinstall 软件包组 安装软件包组 系统服务管理命令如果之前学习或者使用过RHEL6系统，应该已经习惯了service、chkconfig等命令来管理系统服务， 但是在RHEL7系统中改变了systemctl来管理系统服务。 设置开机启动相关 必须掌握的/etc下的linux目录知识/etc：这个目录用来存放所有的系统管理所需要的配置文件和子目录。 #网卡配置文件 /etc/sysconfig/network-script/ifcfg-eth0 #修改机器名以及网卡，网管等配置 /etc/sysconfig/network #linux的dns客户端配置文件，实现域名和ip的互相解析 /etc/resolv.conf #本地dns解析文件,设定ip和域名的对应解析,开发测试最常用的临时域名解析 /etc/hosts/ #系统全局环境变量永久生效的配置文件,如PATH等 /etc/profile #用户的环境变量 ~/.bash_profile ~/.bashrc #存放可执行程序的目录，大多是系统管理命令 /usr/sbin #存放用户自编译安装软件的目录 &gt; 等同于C:\Program files （windows） /usr/local #关于处理器的信息,还可以top指令查看 /proc/cpuinfo #查看内存信息，还可以free -m Linux下安装程序的方法rpm -ivh 包名.rpm 需要手动解决依赖关系 yum install 包名 yum自动处理依赖关系 编译安装（源码安装） 安装Lrzsz#安装此软件，即可拖拽上传下载linux代码到windows yum install lrzsz 服务器无法上网错误1.yum报错 Error couldn&apos;t resolve host &apos;mirrorlist.centos.org&apos; 2.ping www.baidu.com 看是否能上网 3.如果百度不通，ping ip通了 ping 119.29.29.29 ，说明dns有问题]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[vim]]></title>
    <url>%2F2018%2F03%2F17%2Fvim%2F</url>
    <content type="text"><![CDATA[所有的 Unix Like 系统都会内建 vi 文书编辑器，其他的文书编辑器则不一定会存在。 但是目前我们使用比较多的是 vim 编辑器。 vim 具有程序编辑的能力，可以主动的以字体颜色辨别语法的正确性，方便程序设计。 什么是 vim？Vim是从 vi 发展出来的一个文本编辑器。代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。 简单的来说， vi 是老式的字处理器，不过功能已经很齐全了，但是还是有可以进步的地方。 vim 则可以说是程序开发者的一项很好用的工具。 vi/vim 的使用基本上 vi/vim 共分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode）和底线命令模式（Last line mode）。 这三种模式的作用分别是： 命令模式：用户刚刚启动 vi/vim，便进入了命令模式。 此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。比如我们此时按下i，并不会输入一个字符，i被当作了一个命令 移动光标w(e) 移动光标到下一个单词 b 移动到光标上一个单词 数字0 移动到本行开头 $ 移动光标到本行结尾 H 移动光标到屏幕首行 M 移动到光标到屏幕的中间一行 L 移动光标到屏幕的尾行 gg 移动光标到文档的首行 G 移动光标到文档尾行 ctrl + f 下一页 ctrl + b 上一页 `. 移动光标到上一次的修改行 查找/chaoge 在整篇文档中搜索chaoge字符串,向下查找 ?chaoge 在整篇文档中搜索chaoge字符串,向上查找 * 查找整个文档，匹配光标所在的所有单词,按下n查找下一处,N上一处 # 查找整个文档，匹配光标所在的所有单词,按下n查找下一处,N上一处 gd 找到光标所在单词匹配的单词，并停留在非注释的第一个匹配上 % 找到括号的另一半！！ 复制，删除，粘贴yy 拷贝光标所在行 dd 删除光标所在行 D 删除当前光标到行尾的内容 dG 删除当前行到文档尾部的内容 p 粘贴yy所复制的内容 x 删除光标所在的字符 u 撤销上一步的操作 数字与命令3yy 拷贝光标所在的3行 5dd 删除光标所在5行 输入模式 在命令模式下按下字母i 即可进入输入模式，可以编写代码啦。。。 底线命令模式在命令模式下输入冒号（英文的:），就进入了底线命令模式，在底线命令模式下可以输入单个或多个字符的命令，常用命令有： :q! 强制退出 :wq! 强制写入退出 :set nu 显示行号 :数字 调到数字那行 随时按下esc可以退出底线命令模式 vim工作模式vim按键移动光标移动光标的方法 h 或 向左箭头键(←) 光标向左移动一个字符 j 或 向下箭头键(↓) 光标向下移动一个字符 k 或 向上箭头键(↑) 光标向上移动一个字符 l 或 向右箭头键(→) 光标向右移动一个字符 向下移动5行 5j 向右移动10字符 10l n(space) 按下数字n,例如10，然后按下空格，光标会向右移动10个字符 底线命令:! command 暂时离开vim指令模式，执行command的结果 例如 :!ip a 临时看一下ip信息，然后可以回到vim :set nu 显示vim行号 :set nonu 取消行号]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux基本命令]]></title>
    <url>%2F2018%2F03%2F16%2FLinux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux系统命令操作语法格式命令 空格 参数 空格 【文件或路径】需要处理的内容 rm -rf /tmp/* ls -la /home 结婚 -没车没房 女的就行 结婚 -有车有房 白富美 1.一般情况下，【参数】是可选的，一些情况下【文件或路径】也是可选的 2.参数 &gt; 同一个命令，跟上不同的参数执行不同的功能 执行linux命令，添加参数的目的是让命令更加贴切实际工作的需要！ linux命令，参数之间，普遍应该用一个或多个空格分割！ 创建一个目录 /haiyanmake directory &gt; mk dir &gt; mkdir ------------------------------- mkdir /haiyan ------------------------------- cd / mkdir haiyan #递归创建a/b c/d mkdir -p a/b c/d #递归创建test/a,b,c,d四个目录 mkdir -p test/{a,b,c,d} #递归创建文件夹a/b/c/d/e mkdir -p a/b/c/d/e 查看目录 /haiyan#显示/haiyan下的内容 ls /haiyan 改变当前的目录/位置cd /home cd ~ cd - 换来换去的，迷路了怎么办？我到底在哪个目录？ 打印当前工作目录#打印当前工作目录 pwd 创建文件或者修改文件时间戳(文件属性)创建文本 修改文件的修改时间 #修改文件的更改时间，很多黑客就会在恶意修改文件之后再修改成之前的时间 ls -l echo &apos;sb&apos; &gt;&gt; xxx.py touch -t&apos;07101530&apos; 1.txt #触摸 touch xxx.py stat命令显示文件或文件系统的状态。 #用法 stat [参数] 文件 参数列表： -L, --dereference 跟随链接 -f, --file-system 显示文件系统状态而非文件状态 -c --format=格式 使用指定输出格式代替默认值，每用一次指定格式换一新行 --printf=格式 类似 --format，但是会解释反斜杠转义符，不使用换行作 输出结尾。如果您仍希望使用换行，可以在格式中 加入&quot;\n&quot; -t, --terse 使用简洁格式输出 --help 显示此帮助信息并退出 --version 显示版本信息并退出 格式化输出参数： %a 八进制权限 %A 用可读性较好的方式输出权限 #实例1 [root@master tmp]# stat 1.txt File: &apos;1.txt&apos; Size: 0 Blocks: 0 IO Block: 4096 regular empty file Device: fd00h/64768d Inode: 17348002 Links: 1 (权限)Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) (最近访问)Access: 2018-07-10 15:30:00.000000000 +0800 (最近更改)Modify: 2018-07-10 15:30:00.000000000 +0800 (最近改动)Change: 2018-11-07 15:38:36.400989868 +0800 Birth: - #实例2，显示文件权限 [root@master tmp]# stat -c %a 1.txt [root@master tmp]# stat -c %A 1.txt -rw-r--r-- vi/vim所有的 Unix Like 系统都会内建 vi 文书编辑器，其他的文书编辑器则不一定会存在。 但是目前我们使用比较多的是 vim 编辑器。 vim 具有程序编辑的能力，可以主动的以字体颜色辨别语法的正确性，方便程序设计。 #方法，命令 vi vim 使用vi打开haiyan.py,默认是命令模式，需要输入a/i/o进入编辑模式,然后输入文本&quot;Life is short,i use python&quot; 按下esc键，回到命令模式 输入 :wq! 强制保存退出 w write 写入 q quit 退出 ! 强制 或者 :x 保存退出 ------ :q 不保存退出 :q! 不保存强制退出 查看文件内容查看文件内容cat命令用于查看纯文本文件（常用于内容较少的） #查看文件，显示行号 cat -n xxx.py #猫,查看文件 cat xxx.py #在每一行的结尾加上$符 [root@master tmp]# cat -E 1.txt #追加文字到文件 cat &gt;&gt;/tmp/haiyan.txt &lt;&lt; EOF 唧唧复唧唧 木兰开飞机 开的什么机 波音747 EOF more命令1.more命令用于查看内容较多的文本，例如要看一个很长的配置文件，cat查看内容屏幕会快速翻滚到结尾。 2.more命令查看文本会以百分比形式告知已经看到了多少，使用回车键向下读取内容 more /etc/passwd 按下空格space是翻页 按下b键是上一页 回车键向下读取内容 linux快捷键1.tab键 用于自动补全命令/文件名/目录名 2.ctrl + l 清理终端显示 3.clear/cls 清理终端显示 4.ctrl + c 终止当前操作 echo命令echo命令用于在终端输出字符串或变量提取后的值，格式是“echo 【字符串|$变量】” #默认吧内容显示到终端上 echo &quot;666&quot; #把“666”写入到文件里！ echo &quot;666&quot; &gt; /tmp/hiayan.txt echo $PATH #取出打印PATH的值 特殊符号输入/输出 重定向符号 1.&gt;&gt; 追加重定向，把文字追加到文件的结尾 2.&gt; 重定向符号，清空原文件所有内容，然后把文字覆盖到文件末尾 3.&lt; 输入重定向 4.&lt;&lt; 将输入结果输入重定向 echo &quot;python666&quot; &gt; /tmp/haiyan.txt echo &quot;go666&quot; &gt;&gt; /tmp/haiyan.txt cat &gt;&gt;/tmp/haiyan.txt &lt;&lt; EOF ------------------------------------ 我想把命令执行的结果信息，写入到文件中 ip addr &gt; /tmp/network.txt #标准输出重定向 把命令执行结果信息，放入到文件中 3.通配符 ls -l /etc/us* 赋值（拷贝）命令复制 &gt; copy &gt; cp #移动xxx.py到/tmp目录下 cp xxx.py /tmp/ #移动xxx.py顺便改名为python.py cp xxx.py /tmp/python.py Linux下面很多命令，一般没有办法直接处理文件夹,因此需要加上（参数） cp -r 递归,复制目录以及目录的子孙后代 cp -p 复制文件，同时保持文件属性不变 可以用stat cp -a 相当于-pdr #递归复制test文件夹，为test2 cp -r test test2 cp是个好命令，操作文件前，先备份 cp main.py main.py.bak 移动命令移动（搬家）命令 &gt; move &gt; mv cd /home mv /home/haiyan /tmp/ward 文件/文件夹改名 mv x.log xx.log 删除命令删除 &gt; remove &gt; rm 参数 -i 需要删除确认 -f 强制删除 -r 递归删除目录和内容 cd /tmp rm oldboy.py #默认有提示删除，需要输入y rm -f oldboy.py #不需要提示,强制删除 #rm默认无法删除目录，需要跟上参数-r rm -rf /tmp/oldboy/ -------- 友情提醒:初学者使用rm命令，随时快照虚拟机 查找命令#Linux里如何找到需要的文件 例如 haiyan.py find 在哪里(目录) 什么类型（文件类型） 叫什么名字（文件名） 参数 -name 按照文件名查找文件 -type 查找某一类型的文件，诸如： b - 块设备文件。 d - 目录。 c - 字符设备文件。 p - 管道文件。 l - 符号链接文件。 f - 普通文件。 s - socket文件 find /tmp/ -type f -name &quot;haiyan.py&quot; #找出/tmp所有以 .txt 结尾的文件 find /tmp/ -type f -name &quot;*.txt&quot; #找到/etc下所有名字以host开头的文件 find /etc -name &apos;host*&apos; #找到/opt上一个名为settings.py find /opt -name &apos;settings.py&apos; 管道命令Linux提供的管道符“|”讲两条命令隔开，管道符左边命令的输出会作为管道符右边命令的输入。 常见用法： #检查python程序是否启动 ps -ef|grep &quot;python&quot; #找到/tmp目录下所有txt文件 ls /tmp|grep &apos;.txt&apos; #检查nginx的端口是否存活 netstat -tunlp |grep nginx 命令格式： 命令A | 命令B grep(global search regular expression(RE) and print out the line,全 面搜索正则表达式并把行打印出来)是一种强大的文本搜索工具，它能使用正则表达式 搜索文本，并把匹配的行打印出来。 语法： grep [参数] [--color=auto] [字符串] filename 参数详解: -i : 忽略大小写 -n : 输出行号 -v : 反向选择 --color = auto : 给关键词部分添加颜色 grep &quot;我要找什么&quot; /tmp/haiyan.txt #排除 -v，排除我要找的东西 grep -v &quot;我要找什么 /tmp/haiyan.txt 例题，找出/etc/passwd下root用户所在行，以及行号，显示颜色 cat /etc/passwd |grep &apos;^root&apos; --color=auto -n 找出/etc/passwd所有不允许登录的用户 grep /sbin/nologin /etc/passwd 找到/etc/passwd的所有与mysql有关行，行号 cat /etc/passwd |grep &apos;mysql&apos; -n head、tail命令head显示文件前几行，默认前10行 tail显示文件后几行，默认后10行 #查看前两行 head -2 /tmp/haiyan.txt #查看后两行 tail -2 /tmp/haiyan.txt #持续刷新显示 tail -f xx.log #显示文件10-30行 head -30 /tmp/haiyan.txt |tail -21 sedsed是一种流编辑器，它是文本处理中非常中的工具，能够完美的配合正则表达式使 用，功能不同凡响。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间” （pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有 改变，除非你使用重定向存储输出。Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。 命令格式 sed [options] &apos;command&apos; file(s) sed [options] -f scriptfile file(s) 选项 -e&lt;script&gt;或--expression=&lt;script&gt;：以选项中的指定的script来处理输入的文本文件； -f&lt;script文件&gt;或--file=&lt;script文件&gt;：以选项中指定的script文件来处理输入的文本文件； -h或--help：显示帮助； -n或--quiet或——silent：仅显示script处理后的结果； -V或--version：显示版本信息。 -i ∶插入， i 的后面可以接字串 sed命令a\ 在当前行下面插入文本。 i\ 在当前行上面插入文本。 c\ 把选定的行改为新的文本。 d 删除，删除选择的行。 D 删除模板块的第一行。 s 替换指定字符 h 拷贝模板块的内容到内存中的缓冲区。 H 追加模板块的内容到内存中的缓冲区。 g 获得内存缓冲区的内容，并替代当前模板块中的文本。 G 获得内存缓冲区的内容，并追加到当前模板块文本的后面。 l 列表不能打印字符的清单。 n 读取下一个输入行，用下一个命令处理新的行而不是用第一个命令。 N 追加下一个输入行到模板块后面并在二者间嵌入一个新行，改变当前行号码。 p 打印模板块的行。 P(大写) 打印模板块的第一行。 q 退出Sed。 b lable 分支到脚本中带有标记的地方，如果分支不存在则分支到脚本的末尾。 r file 从file中读行。 t label if分支，从最后一行开始，条件一旦满足或者T，t命令，将导致分支到带有标号的命令处，或者到脚本的末尾。 T label 错误分支，从最后一行开始，一旦发生错误或者T，t命令，将导致分支到带有标号的命令处，或者到脚本的末尾。 w file 写并追加模板块到file末尾。 W file 写并追加模板块的第一行到file末尾。 ! 表示后面的命令对所有没有被选定的行发生作用。 = 打印当前行号码。 # 把注释扩展到下一个换行符以前。 sed替换标记g 表示行内全面替换。 p 表示打印行。 w 表示把行写入一个文件。 x 表示互换模板块中的文本和缓冲区中的文本。 y 表示把一个字符翻译为另外的字符（但是不用于正则表达式） \1 子串匹配标记 &amp; 已匹配字符串标记 sed元字符集^ 匹配行开始，如：/^sed/匹配所有以sed开头的行。 $ 匹配行结束，如：/sed$/匹配所有以sed结尾的行。 . 匹配一个非换行符的任意字符，如：/s.d/匹配s后接一个任意字符，最后是d。 * 匹配0个或多个字符，如：/*sed/匹配所有模板是一个或多个空格后紧跟sed的行。 [] 匹配一个指定范围内的字符，如/[ss]ed/匹配sed和Sed。 [^] 匹配一个不在指定范围内的字符，如：/[^A-RT-Z]ed/匹配不包含A-R和T-Z的一个字母开头，紧跟ed的行。 \(..\) 匹配子串，保存匹配的字符，如s/\(love\)able/\1rs，loveable被替换成lovers。 &amp; 保存搜索字符用来替换其他字符，如s/love/**&amp;**/，love这成**love**。 \&lt; 匹配单词的开始，如:/\&lt;love/匹配包含以love开头的单词的行。 \&gt; 匹配单词的结束，如/love\&gt;/匹配包含以love结尾的单词的行。 x\{m\} 重复字符x，m次，如：/0\{5\}/匹配包含5个0的行。 x\{m,\} 重复字符x，至少m次，如：/0\{5,\}/匹配至少有5个0的行。 x\{m,n\} 重复字符x，至少m次，不多于n次，如：/0\{5,10\}/匹配5~10个0的行。 sed实际用例#替换haiyan.txt中所有的haiyan变为haiyan_python #此时结果输出到屏幕,不会写入到文件 sed &apos;s/haiyan/haiyan_python/&apos; /tmp/haiyan.txt #使用选项-i，匹配每一行第一个oldboy替换为haiyan_python,并写入文件 sed -i &apos;s/haiyan/haiyan_python/&apos; /tmp/haiyan.txt #使用替换标记g，同样可以替换所有的匹配 sed -i &apos;s/book/books/g&apos; /tmp/haiyan.txt #删除文件第二行 sed -i &apos;2d&apos; /tmp/haiyan.txt #删除空白行 sed -i &apos;/^$/d&apos; /tmop/haiyan.txt #删除文件第二行，到末尾所有行 sed &apos;2,$d&apos; /tmp/haiyan.txt #显示10-30行 -p --print -n --取消默认输出 sed -n &apos;10,30p&apos; /tmp/haiyan.txt 别名alias命令别名alias命令 Linux在使用rm（删除）、cp（覆盖）、mv（搬家）等命令的时候，必须非常小心， 因为这些命令都是“炸弹”，想必大家都听过“删库到跑路”，一言不合“rm -rf /”，假 如你真的这么做了，那么。。。上帝保佑你 Linux如何提示，在使用这些命令时候，提醒你小心呢？ #查看系统别名 alias 默认别名 alias cp=&apos;cp -i&apos; alias egrep=&apos;egrep --color=auto&apos; alias fgrep=&apos;fgrep --color=auto&apos; alias grep=&apos;grep --color=auto&apos; alias l.=&apos;ls -d .* --color=auto&apos; alias ll=&apos;ls -l --color=auto&apos; alias ls=&apos;ls --color=auto&apos; alias mv=&apos;mv -i&apos; alias rm=&apos;rm -i&apos; alias which=&apos;alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde&apos; 别名作用是： 我们在linux中使用cp时候相当于执行了cp -i -i：删除已有文件或目录之前先询问用户； #别名用比较危险的操作,防止你犯错 为rm设置别名#让系统显示 do not use rm echo do not use rm #设置rm别名 alias rm=&apos;echo do not use rm&apos; #设置别名永久生效,写入到/etc/profile(针对登录用户的合同，设置环境变量) vim /etc/profile #编辑文件 G 快速到达最后一行 o 当前行下一行，创建一个新行，进入编辑模式 source /etc/profile #读取文件（合同生效） --------------- #取消别名 unalias rm which命令which命令用于查找并显示给定命令的绝对路径，环境变量PATH中保存了查找命令时需 要遍历的目录。 which指令会在环境变量$PATH设置的目录里查找符合条件的文件。 也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪 一个位置的命令。 which pwd which python 实例 which python #python命令在哪 /usr/bin/python #命令文件绝对路径 scp命令Linux scp命令用于Linux之间复制文件和目录。 scp是 secure copy的缩写, scp是linux系统下基于ssh登陆进行安全的远程文件拷贝命令。 语法 scp 【可选参数】 本地源文件 远程文件标记 参数 -r :递归复制整个目录 -v:详细方式输出 -q:不显示传输进度条 -C：允许压缩 实例 复制代码 #传输本地文件到远程地址 scp 本地文件 远程用户名@远程ip:远程文件夹/ scp 本地文件 远程用户名@远程ip:远程文件夹/远程文件名 scp /tmp/haiyan.py root@192.168.1.155:/home/ scp /tmp/haiyan.py root@192.168.1.155:/home/haiyan_python.py scp -r 本地文件夹 远程用户名@远程ip:远程文件夹/ scp -r /tmp/haiyan root@192.168.1.155:/home/haiyan #复制远程文件到本地 scp root@192.168.1.155:/home/haiyan.txt /tmp/haiyan.txt scp -r root@192.168.1.155:/home/haiyan /home/ du命令Linux du命令用于显示目录或文件的大小。 du会显示指定的目录或文件所占用的磁盘空间。 用法 du 【参数】【文件或目录】 -s 显示总计 -h 以k，M,G为单位显示，可读性强 实例 显示目录或文件所占空间 #什么都不跟，代表显示当前目录所有文件大小 du #显示/home的总大小 du -sh /home top命令top 命令用于动态地监视进程活动与系统负载等信息 统计信息区 第一行 (uptime) 系统时间 主机运行时间 用户连接数(who) 系统1，5，15分钟的平均负载 第二行:进程信息 进程总数 正在运行的进程数 睡眠的进程数 停止的进程数 僵尸进程数 第三行:cpu信息 1.5 us：用户空间所占CPU百分比 0.9 sy：内核空间占用CPU百分比 0.0 ni：用户进程空间内改变过优先级的进程占用CPU百分比 97.5 id：空闲CPU百分比 0.2 wa：等待输入输出的CPU时间百分比 0.0 hi：硬件CPU中断占用百分比 0.0 si：软中断占用百分比 0.0 st：虚拟机占用百分比 第四行：内存信息（与第五行的信息类似与free命令） 8053444 total：物理内存总量 7779224 used：已使用的内存总量 274220 free：空闲的内存总量（free+used=total） 359212 buffers：用作内核缓存的内存量 第五行：swap信息 8265724 total：交换分区总量 33840 used：已使用的交换分区总量 8231884 free：空闲交换区总量 4358088 cached Mem：缓冲的交换区总量，内存中的内容被换出到交换区，然后又被换入到内存，但是使用过的交换区没有被覆盖，交换区的这些内容已存在于内存中的交换区的大小，相应的内存再次被换出时可不必再对交换区写入。 chattr命令给文件加锁，只能写入数据，无法删除文件 chattr +a test.py chattr -a test.py lsattr命令查看文件隐藏属性 lsattr test.py linux时间同步linux的date命令可以显示当前时间或者设置系统时间 格式化输出 -d --date=string 显示指定的时间，而不是当前时间 以年-月-日显示当前时间 date +&quot;%Y-%m-%d&quot; 以年-月-日 时分秒 显示当前时间 date +&quot;%Y-%m-%d %T&quot; 在Linux下系统时间和硬件时间不会自动同步，在Linux运行过程中，系统时间和硬件时间以异步的方式运行，互不干扰。 硬件时间的运行，是靠Bios电池来运行，而系统时间是用CPU tick来维持的。 在系统开机时候，会从Bios中获取硬件时间，设置为系统时间 硬件始终的查看 [root@python ~ 10:19:04]#hwclock 同步系统时间和硬件时间，可以用hwclock命令 //以系统时间为基准，修改硬件时间 [root@python ~ 10:29:07]#hwclock -w //以硬件时间为基准，修改系统时间 [root@python ~ 10:29:21]#hwclock -s Ntp时间服务器时间对于人类来说是密不可少的，时间就是金钱。因此对于服务器时间的把控非常重要，如果系统的时间不对，那么对于每一个文件的操作都是错误的。 关于时间服务器的配置文件，有如下几种 /bin/date 用于 Linux 时间 (软件时钟) 的修改与显示的指令； /sbin/hwclock 用于 BIOS 时钟 (硬件时钟) 的修改与显示的指令。 这是一个 root 才能执行的指令，因为 Linux 系统上面 BIOS 时间与 Linux 系统时间是分开的，所以使用 date 这个指令调整了时间之后，还需要使用 hwclock 才能将修改过后的时间写入 BIOS 当中！ /usr/sbin/ntpd： 主要提供 NTP 服务的程序啰！配置文件为 /etc/ntp.conf /usr/sbin/ntpdate： 用于客户端的时间校正，如果你没有要启用 NTP 而仅想要使用 NTP Client 功能的话，那么只会用到这个指令而已啦！ 由于我们只需要用作客户端更新时间 ntpdate -u ntp.aliyun.com wget命令wget命令用于在终端下载网络文件 参数是 wget [参数] 下载地址 wget -r -p http://www.xx.com#递归下载xx所有资源，保存到www.xx.com文件中 开关机命令reboot命令用于重启机器 poweroff用于关闭系统]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux文件系统结构]]></title>
    <url>%2F2018%2F03%2F15%2FLinux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Linux之文档与目录结构 Linux文件系统结构Linux目录结构的组织形式和Windows有很大的不同。首先Linux没有“盘(C盘、D盘、E盘)”的概念。 已经建立文件系统的硬盘分区被挂载到某一个目录下，用户通过操作目录来实现磁盘读写。 Linux不像Windows那样的系统目录，Linux使用正斜杠&quot;/&quot;而不是反斜杠&quot;\&quot;来标识目录。 Linux首先是建立一个根”/“文件系统，所有的目录也都是由根目录衍生出来。 登录系统后，在当前命令窗口输入命令: ls / 查看结果如下图： 在Linux底下，所有的文件与目录都是由根目录开始，是目录与文件的源头，然后一个个的分支下来，如同树枝状，因此称为这种目录配置为：目录树。 目录树的特点是什么呢？ 目录树的起始点是根目录(/,root); 每一个目录不止能使用本地的文件系统，也可以使用网络上的文件系统，可以利用NFS服务器挂载特定目录。 每一个文件在此目录树中的文件名，包含完整路径都是独一无二的。 目录树架构示意图 以下是对这些目录的解释 /bin： bin是Binary的缩写, 这个目录存放着最经常使用的命令。 /boot： 这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件。 /dev ： dev是Device(设备)的缩写, 该目录下存放的是Linux的外部设备，在Linux中访问设备的方式和访问文件的方式是相同的。 /etc： 这个目录用来存放所有的系统管理所需要的配置文件和子目录。 /home： 用户的主目录，在Linux中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。 /lib： 这个目录里存放着系统最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。 /lost+found： 这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。 /media： linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下。 /mnt： 系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。 /opt： 这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。 /proc： 这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。 这个目录的内容不在硬盘上而是在内存里，我们也可以直接修改里面的某些文件，比如可以通过下面的命令来屏蔽主机的ping命令，使别人无法ping你的机器： echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all /root： 该目录为系统管理员，也称作超级权限者的用户主目录。 /sbin： s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。 /selinux： 这个目录是Redhat/CentOS所特有的目录，Selinux是一个安全机制，类似于windows的防火墙，但是这套机制比较复杂，这个目录就是存放selinux相关的文件的。 /srv： 该目录存放一些服务启动之后需要提取的数据。 /sys： 这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs 。 sysfs文件系统集成了下面3种文件系统的信息：针对进程信息的proc文件系统、针对设备的devfs文件系统以及针对伪终端的devpts文件系统。 该文件系统是内核设备树的一个直观反映。 当一个内核对象被创建的时候，对应的文件和目录也在内核对象子系统中被创建。 /tmp： 这个目录是用来存放一些临时文件的。 /usr： 这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于windows下的program files目录。 /usr/bin： 系统用户使用的应用程序。 /usr/sbin： 超级用户使用的比较高级的管理程序和系统守护程序。 /usr/src：内核源代码默认的放置目录。 /var： 这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。 在linux系统中，有几个目录是比较重要的，平时需要注意不要误删除或者随意更改内部文件。 /etc： 上边也提到了，这个是系统中的配置文件，如果你更改了该目录下的某个文件可能会导致系统不能启动。 /bin, /sbin, /usr/bin, /usr/sbin: 这是系统预设的执行文件的放置目录，比如 ls 就是在/bin/ls 目录下的。 值得提出的是，/bin, /usr/bin 是给系统用户使用的指令（除root外的通用户），而/sbin, /usr/sbin 则是给root使用的指令。 /var： 这是一个非常重要的目录，系统上跑了很多程序，那么每个程序都会有相应的日志产生，而这些日志就被记录到这个目录下，具体在/var/log 目录下，另外mail的预设放置也是在这里。 目录的相关操作我们知道切换目录的指令是cd，那么首先得知道如何切换目录，这个得用心记呀！ . 当前目录 .. 上一层目录 - 前一个工作目录 ~ 当前【用户】所在的家目录 需要注意的是，在所有目录底下都存在两个目录，分别是【.】和【..】，分别代表当前目录，上层目录！那么如何证明它的存在呢？ 命令： ls -la / 查看命令解释：man ls (Linux下的帮助指令) 结论：ls - list directory contens (列出目录内容) ls -la / 以竖状格式化显示列出/目录所有内容 接下来看一下常用的目录处理指令： cd : (change directory,更改目录) pwd:(显示当前目录) mkdir:(建立一个新目录) rmdir:（删除一个空目录） cd命令，变换目录cd是change directory的缩写，这是用来变换工作目录的命令，注意命令和目录之间有一个空格。 mkdir，建立新目录mkdir是make directory的缩写，用来建立新目录，在默认情况下，目录得一级一级的建立。 例如我要建立/home/haiyan/python目录，我就必须有/home，然后/home/oldboy，最后/home/haiyan/python，如果没有/home/haiyan，则不能建立python目录！ 可见高效的创建目录用上-p参数，可以直接执行命令【mkdir -p /home/hiayan/python】，系统会自动添加上/home，/home/haiyan，/home/haiyan/python依次建立目录，是不是很方便，^ ^ rmdir，删除空目录当我想删除一个空目录时，就用rmdir吧，例如我想删除刚才建立的haiyan目录，以及/tmp/haiyan/python,那么可以使用【rmdir haiyan】，但是注意rmdir只能删除空目录。 删除命令可以正确使用【rm -rf】 Linux的路径PATH会配置windows下的环境变量（PATH），都知道系统会按照PATH的设定，去每个PATH定义的目录下搜索可执行文件。 那么如何查看Linux下的PATH环境变量呢？ 执行命令： echo $PATH echo命令是有打印的意思 $符号后面跟上PATH,表示输出PATH的变量 PATH(一定是大写的)这个变量是由一堆目录组成，分隔符是”:”号，而不同于windows的”;”号。 绝对路径与相对路径Linux下特别注意文件名/路径的写法，可以将所谓的路径(path)定义为绝对路径(absolute)和相对路径(relative)。这两种文件名/路径的写法依据是这样的： 绝对路径：由根目录(/)为开始写起的文件名或者目录名称，如/home/haiyan/test.py;相对路径：相对于目前路径的文件名写法。例如./home/haiyan/exam.py或../../home/haiyan/exam.py，简单来说只要开头不是/，就是属于相对路径因此你必须了解，相对路径是：以你当前所在路径的相对路径来表示的。 例如你现在在/home 这个目录下，如要进入/var/log这个路径，如何写呢？ cd /var/log (绝对路径)cd ../var/log(相对路径)结果如图： 因为你在/home底下，因此你要回到上一层(../)之后，才能继续前往/var，特别注意： . :代表当前的目录，也可以用./ 来表示 .. :代表上一层的目录，也可以用../来表示 分割线—- 这个.与..目录概念非常重要，平时经常会看到cd ..或者python ../home/haiyan/exam.py 就是代表进入上一层与执行相对路径的python代码！ 1.linux是以 / 开始的树状目录结构,tree查看 2.常用文件目录操作命令是ls,cd,mkdir,rmdir 3.Linux的PATH查看是 echo $PATH，可以修改/etc/profile文件永久生效,以冒号分割 4.绝对路径,相对路径的查看 5.文件权限chmod chgrp chown Linux的文件系统用户在硬件存储设备中执行的文件建立，写入，读取，修改，转存与控制等操作都是依赖文件系统完成的。文件系统的作用是合理规划硬盘，保证用户正常使用。 Linux系统支持数十种文件系统，常见文件系统如下。 Ext3 是一款日志文件系统，能够在系统异常宕机时避免文件系统资料丢失，并能 自动修复数据的不一致与错误。 Ext4 Ext3 的改进版本，作为 RHEL 6 系统中的默认文件管理系统，它支持的存储容 量高达 1EB(1EB=1,073,741,824GB)，且能够有无限多的子目录。另外，Ext4 文件系统能够批量分配 block 块，从而极大地提高了读写效率。 XFS 是一种高性能的日志文件系统，而且是 RHEL 7 中默认的文件管理系统，它的优势在发生意外宕机后尤其明显，即可以快速地恢复可能被破坏的文件，而且强大的 日志功能只用花费极低的计算和存储性能。并且它最大可支持的存储容量为 18EB， 这几乎满足了所有需求。 /etc/fstab是用来存放文件系统的静态信息的文件cat /etc/fstab #检查linux的文件系统]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[redis之使用]]></title>
    <url>%2F2018%2F02%2F27%2Fredis%E4%B9%8B%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[================================= 1、自动分配、你在什么时候用到了自动分配？ 答：市场部或运营部招来的新的客户，单条（批量）录入数据的时候，进行自动分配。 2、那是怎么自动分配的呢？ 答：基于redis的列表实现的。相当于队列用了。 ==================================== 自动分配(redis)数据放缓存，为的就是速度快redis是支持持久化的，如果关机以后，数据已经会放在文件里了 先买上一台电脑：装上redis服务器软件 - 这个服务器有个工网IP：47.93.4.198 - 端口：6379 我们的电脑：装上链接redis的模块 - pip instaill redis redis:说白了就是一个服务器的一个软件，帮助我们在内存里面存数据 conn.lpush(&quot;names&quot;:&quot;sss&quot;) #往里边放入值 conn.lpush(&quot;names&quot;:*[地方法规&quot;，&quot;dfgdf&quot;]) #放多个值 ，从左边添加，相当于insert conn.rpush(&quot;names&quot;:*[地方法规&quot;，&quot;dfgdf&quot;]) #放多个值 ,从后面添加，相当于append conn.lpop(&quot;names&quot;) #一个一个从里面取值 ，bytes类型 conn.rpop(&quot;names&quot;) #从里面取值 ，bytes类型 conn.llen(&quot;names&quot;) #查看长度 12345678910111213141516171819202122232425262728import redisconn = redis.Redis(host="192.168.20.150",port=6379)#===========对于字符串用set,get设置，得到值===========conn.set("k13","v2") #向远程redis中写入了一个键值对val = conn.get("k13") #获取键值对print(val)conn.set("names","ss")val2 = conn.get("names")print(val2)#===========对于列表的操作: lpush操作和lpop操作，（从左边放值，从左边取值）=============val4 = conn.lpush("names_s",*["海燕","刘伟"])conn.lpush('names_s',*['把几个','鲁宁']) #'鲁宁','把几个',"刘伟","海燕",conn.delete("names_s")v = conn.llen("names_s")print(conn.llen("names_s")) #4for i in range(v): print(conn.lpop("names_s").decode("utf-8"))# ==========对于列表的操作: rpush操作和rpop操作，（从右边放值，从右边取值）======conn.rpush("abcd",[1,2,3])conn.rpush("abcd",*["a","b","c"]) #[1,2,3],a,b,c #*代表是解包，如果不加*,放进去的就是一个列表# conn.delete("abcd")v = conn.llen("abcd")# print(v) #for i in range(v): print(conn.rpop("abcd").decode("utf-8")) #c,b,a,[1,2,3] 在项目中应用链接redis，吧所有的数据列表放在redis里，吧回滚的也放在redis里面 原来是迭代器一个一个取值，现在我们可以用链接redis，rpop一个一个取值 当出问题回滚的时候（或者没有使用），我们可以用rpush吧它再添加进去，然后在取出来 conn.lindex(&quot;said_id_list_origin&quot;,0) #查看索引0对应的值 第一次运行，只有数据库有数据 如果数据库中没有取到值，那么直接返回None 接下来一个一个获取，如果取到了None，已经取完，再把备用的列表里面的数据在放回去 分配表里面的数据如果更新的话就需要重置了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import redisfrom crm import modelsPOOL = redis.ConnectionPool(host='47.93.4.198', port=6379, password='123123')CONN = redis.Redis(connection_pool=POOL)class AutoSale(object): @classmethod def fetch_users(cls): # [obj(销售顾问id,num),obj(销售顾问id,num),obj(销售顾问id,num),obj(销售顾问id,num),] sales = models.SaleRank.objects.all().order_by('-weight') sale_id_list = [] count = 0 while True: flag = False for row in sales: if count &lt; row.num: sale_id_list.append(row.user_id) flag = True count += 1 if not flag: break if sale_id_list: CONN.rpush('sale_id_list', *sale_id_list) # 自动pop数据 CONN.rpush('sale_id_list_origin', *sale_id_list) # 原来的数据 return True return False @classmethod def get_sale_id(cls): # 查看原来数据是否存在 sale_id_origin_count = CONN.llen('sale_id_list_origin') if not sale_id_origin_count: # 去数据库中获取数据，并赋值给： 原数据，pop数据 status = cls.fetch_users() if not status: return None user_id = CONN.lpop('sale_id_list') if user_id: return user_id reset = CONN.get('sale_id_reset') # 要重置 if reset: CONN.delete('sale_id_list_origin') status = cls.fetch_users() if not status: return None CONN.delete('sale_id_reset') return CONN.lpop('sale_id_list') else: ct = CONN.llen('sale_id_list_origin') for i in range(ct): v = CONN.lindex('sale_id_list_origin', i) CONN.rpush('sale_id_list', v) return CONN.lpop('sale_id_list') @classmethod def reset(cls): CONN.set('sale_id_reset',1) @classmethod def rollback(cls,nid): CONN.lpush('sale_id_list',nid) 总结： 1、什么是redis？ 2、set，get对字符串做操作的， 3、lpush,rpush,lpop,rpop对于列表做操作的 lindex：取索引 llen() ：长度 4、 delete :删除 ：公共的 扩展： redis和我们的数据库一样，不能每次都链接，redis支持连接池 不推荐 推荐 批量导入上传excel文件,页面上显示 上传文件 1、拿到文件名和文件大小 file_obj.field_name: 文件名， file_obj.size :文件大小 2、打开文件读取，以写的方式存起来 3、安装xlrd-1.1.0的两种方式 python setup.py build pip instail xlrd 4、打开excle文件做操作。拿到每一个单元格的数据，写入数据库 吧第一行排除，可以吧列表转换成字典，录入到数据库 5、作业 自动获取ID 录入客户表 录入分配表 不在创建临时xlsx文件，写在内存里面， 写上一个模板文件，让用户去下载 6、文件，用户下载文件的两种方式 吧文件写在静态文件里面，用a标签去跳转。但是这种当是可能不行 设置响应头（搜索django如何实现文件下载） 微信自动绑定]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[redis之进阶]]></title>
    <url>%2F2018%2F02%2F25%2Fredis%E4%B9%8B%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[redis介绍redis的功能特性1，高速读写 2，数据类型丰富 3，支持持久化 4，多种内存分配及回收策略 5，支持事务 6，消息队列、redis用的多的还是发布-订阅模式 7，支持高可用 8，支持分布式分片集群 linux操作系统是怎么分配内存的？ 把内存分为三大块 PSS page cache anno page：程序之间进行交互的时候。。。。#匿名页 linux操作系统以page进行分配内存，page大小默认4kb slab allocator 内存页的划分 怎么保证使用连续的内存 slab allocator redis的优势1、redis在单用户(单线程)多并发读写的性能高 2、在多用户(多线程)少读写时memache更优 3、redis是一个单核的管理机制，生产中一般是，单机多实例的框架 redis的使用下载 安装 解压 tar -zxvf redis-3.2.6.tar.gz cd redis-2.6.0 make #编译安装 yum install gcc* cd /application/redis-3.2.6/src ./redis-server &amp; #启动redis服务端 ,&amp;后台运行，不然一直占用端口 ps -ef |grep redis #查看是否启动 ./redis-cli #连接服务器 使用redis set foo bar get foo 基本的配置文件 vim /etc/redis.conf #去编辑redis.conf文件 #添加配置 daemonize yes port 6379 dbfilename dump.rdb dir &quot;/application/data/6379&quot; logfile /var/log/redis.log ###### mkdir -p /application/data/6379 ps -ef |grep redis ./redis-server /etc/redis.conf /application/redis-3.2.6/src/redis-server /etc/redis.conf #为了不用每次都切进去，在环境变量里面设置一下 cd /root vim .bash_profile PATh 添加 :/application/redis-3.2.6/src :wq保存 配置生效 source .bash_profile redis-cli 配置完成之后，可以直接在命令行调用redis命令 例如： redis-cli shutdown 或者 redis-server /etc/redis.conf #安全控制（也在配置文件里面设置） bind 10.0.0.200 #绑定ip10字段 requirepass root #没有用户只有密码，密码为root redis-cli shutdown redis-server /etc/redis.conf 设置完成之后需要换种方式打开： redis-cli -h 10.0.0.200 -a root #改完配置文件每次都需要重启，不用每次都重启，在线变更配置： 获取当前配置 CONFIG GET * 变更运行配置 CONFIG SET loglevel &apos;notice&apos; 修改密码 CONFIG SET requirepass &quot;123&quot; CONFIG GET requirepass 在线修改的配置，下次登录生效，但是重启之后配置会丢失 #Python链接redis import redis .... redis的数据持久化RDB持久化：快照，只记录一个时刻内存数据状态（快照记录某一时刻的数据） AOF持久化：只追加日志文件的方式，记录了redis里面所有的修改命令 RDB记录某一时刻的，还可以用做备份 AOF比较安全，但是比较啰嗦，每次都把所有的搜保存下来了 #如果配置持久化功能 方式一： RDB 持久化配置：还是修改配置文件 dbfilename dump.rbd dir &apos;/application/data/6379&apos; save 900 1 900秒内有一个更改 save 300 10 300秒内有10个更改 save 60 10000 60秒内有10000个更改 #也可以设置配置做持久化 方式二： set foo bar save 或者 bgsave #手工触发持久化 #配置扩展 stop-writes-on-bgsave-error yes rdbcompression yes rdbchecksum yes #AOF 配置 appendonly yes applendfsync every redis数据类型计数器 incr fensi ##你点击一下增加一下，刷点击量 incrby fensi 10000 DECR fensi #递减 DECRBY fensi 20 set foo bar set foo ex 10 hset stu(表) id(列) 100 hmset stu id 100 name zhangsna lpush pengyouquan &apos;today is nice day&apos; lpush pengyouquan &apos;today is bad day&apos; lpush pengyouquan &apos;today is a day&apos; lpop pengyouquan #删除最后一条 lrange pengyouquan 0 -1 #查看所有 有序集合：像是排行榜 发布订阅模式发布订阅模式（中间桥梁：频道）:朋友圈是很好的证明。先关注你就能看到 开两个端口 PUBLISH weibo hello 先订阅某个频道 SUBSCRIBE weibo 订阅weibo一个频道,subscribe PSUBSCRIBE * 一次性订阅多个频道（广告类） PSUBSCRIBE it.* 一次性订阅多个和it相关的频道 退出就取消订阅了 redis的事物管理redis使用multi开启事物 discard 撤销 exec 退出 redis 中的锁机制 mysql的悲观锁：我在做操作的时候，你别和我抢， redis的乐观锁：查看一下， redis的一些管理命令Info Clinet list 客户端连接的状况以及对系统的使用情况 Client kill ip:port config get * CONFIG RESETSTAT 重置统计 CONFIG GET/SET 动态修改 Dbsize FLUSHALL 清空所有数据 select 1 FLUSHDB 清空当前库 MONITOR 监控实时指令 主从复制123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111假如说你访问redis呢，访问不了呢，数据查看不了了，怎么办？ 我们要做到一个恢复的功能，所以就有了主从复制的功能 假如说一个机器废了，还有另一个机器能提供数据 至少要有两台服务器 主从复制的两种功能 1、可以实现故障的转移 failover 2、可以分担多节点的压力 blance 底层原理依赖于 同步传输rbd存储的机制 怎么搭建主从？ 准备2台或以上的redis实例 1、多配置文件（端口、数据路径、日志路径、pid） 端口、：6380(主),6381(从) 数据路径： /application/data/6380 /application/data/6381 日志路径 /var/log/redis6380.log /var/log/redis6381.log pid :记录一个程序进程号的id /application/data/6380/redis.pid /application/data/6381/redis.pid 2、主从复制的配置过程 1、创建目录 mkdir -p /application/data/6380 mkdir -p /application/data/6381 2、配置文件准备 vim /application/data/6380/redis.conf port 6380 daemonize yes pidfile /application/data/6380/redis.pid logfile "/var/log/redis6380.log" dbfilename dump.rdb dir /application/data/6380 vim /application/data/6381/redis.conf port 6381 daemonize yes pidfile /application/data/6381/redis.pid logfile "/var/log/redis6381.log" dbfilename dump.rdb dir /application/data/6381 3、启动两个实例 redis-server /application/data/6380/redis.conf redis-server /application/data/6381/redis.conf 4、构建主从 redis-cli -p 6381 slaveof 127.0.0.1 6380 5、验证主从 登录主库： redis-cli -p 6380 set foo bar 登录主库： redis-cli -p 6381 get 6、主从复制状态查看。 role info replication 7、主从复制，手工切换 slaveof no one 传统主从的缺陷1、没有自动监控机制2、没有自动切换的功能3、对于应用不透明sentinel 功能1、自动监控redis所有节点状态2、发现主库故障，自动选主切换3、自动通知应用端准备，1主2从结构比较合适。添加6382节点：mkdir -p /application/data/6382vim /application/data/6382/redis.confport 6382daemonize yespidfile /application/data/6382/redis.pidlogfile "/var/log/redis6382.log"dbfilename dump.rdbdir /application/data/6382redis-server /application/data/6382/redis.confredis-cli -p 6382slaveof 127.0.0.1 6380sentinel配置mkdir -p /application/data/26380vim /application/data/26380/sentinel.confport 26380dir "/application/data/26380"sentinel monitor mymaster 127.0.0.1 6380 1sentinel down-after-milliseconds mymaster 60000sentinel config-epoch mymaster 0启动redis-sentinel /application/data/26380/sentinel.conf Python sentinel1234567891011&gt;&gt;&gt; from redis.sentinel import Sentinel &gt;&gt;&gt; sentinel = Sentinel([('127.0.0.1', 26380)], socket_timeout=0.1) &gt;&gt;&gt; sentinel.discover_master('mymaster') ('127.0.0.1', 6379) &gt;&gt;&gt; sentinel.discover_slaves('mymaster') [('127.0.0.1', 6380)] &gt;&gt;&gt; master = sentinel.master_for('mymaster', socket_timeout=0.1) &gt;&gt;&gt; slave = sentinel.slave_for('mymaster', socket_timeout=0.1) &gt;&gt;&gt; master.set('foo', 'bar') &gt;&gt;&gt; slave.get('foo') 'bar']]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[redis之五大数据类型]]></title>
    <url>%2F2018%2F02%2F23%2Fredis%E4%B9%8B%E4%BA%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[redis的两种链接方式简单链接1234import redisconn = redis.Redis(host='10.0.0.200',port=6379)conn.set('k1','value')print(conn.get('k1')) 连接池如果要链接redis的时候推荐用连接池的方式；如果每次操作都用同一个链接，可以使用连接池 redis使用connection_poll来管理对一个redis服务的所有链接，避免每次建立，释放链接的开销默认每个redis实例都会维护一个自己的链接池。可以直接建立一个连接池，然后作为参数redis，这样就可以实现多个redis实例共享一个连接池 1234567#连接池import redispool = redis.ConnectionPool(host='10.0.0.200',port=6379)conn = redis.Redis(connection_pool=pool)conn.set('a','python')print(conn.get('a')) 例子pool.py12import redisPOOL = redis.ConnectionPool(host='10.0.0.200',port=6379) view.py1234567891011from django.shortcuts import render,HttpResponseimport redisfrom app01.pool import POOL# Create your views here.def index(request): pool = redis.Redis(connection_pool=POOL) #连接redis return HttpResponse('ok') def home(request): pool = redis.Redis(connection_pool=POOL) return HttpResponse('ok') Django-redis组件安装： pip install django-redis 配置文件 12345678910CACHES = &#123; "default": &#123; "BACKEND": "django_redis.cache.RedisCache", "LOCATION": "redis://10.0.0.200:6379", "OPTIONS": &#123; "CLIENT_CLASS": "django_redis.client.DefaultClient", #"PASSWORD": "123456", &#125; &#125;&#125; 使用 12345678#利用django-redis组件进行连接from django.core.cache import cachesimport osimport django_redisos.environ['DJANGO_SETTINGS_MODULE'] = 'redis_use.settings'conn = django_redis.get_redis_connection()conn.set('b','666') redis的字符串操作(string)Sting操作，redis中的String在内存中按照一个name对应一个value来存储 1、set(name, value, ex=None, px=None, nx=False, xx=False) # 设置值 在Redis中设置值，默认，不存在则创建，存在则修改 参数： ex，过期时间（秒） px，过期时间（毫秒） nx，如果设置为True，则只有name不存在时，当前set操作才执行 xx，如果设置为True，则只有name存在时，岗前set操作才执行2、setnx(name, value) 设置值，只有name不存在时，执行设置操作（添加） #相当于只是添加，不能进行修改操作 3、setex(name, value, time) # 设置值 # 参数： # time，过期时间（数字秒 或 timedelta对象） 4、psetex(name, time_ms, value) # 设置值 # 参数： # time_ms，过期时间（数字毫秒 或 timedelta对象） 5、mset(*args, **kwargs) 批量设置值 如： mset(k1=&apos;v1&apos;, k2=&apos;v2&apos;) 或 mset({&apos;k1&apos;: &apos;v1&apos;, &apos;k2&apos;: &apos;v2&apos;}) 6、get(name) 获取值 7、mget(keys, *args) 批量获取 如： mget(&apos;ylr&apos;, &apos;zzz&apos;) 或 r.mget([&apos;ylr&apos;, &apos;zzz&apos;]) 8、getset(name, value) 设置新值并获取原来的值 9、getrange(key, start, end) # 获取子序列（根据字节获取，非字符） # 参数： # name，Redis 的 name # start，起始位置（字节） # end，结束位置（字节） # 如： &quot;拉销量&quot; ，0-3表示 &quot;拉&quot; 待续。。 redis的列表操作(list)redis的散列表操作(类似于字典里面嵌套字典)Hash操作，也叫做散列表操作。redis中Hash在内存中的存储格式如下 1、hset(name, key, value) # name对应的hash中设置一个键值对（不存在，则创建；否则，修改） # 参数： # name，redis的name # key，name对应的hash中的key # value，name对应的hash中的value # 注： # hsetnx(name, key, value),当name对应的hash中不存在当前key时则创建（相当于添加） 2、hmset(name, mapping) # 在name对应的hash中批量设置键值对 # 参数： # name，redis的name # mapping，字典，如：{&apos;k1&apos;:&apos;v1&apos;, &apos;k2&apos;: &apos;v2&apos;} # 如： # r.hmset(&apos;xx&apos;, {&apos;k1&apos;:&apos;v1&apos;, &apos;k2&apos;: &apos;v2&apos;}) 3、hget(name,key) # 在name对应的hash中获取根据key获取value 4、hmget(name, keys, *args) # 在name对应的hash中获取多个key的值 # 参数： # name，reids对应的name # keys，要获取key集合，如：[&apos;k1&apos;, &apos;k2&apos;, &apos;k3&apos;] # *args，要获取的key，如：k1,k2,k3 # 如： # r.mget(&apos;xx&apos;, [&apos;k1&apos;, &apos;k2&apos;]) # 或 # print r.hmget(&apos;xx&apos;, &apos;k1&apos;, &apos;k2&apos;) 5、hgetall(name) 获取name对应的hash中的所有键值 6、hlen(name) 获取name对应的hash中键值对的个数 7、hkeys(name) 获取name对应的hash中所有的key的值 8、hvals(name) 获取name对应的hash中所有的value的值 9、hexists(name, key) 检查name对应的hash是否存在当前传入的key 10、hdel(name,*keys) 将name对应的hash中指定key的键值对删除 11、hincrby(name, key, amount=1) 吧原来的值自加1 hincrby (&apos;xxx&apos;,&apos;slex&apos;,amount=-1) #吧原来的值自减1 # 自增name对应的hash中的指定key的值，不存在则创建key=amount # 参数： # name，redis中的name # key， hash对应的key # amount，自增数（整数） 12、hincrbyfloat(name, key, amount=1.0) 支持浮点型的 13、hscan(name, cursor=0, match=None, count=None) # 增量式迭代获取，对于数据大的数据非常有用，hscan可以实现分片的获取数据，并非一次性将数据全部获取完，从而放置内存被撑爆 # 参数： # name，redis的name # cursor，游标（基于游标分批取获取数据） # match，匹配指定key，默认None 表示所有的key # count，每次分片最少获取个数，默认None表示采用Redis的默认分片个数 # 如： # 第一次：cursor1, data1 = r.hscan(&apos;xx&apos;, cursor=0, match=None, count=None) # 第二次：cursor2, data1 = r.hscan(&apos;xx&apos;, cursor=cursor1, match=None, count=None) # ... # 直到返回值cursor的值为0时，表示数据已经通过分片获取完毕 14、hscan_iter(name, match=None, count=None) # 利用yield封装hscan创建生成器，实现分批去redis中获取数据 # 参数： # match，匹配指定key，默认None 表示所有的key # count，每次分片最少获取个数，默认None表示采用Redis的默认分片个数 # 如： # for item in r.hscan_iter(&apos;xx&apos;): # print item # for item in r.hscan_iter(&apos;xx&apos;,match=&apos;*lx&apos;): #匹配以lx结尾的 # print item redis的集合操作(set)redis的有序集合操作(zset)]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[redis之安装]]></title>
    <url>%2F2018%2F02%2F22%2Fredis%E4%B9%8B%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[redis介绍redis是一个key-value存储系统，菲关系型数据库。和Memcached类似，他支持存储的value类型相对更多，包括字符串、列表、哈希散列表、集合、有序集合。 这些数据都支持push/pop、add/remove及取交集并集和差集及丰富的操作 而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。 与memcached一样，为了保证效率，数据都在缓存的内存中。区别的是redis 会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且 在此基础上实现master-slave(主从)同步 本质：将数据保存在内存中 用提：redis可以做缓存；redis可以做消息队列 特性： 1，可以做持久化：在配置文件设置，如果你要保存到文件，可以添加设置，就算电脑不小心关键了，数据还是存在的。 这个要不要保存都要自己来定。 2.支持存放数据的格式多（5中） 12345678910&#123; 'k1':'hiayan', #第一种字符串格式 'k2':[11,22,33,44], #第二种列表格式 'k3':&#123;11,22,33,44&#125;, #第三种集合格式 'k4':&#123; #第四种,字典，也可以叫做哈希散列表, 'n1':'xxx', 'n2':'fff' &#125;, 'k5':&#123;(11,1),('xxx':5)&#125; #有序集合&#125; 相关问题1、为什么使用redis？使用redis有哪些好处？ 1，速度快，因为数据在内存中，类似HashMap的优势就是查找和操作的时间复杂度都是o(1) 2，支持丰富的数据类型，支持string，list，set，sorted set，hash 3，支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 4，丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除。 2、redis的速度memcached有哪些优势？ 1、memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型。 2、redis的速度比memcached快很多 3、redis可以持久化其数据 redis的安装有时候会需要安装gcc 方式一：硬盘免安装1234wget http://download.redis.io/releases/redis-3.0.6.tar.gz #下载tar xzf redis-3.0.6.tar.gz #解压cd redis-3.0.6 #切换到redismake #安装 启动服务端 src/redis-server 启动客户端 src/redis-cli redis&gt; set foo bar OK redis&gt; get foo &quot;bar&quot; 方式二：安装包yum install redis /etc/init.d/redis start #开启 /etc/init.d/redis restart #重启 配置：/etc/redis/redis.conf #默认会读取这个文件去运行 方式三：rpm安装公司说你安装以下redis 有两种情况： 1、直接给你rpm包 2、或者说你直接yum install redis - 安装公司自定制 - 安装官方 ls #查看 ctrl+c #停止 结束进程（找服务器并杀掉）： ps -e|grep redis #杀掉 kill -9 12343 #重新运行 远程操作rdis的模块（模块的本质是通过socket进行通信的） mysql的端口：3306 redis的端口：6379 Python操作Redissudo pip install redisorsudo easy_install redisor源码安装详见：https://github.com/WoLpH/redis-py]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[git下]]></title>
    <url>%2F2018%2F01%2F14%2Fgit%E4%B8%8B%2F</url>
    <content type="text"><![CDATA[分支管理策略1）master分支 非常稳定的，只用来发布新版本，平时不在上面干活 2）dev分支 不稳定的，主要在上面干活，每个人都有自己的分支，时不时的往dev分支上合并 通常，合并分支时，如果可能，Git会用`Fast forward`模式，但这种模式下，删除分支后，会丢掉分支信息。 如果要强制禁用Fast forward模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。 &gt; git log --graph --pretty=oneline --abbrev-commit Bug分支你目前在dev分支上工作，工作到一半，但突然有一个紧急的bug需要修复，可以先保存你的工作现场，修复完bug后，在切回来。 步骤： 当前在dev分支上： git stash # 把当前工作现场“储藏”起来 切换到要修复bug的分支（假定master）： git checkout master git checkout -b issue-101 .... 修复问题 git add filename git commit filename 把修改合并到修复的分支： git checkout master git merge --no-ff -m &quot;merge fix 101 modification&quot; issue-101 git branch -D issue-101 切换回工作现场： git checkout dev git stash list # 查看之前保存了哪些工作现场 git stash drop 两种恢复方式： 1）git stash apply恢复，但是恢复后，stash内容并不删除，你需要用git stash drop来删除 git stash apply stash@{0} git stash drop stash@{0} 2）git stash pop，恢复的同时把stash内容也删了 Feature分支与bug分支类似 两条命令： 1）git branch -d dev_name # 已经合并完的分支可以使用此命令删除 2）git branch -d dev_name # 强制删除分支（未合并的也可以） 多人协作多个人在同一分支上工作，如何正确的合并文件？ 两种情况： **1）你和他人同时修改同一个文件，他人修改完成，提前推送到远程，如何提交你的修改** 详细步骤： 1）试图用git push origin &lt;branch-name&gt;推送自己的修改； 2）如果推送失败，则因为远程分支比你的本地更新，需要先用git pull拉取远程最新的版本； 3）如果合并有冲突，则解决冲突，并在本地提交； 4）没有冲突或者解决掉冲突后，再用git push origin &lt;branch-name&gt;推送 **2）你和他人操作的不是同一个文件 详细步骤： 1）试图用git push origin &lt;branch-name&gt;推送自己的修改； 2）如果推送失败，先用git pull拉取远程最新的版本； 3）git add . # 添加本地的全部修改到暂存区 4）git commit -m &quot;说明信息&quot; # 提交更改至本地 5）git push origin &lt;branch-name&gt;推送本地分支至远程 提交更改前，都要先git pull拉取远程最新版本 当从远程克隆时，Git自动把本地的master分支与远程的master分支对应起来，远程仓库的默认名称是origin。 查看远程库信息： git remote -v 推送分支： git push origin master 把本地的mater分支推送到远程对应的master分支上 git push origin dev 把本地的dev分支推送到远程对应的dev分支（远程没有dev分支会自动创建一个dev分支） 创建远程origin的dev分支到本地 git checkout -b dev origin/dev 指定本地dev分支与远程origin/dev分支的链接 git branch --set-upstream-to origin/dev dev 或 git branch --track origin/dev dev 标签tag是一个容易记住的有意义的名字，它跟某个commit绑定在一起。 打标签： git tag tag_name # 默认打在最新提交的commit上,当前HEAD的指向 git tag # 查看标签 git show tag_name # 查看标签详细信息 在指定的commit上打标签： git log --pretty=oneline # 查看commit id git log -a tag_name -m &quot;explain content&quot; commit_id 推送标签： git push origin tag_name # 推送一个指定的标签 git push origin --tags # 推送全部尚未推送到远程的本地标签 删除标签： 1) 标签尚未推送到远程 git tag -d tag_name 2）标签已推送到远程 git tag -d tag_name git push origin :refs/tags/tag_name Rebase解决查看log分支多，混乱的问题；遗留]]></content>
      <categories>
        <category>git</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[conda常用命令]]></title>
    <url>%2F2018%2F01%2F14%2Fconda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[查看 conda 版本号conda -Vconda –version 环境管理 查看当前有哪些环境 conda env list 或conda info -e 实际执行命令示例:➜ ~ conda env list conda environments:#base * /anaconda3flaskdev /anaconda3/envs/flaskdevpythonRoad /anaconda3/envs/pythonRoadtest_py2 /anaconda3/envs/test_py2 ➜ ~ conda info -e conda environments:#base * /anaconda3flaskdev /anaconda3/envs/flaskdevpythonRoad /anaconda3/envs/pythonRoadtest_py2 /anaconda3/envs/test_py2 查看环境管理的命令帮助 conda env -h 创建环境 conda create –name your_env_name 创建指定 python 版本的环境 conda create –name your_env_name python=2.7conda create –name your_env_name python=3.6 创建包含某些包的环境 conda create –name your_env_name numpy scrapy 创建指定版本下包含某些包的环境 conda create –name your_env_name python=3.6 numpy scrapy 激活某个环境 source activate target_env_name 关闭激活的环境 source deactivate target_env_name 复制某个环境 conda create –name new_env_name –clone old_env_name 删除某个环境 conda remove –name target_env_name –all 包管理 列举当前活跃环境下的所有包 conda list 列举一个指定环境下的所有包 conda list -n your_env_name 为激活环境安装某个包 conda install package_name 为指定环境安装某个包 conda install –name target_env_name package_name 更新当前环境某个包 conda update package_name 更新指定环境某个包 conda update -n target_env_name package_name 删除当前环境某个包 conda remove package_name注意: 如果是通过pip安装的包,移除时也请使用 pip uninstall package_name 命令移除,如果使用 conda remove 可能会发生异常,导致conda不可用 删除指定环境某个包 conda remove -n target_env_name package_name 搜索某个包信息 conda search package_name 更新anaconda conda update anaconda 更新python至最新版本 conda update python 更新所有包 conda update –all 分享环境把自己的环境分享给别人,方便他人快速建立与你一模一样的环境(同一个版本的python及各种包). 一个分享环境快速的方法就是给他人一个你要分享环境的.yml文件步骤:1) 生成欲分享环境的yml文件 conda env export &gt; environment.yml 2) 他人在自己本地使用yml文件创建文件 conda env create -f environment.yml 参考博客: https://blog.csdn.net/menc15/article/details/71477949/]]></content>
      <categories>
        <category>conda</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[git上]]></title>
    <url>%2F2018%2F01%2F03%2Fgit%E4%B8%8A%2F</url>
    <content type="text"><![CDATA[目录： 建立本地版本库 本地版本库与远程关联 修改文件并提交 创建分支,修改文件合并至master git的由来linux系统是很多开发者贡献代码不断完善的,linux的创始人linus起初管理贡献者的代码,是通过手工的方式,但随着代码的增多,很难通过手工方式去管理,于是找了一个商业的版本控制系统BitKeeper管理代码. 开发Samba的Andrew试图破解BitKeeper的协议（这么干的其实也不只他一个），被BitMover公司发现了（监控工作做得不错！），于是BitMover公司怒了，要收回Linux社区的免费使用权。 Linus可以向BitMover公司道个歉，保证以后严格管教弟兄们，嗯，这是不可能的。实际情况是这样的： Linus花了两周时间自己用C写了一个分布式版本控制系统，这就是Git！一个月之内，Linux系统的源码已经由Git管理了！ 集中式与分布式区别- 集中式： cvs, svn 版本库集中放在中央服务器上,所有人干活时,都要先从中央服务器获取最新版本到本地,然后在本地修改,干完活后,将修改推送到中央服务器. **必须联网**才能工作. - 分布式 每个人的电脑都是一个版本库,工作的时候 **不需要联网**,直接在本地修改,提交就可以.你和同事同时修改一个文件A,修改完成后互相将自己修改的文件推送给对方即可. **安全性高**, 每个人的本地都有一个完整的版本库,某个人的电脑突然崩溃,从其他人那直接copy一份就可以了. 但集中式版本控制系统,一旦中央服务器垮掉,版本库信息就都丢失了. 创建版本库,添加文件命令: - 创建版本库 mkdir studyGit git init - 添加文件 vim readme.txt git add readme.txt git commit -m &quot;注释说明,方便自己或他人查看&quot; 修改文件并提交命令: - vim 编辑修改文件内容 - git status 查看当前仓库状态 - git diff filename 查看文件具体改动内容 - 提交: git add filename git commit -m &quot;本次提交注释说明&quot; 版本回退Git的版本回退速度非常快，因为Git在内部有个指向当前版本的HEAD指针，当你回退版本的时候，Git仅仅是把HEAD指向至你切换的版本. 命令: - 回退到上一个版本 git reset --hard HEAD^ - 回退到上上版本 git reset --hard HEAD^^ - 回退到指定版本 git log 查看你要切换版本的commit id 或 git log --pretty=oneline git reset --hard target_commit_id - 回退之后后悔了,想切换到回退前的版本 1) 通过git log是找不到回退前那次提交的日志的,没办法指定commit id回退切换 2) 通过git reflog查看, git reflog是记录我们的历史命令的,找到你那次提交历史命令前的commit id,即可切换回去 工作区和暂存区工作区: 电脑上直接看到的,你管理的文件夹(使用git init创建的),就是工作区 暂存区: 在工作区下,隐藏的.git文件夹,其中有很多文件,有几个重要的要理解: - 暂存区: stage - 版本信息(master分支) - HEAD指针,指向具体分支 提交工作区的文件修改或新增文件: 1) git add files -&gt; 实际将这些修改先推送到本地暂存区(暂存区中存放了所有待提交的文件) 2) git commit -m &quot;说明&quot; -&gt; 提交暂存区中的所有文件至master或分支版本 管理修改工作区中readme.txt文件 1) 第一次修改, 增加一行内容, git add readme.txt 2) 第二次修改, 又增加了一行内容, 但未执行 git add readme.txt 3) git commit -m &quot;注释&quot;; 那么此次提交的只是第一次修改的内容 git diff HEAD -- readme.txt 查看工作区中与版本库中的不同之处 撤销修改1) 工作区修改,改乱了,还没有提交至暂存区; 可以通过 git checkout -- filename 恢复至与版本库一致的状态 2) 工作区修改,改乱了,但之前已提交至暂存区,撤销修改: git reset HEAD filename 把暂存区的修改撤销掉(unstage) git checkout -- filename 恢复工作区与版本库一致 删除文件git rm filename git commit -m &quot;delete file filename&quot; 远程仓库关联1) 创建ssh key: ssh-keygen -t rsa -C &quot;youremail@example.com&quot; # 一路回车即可 在用户主目录里会生成一个.ssh文件夹,里面有id_rsa和id_rsa.pub, id_rsa是私钥, id_rsa.pub是公钥; 登录github,进入个人账户settings页面,选择ssh key -&gt; add new; 添加, 将id_rsa.pub复制到页面中,完成. 2) 添加远程仓库 - 在github网站新增仓库,与本地要关联的仓库同名 - 进入本地仓库所在的目录, git remote add origin &lt;新增的远程仓库地址&gt; - git push -u origin master # 将本地仓库的master分支推送到远程服务器上,后续提交可以省略参数-u(远程初始仓库为空,所以加-u) - 本地修改文件,提交; 推送至远程 克隆远程仓库进入你想保存仓库的路径,然后执行: git clone &lt;远程仓库地址&gt; 创建与合并分支查看分支：git branch 创建分支：git branch &lt;name&gt; 切换分支：git checkout &lt;name&gt; 创建+切换分支：git checkout -b &lt;name&gt; 合并某分支到当前分支：git merge &lt;name&gt; 删除分支：git branch -d &lt;name&gt; 解决冲突1) 在分支上修改了文件,并commit 2) 在mster上修改了文件,并commit 3) git merge &lt;ranchname&gt;; 报错, 无法实现快速合并, 需先解决冲突, 把冲突文件改成自己想要的内容, 然后 git add filename, git commit -m &quot;注释&quot;.]]></content>
      <categories>
        <category>git</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django的ContentType组件]]></title>
    <url>%2F2017%2F11%2F30%2FDjango%E7%9A%84ContentType%E7%BB%84%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[需求我们商城里有很多的商品，节日要来了，我们要搞活动 那么我们就要设计优惠券，优惠卷都有什么类型嗯，满减的，折扣的，立减的等 我们对应着我们活动类型，对我们的某类商品设计优惠券， 比如： 家电是一类商品 食物是一类商品 那么我们可以设计家电折扣优惠卷，以及食物满减优惠卷等 那么表结构怎么设计 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849from django.db import models class Appliance(models.Model): """ 家用电器表 id name 1 冰箱 2 电视 3 洗衣机 """ name = models.CharField(max_length=64) class Food(models.Model): """ 食物表 id name 1 面包 2 牛奶 """ name = models.CharField(max_length=32) class Fruit(models.Model): """ 水果表 id name 1 苹果 2 香蕉 """ name = models.CharField(max_length=32) class Coupon(models.Model): """ 优惠券表 id name appliance_id food_id fruit_id 1 通用优惠券 null null null 2 冰箱折扣券 1 null null 3 电视折扣券 2 null null 4 苹果满减卷 null null 1 我每增加一张表就要多增加一个字段 """ name = models.CharField(max_length=32) appliance = models.ForeignKey(to="Appliance", null=True, blank=True) food = models.ForeignKey(to="Food", null=True, blank=True) fruit = models.ForeignKey(to="Fruit", null=True, blank=True)&lt;br&gt;# 实际上我们商品的种类会特别的多，导致我们这张表外键越来越多 遇到这种一张表要跟多张表进行外键关联的时候，我们的Django提供了ContentType组件 ContentType组件ContentType是Django内置的一个应用，可以追踪项目中所有的APP和model的对应关系，并且记录在ContentType表中。 当我们的项目做数据库迁移后，会有很多DJango自带的表，其中就有dJango_content_type表 ContentType组件应用1，在model中定义ForeignKey字段，并关联到ContentType表，通常这个字段命名为content-type 2，在model中定义PositiveIntergerField字段, 用来存储关联表中的主键，通常我们用object_id 3，在model中定义GenericForeignKey字段，传入上面两个字段的名字 4，方便反向查询可以定义GenericRelation字段 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657from django.db import modelsfrom django.contrib.contenttypes.models import ContentTypefrom django.contrib.contenttypes.fields import GenericForeignKey, GenericRelation class Appliance(models.Model): """ 家用电器表 id name 1 冰箱 2 电视 3 洗衣机 """ name = models.CharField(max_length=64) coupons = GenericRelation(to="Coupon") class Food(models.Model): """ 食物表 id name 1 面包 2 牛奶 """ name = models.CharField(max_length=32) class Fruit(models.Model): """ 水果表 id name 1 苹果 2 香蕉 """ name = models.CharField(max_length=32) class Coupon(models.Model): """ 优惠券表 id name appliance_id food_id fruit_id 1 通用优惠券 null null null 2 冰箱折扣券 1 null null 3 电视折扣券 2 null null 4 苹果满减卷 null null 1 我每增加一张表就要多增加一个字段 """ name = models.CharField(max_length=32) # appliance = models.ForeignKey(to="Appliance", null=True, blank=True) # food = models.ForeignKey(to="Food", null=True, blank=True) # fruit = models.ForeignKey(to="Fruit", null=True, blank=True) # 第一步 content_type = models.ForeignKey(to=ContentType) # 第二步 object_id = models.PositiveIntegerField() # 第三步 content_object = GenericForeignKey('content_type', 'object_id') 数据库迁移后，添加数据，再进行增删改操作 基本的使用12345678910111213141516171819202122232425262728293031323334353637from django.http import HttpResponsefrom rest_framework.views import APIViewfrom rest_framework.response import Responsefrom django.contrib.contenttypes.models import ContentTypefrom .models import Appliance, Coupon # Create your views here. class Test(APIView): def get(self, request): # 通过ContentType获得表名 content = ContentType.objects.filter(app_label="app01", model="appliance").first() # 获得表model对象 相当于models.Applicance model_class = content.model_class() ret = model_class.objects.all() # 为海尔冰箱创建一条优惠记录 ice_box = Appliance.objects.filter(id=1).first() Coupon.objects.create(name="海尔冰箱折扣券", content_object=ice_box) # 查询优惠券id=1绑定了哪个商品 coupon_obj = Coupon.objects.filter(id=1).first() goods_obj = coupon_obj.content_object print(goods_obj.name) # 查询海尔冰箱的所有优惠券 id=1 # 我们定义了反向查询 results = ice_box.coupons.all() print(results[0].name) # 如果没定义反向查询 content = ContentType.objects.filter(app_label="app01", model="appliance").first() result = Coupon.objects.filter(content_type=content, object_id=1).all() print(result[0].name) return HttpResponse(ret)]]></content>
      <categories>
        <category>restful framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CORS跨域请求]]></title>
    <url>%2F2017%2F11%2F29%2FCORS%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82%2F</url>
    <content type="text"><![CDATA[跨域 CORS跨域请求CORS即Cross Origin Resource Sharing 跨域资源共享 跨域请求分为两种，一种叫简单请求，一种是复杂请求 简单请求HTTP方法是下列方法之一 HEAD，GET，POST HTTP头信息不超出以下几种字段 Accept， Accept-Language， Content-Language， Last-Event-ID Content-Type只能是下列类型中的一个 application/x-www-from-urlencoded multipart/form-data text/plain 任何一个不满足上述要求的请求，即会被认为是复杂请求 复杂请求会先发出一个预请求，我们也叫预检，OPTIONS请求 浏览器的同源策略跨域是因为浏览器的同源策略导致的，也就是说浏览器会阻止非同源的请求 那么什么是非同源的呢？ 即域名不同，端口不同都属于非同源 浏览器只阻止表单以及ajax请求，并不会阻止src请求，所以我们的cnd，图片等src请求都可以发 解决跨域JSONPjsonp的实现原理是根据浏览器不组织src请求入手来实现的 JsonP实现的后端代码123456class Test(APIView): def get(self, request): callback = request.query_params.get("callback", "") ret = callback + "(" + "'success'" + ")" return HttpResponse(ret) JsonP测试前端代码123456789101112131415161718192021222324252627&lt;button id="btn_one"&gt;点击我向JsonP1发送请求&lt;/button&gt;&lt;script&gt; // 测试发送请求失败 跨域不能得到数据 $('#btn_one').click(function () &#123; $.ajax(&#123; url: "http://127.0.0.1:8000/jsonp1", type: "get", success: function (response) &#123; console.log(response) &#125; &#125;) &#125;); function handlerResponse(response) &#123; alert(response) &#125;; window.onload = function () &#123; $("#btn_one").click(function () &#123; let script_ele = document.createElement("script"); script_ele.src = "http://127.0.0.1:8000/jsonp1?callback=handlerResponse"; document.body.insertBefore(script_ele, document.body.firstChild); &#125;) &#125;&lt;/script&gt; JsonP解决跨域问题只能发送get请求，并且实现起来需要前后端交互比较多 添加响应头中间件响应头12345678910from django.utils.deprecation import MiddlewareMixinclass MyCors(MiddlewareMixin): def process_response(self, request, response): response["Access-Control-Allow-Origin"] = "*" if request.method == "OPTIONS": response["Access-Control-Allow-Headers"] = "Content-Type" response["Access-Control-Allow-Methods"] = "DELETE, PUT, PATCH" return response]]></content>
      <categories>
        <category>restful framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[RESTful_API]]></title>
    <url>%2F2017%2F11%2F27%2FRESTful-API%2F</url>
    <content type="text"><![CDATA[什么是RESTful REST与技术无关，代表的是一种软件架构风格，REST是Representational State Transfer的简称，中文翻译为“表征状态转移” REST从资源的角度类审视整个网络，它将分布在网络中某个节点的资源通过URL进行标识，客户端应用通过URL来获取资源的表征，获得这些表征致使这些应用转变状态 所有的数据，不管是通过网络获取的还是操作数据库获得（增删改查）的数据，都是资源，将一切数据视为资源是REST区别与其他架构风格的最本质属性 对于REST这种面向资源的架构风格，有人提出一种全新的结构理念，即：面向资源架构（ROA：Resource Oriented Architecture） 对互联网上的任意东西都视为资源，他认为一个url就是一个资源 比如：http://www.xxx.com/get_user/ 什么是APIAPI就是接口，提供的url。接口有两个用途： 为别人提供服务 前后端分离，一个写vue，一个写后端，他们之间都是通过ajax请求 基于Django实现的API网络应用程序，分为前端和后端两个部分。 当前的发展趋势，就是前端设备层出不穷（手机、平板、桌面电脑、其他专用设备......）。 因此，必须有一种统一的机制，方便不同的前端设备与后端进行通信。 这导致API构架的流行，甚至出现&quot;API First&quot;的设计思想。 RESTful API是目前比较成熟的一套互联网应用程序的API设计理论。 那么先来简单了解一下 协议API与用户的通信协议，总是使用HTTPs协议 域名有两种方式 方式一： 尽量将API部署在专用域名（会存在跨域问题） https://api.example.com 方式二：如果确定API很简单，不会有进一步扩展，可以考虑放在主域名下。 https://example.org/api/ 版本(Versioning)应该将API的版本号放入URL。 https://api.example.com/v1/ 另一种做法是，将版本号放在HTTP头信息中，但不如放入URL方便和直观。Github采用这种做法。 路径(Endpoint)路径又称”终点”（endpoint），表示API的具体网址。 在RESTful架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。一般来说，数据库中的表都是同种记录的”集合”（collection），所以API中的名词也应该使用复数。 举例来说，有一个API提供动物园（zoo）的信息，还包括各种动物和雇员的信息，则它的路径应该设计成下面这样。 https://api.example.com/v1/zoos https://api.example.com/v1/animals https://api.example.com/v1/employees HTTP动词对于资源的具体操作类型，由HTTP动词表示。 常用的HTTP动词有下面五个（括号里是对应的SQL命令）。 GET（SELECT）：从服务器取出资源（一项或多项）。即获取数据 POST（CREATE）：在服务器新建一个资源。 即添加数据 PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。即更新数据 PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。即更新数据 DELETE（DELETE）：从服务器删除资源 。即删除数据 还有两个不常用的HTTP动词。 HEAD：获取资源的元数据。 OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。 下面是一些例子： GET /zoos：列出所有动物园 POST /zoos：新建一个动物园 GET /zoos/ID：获取某个指定动物园的信息 PUT /zoos/ID：更新某个指定动物园的信息（提供该动物园的全部信息） PATCH /zoos/ID：更新某个指定动物园的信息（提供该动物园的部分信息） DELETE /zoos/ID：删除某个动物园 GET /zoos/ID/animals：列出某个指定动物园的所有动物 DELETE /zoos/ID/animals/ID：删除某个指定动物园的指定动物 过滤信息(Filtering)如果记录数量很多，服务器不可能都将它们返回给用户。API应该提供参数，过滤返回结果。 下面是一些常见的参数。 ?limit=10：指定返回记录的数量 ?offset=10：指定返回记录的开始位置。 ?page=2&amp;per_page=100：指定第几页，以及每页的记录数。 ?sortby=name&amp;order=asc：指定返回结果按照哪个属性排序，以及排序顺序。 ?animal_type_id=1：指定筛选条件 参数的设计允许存在冗余，即允许API路径和URL参数偶尔有重复。比如， GET /zoo/ID/animals 与 GET /animals?zoo_id=ID 的含义是相同的。 状态码(status codes)服务器向用户返回的状态码和提示信息，常见的有以下一些（方括号中是该状态码对应的HTTP动词）。 200 OK - [GET]：服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）。 201 CREATED - [POST/PUT/PATCH]：用户新建或修改数据成功。 202 Accepted - [*]：表示一个请求已经进入后台排队（异步任务） 204 NO CONTENT - [DELETE]：用户删除数据成功。 400 INVALID REQUEST - [POST/PUT/PATCH]：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的。 401 Unauthorized - [*]：表示用户没有权限（令牌、用户名、密码错误）。 403 Forbidden - [*] 表示用户得到授权（与401错误相对），但是访问是被禁止的。 404 NOT FOUND - [*]：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的。 406 Not Acceptable - [GET]：用户请求的格式不可得（比如用户请求JSON格式，但是只有XML格式）。 410 Gone -[GET]：用户请求的资源被永久删除，且不会再得到的。 422 Unprocesable entity - [POST/PUT/PATCH] 当创建一个对象时，发生一个验证错误。 500 INTERNAL SERVER ERROR - [*]：服务器发生错误，用户将无法判断发出的请求是否成功。 错误处理(Error handing)如果状态码是4xx，就应该向用户返回出错信息。一般来说，返回的信息中将error作为键名，出错信息作为键值即可。 { error: &quot;Invalid API key&quot; } 返回结果针对不同操作，服务器向用户返回的结果应该符合以下规范 GET /collection：返回资源对象的列表（数组） GET /collection/resource：返回单个资源对象 POST /collection：返回新生成的资源对象 PUT /collection/resource：返回完整的资源对象 PATCH /collection/resource：返回完整的资源对象 DELETE /collection/resource：返回一个空文档 Hypermedia API 超媒体APIRESTful API最好做到Hypermedia，即返回结果中提供链接，连向其他API方法，使得用户不查文档，也知道下一步应该做什么。 比如，当用户向api.example.com的根目录发出请求，会得到这样一个文档。 {&quot;link&quot;: { &quot;rel&quot;: &quot;collection https://www.example.com/zoos&quot;, #表示这个API与当前网址的关系（collection关系，并给出该collection的网址） &quot;href&quot;: &quot;https://api.example.com/zoos&quot;, #API路径 &quot;title&quot;: &quot;List of zoos&quot;, #API的标题 &quot;type&quot;: &quot;application/vnd.yourformat+json&quot; #返回类型 }} Hypermedia API的设计被称为HATEOAS。Github的API就是这种设计，访问api.github.com会得到一个所有可用API的网址列表。 { &quot;current_user_url&quot;: &quot;https://api.github.com/user&quot;, &quot;authorizations_url&quot;: &quot;https://api.github.com/authorizations&quot;, // ... } 从上面可以看到，如果想获取当前用户的信息，应该去访问api.github.com/user，然后就得到了下面结果。 { &quot;message&quot;: &quot;Requires authentication&quot;, &quot;documentation_url&quot;: &quot;https://developer.github.com/v3&quot; } 基于Django实现API方式一：FBV模式全局url1234567891011from django.contrib import adminfrom django.conf.urls import url, includefrom app01 import viewsfrom app02 import viewsurlpatterns = [ url('admin/', admin.site.urls), # path('hosts/',views.HostView.as_view()), url('app02/', include('app02.urls'))] app02/url123456789from app02 import viewsfrom django.conf.urls import urlurlpatterns = [ url('^users/', views.users), url('^user/(\d+)', views.user), url('^users/', views.UsersView.as_view()), url('^user/', views.UserView.as_view()),] views1234567891011121314151617181920212223from django.shortcuts import render,HttpResponse# Create your views here.import jsondef users(request): response = &#123;'code':1000,'data':None&#125; #code用来表示状态，比如1000代表成功，1001代表 response['data'] = [ &#123;'name':'haiyan','age':22&#125;, &#123;'name':'haidong','age':10&#125;, &#123;'name':'haixiyu','age':11&#125;, ] return HttpResponse(json.dumps(response)) #返回多条数据def user(request,pk): if request.method =='GET': return HttpResponse(json.dumps(&#123;'name':'haiyan','age':11&#125;)) #返回一条数据 elif request.method =='POST': return HttpResponse(json.dumps(&#123;'code':1111&#125;)) #返回一条数据 elif request.method =='PUT': pass elif request.method =='DELETE': pass 方式二：CBV模式app02/url123456from app02 import viewsfrom django.conf.urls import url urlpatterns = [ url('^users/', views.UsersView.as_view()), url('^user/', views.UserView.as_view()),] 基于django实现的API许多功能都需要我们自己开发， 这时候djangorestframework就给我们提供了方便， 直接基于它来返回数据，总之原理都是一样的， 就是给一个接口也就是url， 让前端的人去请求这个url去获取数据， 在页面上显示出来。 这样也就达到了前后端分离的效果。 下面我们来看看基于Django Rest Framework框架实现 views基于Django Rest Framework框架的实现自定义认证12345678910111213class MyAuthtication(BasicAuthentication): def authenticate(self, request): token = request.query_params.get('token') #注意是没有GET的，用query_params表示 if token == 'zxxzzxzc': return ('uuuuuu','afsdsgdf') #返回user，auth raise APIException('认证错误')class UserView(APIView): authentication_classes = [MyAuthtication,] def get(self,request,*args,**kwargs): print(request.user) print(request.auth) return Response('用户列表') 应用主要是做Token验证 url中as_view里面调用了dispatch方法。 可以有两种方式 局部使用urls.py1234567from app01 import viewsfrom django.conf.urls import urlurlpatterns = [ # django rest framework url('^hosts/', views.HostView.as_view()), url(r'^auth/', views.AuthView.as_view()),] views.py1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586from django.shortcuts import render,HttpResponse# Create your views here.from rest_framework.views import APIViewfrom rest_framework.views import Requestfrom rest_framework.authentication import SessionAuthenticationfrom rest_framework.authentication import BaseAuthentication, BasicAuthenticationfrom rest_framework.parsers import JSONParserfrom rest_framework.negotiation import DefaultContentNegotiationfrom rest_framework.exceptions import APIExceptionfrom app01 import modelsfrom rest_framework.response import Response #友好的显示返回结果class AuthView(APIView): #auth登录页面不需要验证，可设置 authentication_classes = [] #登录页面不需要认证 def get(self,request): ''' 接收用户名和密码 :param request: :return: ''' ret = &#123;'code':1000,'msg':None&#125; user = request.query_params.get('username') pwd = request.query_params.get('password') print(user,pwd) obj = models.UserInfo.objects.filter(username=user,password=pwd).first() print(obj) if not obj : ret['code'] = 1001 ret['msg'] = '用户名或者密码错误' return Response(ret) #创建随机字符串 import time import hashlib ctime = time.time() key = '%s|%s'%(user,ctime) m = hashlib.md5() m.update(key.encode('utf-8')) token = m.hexdigest() #保存数据 obj.token = token obj.save() ret['token'] = token return Response(ret)class HostView(APIView): def dispatch(self, request, *args, **kwargs): return super().dispatch(request, *args, **kwargs) # authentication_classes = [MyAuthtication] def get(self,request,*args,**kwargs): print(request.user,'dddddddddddffffff') print(request.auth,'dddddddddd') #原来的request，django.core.handlers.wsgi.WSGIRequest #现在的request ,rest_framework.request.Request # print(request) authentication_classes = [SessionAuthentication,BaseAuthentication] # print(self.authentication_classes) # [&lt;class 'rest_framework.authentication.SessionAuthentication'&gt;, # &lt;class 'rest_framework.authentication.BasicAuthentication'&gt;] return HttpResponse('GET请求的响应内容') def post(self,request,*args,**kwargs): pass # try: # try : # current_page = request.POST.get("page") # # current_page = int(current_page) # int("asd") # except ValueError as e: # print(e) # raise #如果有raise说明自己处理不了了，就交给下面的一个去捕捉了 # except Exception as e: # print("OK") return HttpResponse('post请求的响应内容') def put(self, request, *args, **kwargs): return HttpResponse('put请求的响应内容') 全局使用settings12345678#注册认证类REST_FRAMEWORK = &#123; 'UNAUTHENTICATED_USER': None, 'UNAUTHENTICATED_TOKEN': None, #将匿名用户设置为None "DEFAULT_AUTHENTICATION_CLASSES": [ "app01.utils.MyAuthentication", ],&#125; 全局验证1234567891011121314from rest_framework.authentication import BaseAuthenticationfrom rest_framework.exceptions import APIExceptionfrom app02 import modelsclass MyAuthentication(BaseAuthentication): def authenticate(self, request): token=request.query_params.get('token') print(token) obj=models.UserInfo.objects.filter(token=token).first() print(obj) if obj: return (obj.username,obj) raise APIException('没有通过验证') 注：rest_framewor是一个app需要settings里面设置。]]></content>
      <categories>
        <category>restful framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django-Rest-Framework源码流程]]></title>
    <url>%2F2017%2F11%2F25%2FDjango-Rest-Framework%E6%BA%90%E7%A0%81%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[一请求到来之后，都要先执行dispatch方法，dispatch方法方法根据请求方式的不同触发get/post/put/delete等方法 注意：APIView中的dispatch方法有很多功能 123456789101112131415161718192021222324252627282930313233343536def dispatch(self, request, *args, **kwargs): """ `.dispatch()` is pretty much the same as Django's regular dispatch, but with extra hooks for startup, finalize, and exception handling. """ self.args = args self.kwargs = kwargs 第一步：对request进行加工（添加数据） request = self.initialize_request(request, *args, **kwargs) self.request = request self.headers = self.default_response_headers # deprecate? try: #第二步： #处理版权信息 #认证 #权限 #请求用户进行访问频率的限制 self.initial(request, *args, **kwargs) # Get the appropriate handler method if request.method.lower() in self.http_method_names: handler = getattr(self, request.method.lower(), self.http_method_not_allowed) else: handler = self.http_method_not_allowed # 第三步、执行：get/post/put/delete函数 response = handler(request, *args, **kwargs) except Exception as exc: response = self.handle_exception(exc) #第四步、 对返回结果再次进行加工 self.response = self.finalize_response(request, response, *args, **kwargs) return self.response 二上面是大致步骤，下面我们来具体分析一下，看每个步骤中都具体干了什么事 对request进行加工（添加数据）我们看看request里面都添加了那些数据 a首先 request = self.initialize_request(request, *args, **kwargs) 点进去，会发现：在Request里面多加了四个，如下 123456789101112131415def initialize_request(self, request, *args, **kwargs): """ Returns the initial request object. """ #吧请求弄成一个字典返回了 parser_context = self.get_parser_context(request) return Request( request, parsers=self.get_parsers(), #解析数据，默认的有三种方式，可点进去看 #self.get_authenticator优先找自己的，没有就找父类的 authenticators=self.get_authenticators(), #获取认证相关的所有类并实例化，传入request对象供Request使用 negotiator=self.get_content_negotiator(), parser_context=parser_context ) b获取认证相关的类的具体 authenticators=self.get_authenticators() 123456def get_authenticators(self): """ Instantiates and returns the list of authenticators that this view can use. """ #返回的是对象列表 return [auth() for auth in self.authentication_classes] #[SessionAuthentication,BaseAuthentication] c查看认证的类：self.authentication_classes 1authentication_classes = api_settings.DEFAULT_AUTHENTICATION_CLASSES #默认的，如果自己有会优先执行自己的 d接着走进api_settings 1api_settings = APISettings(None, DEFAULTS, IMPORT_STRINGS) #点击继承的DEFAULTS类 123456DEFAULTS = &#123; # Base API policies 'DEFAULT_AUTHENTICATION_CLASSES': ( 'rest_framework.authentication.SessionAuthentication', #这时候就找到了他默认认证的类了，可以导入看看 'rest_framework.authentication.BasicAuthentication' ), e导入了类看看类里面具体干了什么 12from rest_framework.authentication import SessionAuthenticationfrom rest_framework.authentication import BaseAuthentication f看到里面有个authenticate方法和authenticate_header方法 12345678910111213141516171819class BaseAuthentication(object): """ All authentication classes should extend BaseAuthentication. """ def authenticate(self, request): """ Authenticate the request and return a two-tuple of (user, token). """ raise NotImplementedError(".authenticate() must be overridden.") def authenticate_header(self, request): """ Return a string to be used as the value of the `WWW-Authenticate` header in a `401 Unauthenticated` response, or `None` if the authentication scheme should return `403 Permission Denied` responses. """ pass 具体处理认证，从headers里面能获取用户名和密码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class BasicAuthentication(BaseAuthentication): """ HTTP Basic authentication against username/password. """ www_authenticate_realm = 'api' def authenticate(self, request): """ Returns a `User` if a correct username and password have been supplied using HTTP Basic authentication. Otherwise returns `None`. """ auth = get_authorization_header(request).split() if not auth or auth[0].lower() != b'basic': return None #返回none不处理。让下一个处理 if len(auth) == 1: msg = _('Invalid basic header. No credentials provided.') raise exceptions.AuthenticationFailed(msg) elif len(auth) &gt; 2: msg = _('Invalid basic header. Credentials string should not contain spaces.') raise exceptions.AuthenticationFailed(msg) try: auth_parts = base64.b64decode(auth[1]).decode(HTTP_HEADER_ENCODING).partition(':') #用partition切割冒号也包括 except (TypeError, UnicodeDecodeError, binascii.Error): msg = _('Invalid basic header. Credentials not correctly base64 encoded.') raise exceptions.AuthenticationFailed(msg) userid, password = auth_parts[0], auth_parts[2] # 返回用户和密码 return self.authenticate_credentials(userid, password, request) def authenticate_credentials(self, userid, password, request=None): """ Authenticate the userid and password against username and password with optional request for context. """ credentials = &#123; get_user_model().USERNAME_FIELD: userid, 'password': password &#125; user = authenticate(request=request, **credentials) if user is None: raise exceptions.AuthenticationFailed(_('Invalid username/password.')) if not user.is_active: raise exceptions.AuthenticationFailed(_('User inactive or deleted.')) return (user, None) def authenticate_header(self, request): return 'Basic realm="%s"' % self.www_authenticate_realm g当然restfulframework默认定义了两个类。我们也可以自定制类， 自己有就用自己的了，自己没有就去找父类的了， 但是里面必须实现authenticate方法，不然会报错。 进行以下操作 处理版权信息 认证 权限 请求用户进行访问频率的限制 我们主要来看一下认证流程： a首先 self.initial(request, *args, **kwargs)可以看到做了以下操作 12345678910111213141516171819202122def initial(self, request, *args, **kwargs): """ Runs anything that needs to occur prior to calling the method handler. """ self.format_kwarg = self.get_format_suffix(**kwargs) # Perform content negotiation and store the accepted info on the request neg = self.perform_content_negotiation(request) request.accepted_renderer, request.accepted_media_type = neg # Determine the API version, if versioning is in use. #2.1 处理版本信息 version, scheme = self.determine_version(request, *args, **kwargs) request.version, request.versioning_scheme = version, scheme # Ensure that the incoming request is permitted #2.2 认证 self.perform_authentication(request) # 2.3 权限 self.check_permissions(request) # 2.4 请求用户进行访问频率的限制 self.check_throttles(request) b我们先来看认证，self.perform_authentication(request) 具体干了什么，按住ctrl点击进去 123456789def perform_authentication(self, request): """ Perform authentication on the incoming request. Note that if you override this and simply 'pass', then authentication will instead be performed lazily, the first time either `request.user` or `request.auth` is accessed. """ request.user #执行request的user，这是的request已经是加工后的request了 c那么我们可以从视图里面导入一下Request，找到request对象的user方法 1from rest_framework.views import Request 12345678910@property def user(self): """ Returns the user associated with the current request, as authenticated by the authentication classes provided to the request. """ if not hasattr(self, '_user'): with wrap_attributeerrors(): self._authenticate() # return self._user #返回user d执行self._authenticate() 开始用户认证， 如果验证成功后返回元组： (用户,用户Token) 123456789101112131415161718192021def _authenticate(self): """ Attempt to authenticate the request using each authentication instance in turn. """ #循环对象列表 for authenticator in self.authenticators: try: #执行每一个对象的authenticate 方法 user_auth_tuple = authenticator.authenticate(self) except exceptions.APIException: self._not_authenticated() raise if user_auth_tuple is not None: self._authenticator = authenticator self.user, self.auth = user_auth_tuple #返回一个元组，user，和auth，赋给了self, # 只要实例化Request，就会有一个request对象，就可以request.user,request.auth了 return self._not_authenticated() e在user_auth_tuple = authenticator.authenticate(self) 进行验证， 如果验证成功，执行类里的authenticatie方法 f如果用户没有认证成功：self._not_authenticated() 12345678910111213141516171819202122def _not_authenticated(self): """ Set authenticator, user &amp; authtoken representing an unauthenticated request. Defaults are None, AnonymousUser &amp; None. """ #如果跳过了所有认证，默认用户和Token和使用配置文件进行设置 self._authenticator = None # if api_settings.UNAUTHENTICATED_USER: self.user = api_settings.UNAUTHENTICATED_USER() # 默认值为：匿名用户AnonymousUser else: self.user = None # None 表示跳过该认证 if api_settings.UNAUTHENTICATED_TOKEN: self.auth = api_settings.UNAUTHENTICATED_TOKEN() # 默认值为：None else: self.auth = None # (user, token) # 表示验证通过并设置用户名和Token； # AuthenticationFailed异常 执行get/post/delete等方法对返回结果在进行加工]]></content>
      <categories>
        <category>restful framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django-Rest-Framework的分页]]></title>
    <url>%2F2017%2F11%2F23%2FDjango-Rest-Framework%E7%9A%84%E5%88%86%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[DRF的分页为什么要使用分页其实这个不说大家都知道，大家写项目的时候也是一定会用的， 我们数据库有几千万条数据，这些数据需要展示，我们不可能直接从数据库把数据全部读取出来， 这样会给内存造成特别大的压力，有可能还会内存溢出，所以我们希望一点一点的取， 那展示的时候也是一样的，总是要进行分页显示，我们之前自己都写过分页。 那么大家想一个问题，在数据量特别大的时候，我们的分页会越往后读取速度越慢， 当有一千万条数据，我要看最后一页的内容的时候，怎么能让我的查询速度变快。 DRF给我们提供了三种分页方式，我们看下他们都是什么样的 DRF提供的三种分页1from rest_framework.pagination import PageNumberPagination, LimitOffsetPagination, CursorPagination 全局配置 123REST_FRAMEWORK = &#123; 'PAGE_SIZE': 2&#125; 第一种PageNumberPagination 看第n页，每页显示n条数据http://127.0.0.1:8000/book?page=2&amp;size=1 自定义分页类12345class MyPageNumber(PageNumberPagination): page_size = 2 # 每页显示多少条 page_size_query_param = 'size' # URL中每页显示条数的参数 page_query_param = 'page' # URL中页码的参数 max_page_size = None # 最大页码数限制 视图123456789class BookView(APIView): def get(self, request): book_list = Book.objects.all() # 分页 page_obj = MyPageNumber() page_article = page_obj.paginate_queryset(queryset=book_list, request=request, view=self) ret = BookSerializer(page_article, many=True) return Response(ret.data) 返回带页码链接的响应1234567891011class BookView(APIView): def get(self, request): book_list = Book.objects.all() # 分页 page_obj = MyPageNumber() page_article = page_obj.paginate_queryset(queryset=book_list, request=request, view=self) ret = BookSerializer(page_article, many=True) # return Response(ret.data) # 返回带超链接 需返回的时候用内置的响应方法 return page_obj.get_paginated_response(ret.data) 第二中LimitOffsetPagination 在第n个位置 向后查看n条数据http://127.0.0.1:8000/book?offset=2&amp;limit=1 自定义的分页类12345class MyLimitOffset(LimitOffsetPagination): default_limit = 1 limit_query_param = 'limit' offset_query_param = 'offset' max_limit = 999 视图123456789101112# 只有用的分页类不同，其他都相同class BookView(APIView): def get(self, request): book_list = Book.objects.all() # 分页 page_obj = MyLimitOffset() page_article = page_obj.paginate_queryset(queryset=book_list, request=request, view=self) ret = BookSerializer(page_article, many=True) # return Response(ret.data) # 返回带超链接 需返回的时候用内置的响应方法 return page_obj.get_paginated_response(ret.data) 第三种CursorPagination 加密游标的分页 把上一页和下一页的id记住 自定义分页类1234class MyCursorPagination(CursorPagination): cursor_query_param = 'cursor' page_size = 1 ordering = '-id' 视图1234567891011class BookView(APIView): def get(self, request): book_list = Book.objects.all() # 分页 page_obj = MyCursorPagination() page_article = page_obj.paginate_queryset(queryset=book_list, request=request, view=self) ret = BookSerializer(page_article, many=True) # return Response(ret.data) # 返回带超链接 需返回的时候用内置的响应方法 return page_obj.get_paginated_response(ret.data) 总结pagination.py123456789101112131415161718192021222324from rest_framework import paginationclass MyPaginator(pagination.PageNumberPagination): # 每页限制数量 page_size = 2 # 参数 page_query_param = 'page_num' page_size_query_param = 'size' # 限制 max_page_size = 3class MyLimitOffset(pagination.LimitOffsetPagination): default_limit = 1 limit_query_param = 'limit' offset_query_param = 'offset' max_limit = 999class MyCursorPagination(pagination.CursorPagination): cursor_query_param = 'cursor' page_size = 1 ordering = '-id' view.py普通版12345678910111213class PageBookView(APIView): def get(self, request): queryset = models.Book.objects.all() # 先实例化分页器对象 # page_obj = MyPaginator() # page_obj = MyLimitOffset() page_obj = MyCursorPagination() # 用自己的分页器调用分页方法进行分页 page_data = page_obj.paginate_queryset(queryset, request) # 序列化分页好的数据 ser_obj = serializers.BookSerializer(page_data, many=True) # 给响应添加上一页下一页的链接 return page_obj.get_paginated_response(ser_obj.data) ModelViewSet版12345678from rest_framework import viewsetsclass BookModelView(viewsets.ModelViewSet): queryset = models.Book.objects.all() serializer_class = serializers.BookSerializer # pagination_class = MyPaginator # pagination_class = MyLimitOffset pagination_class = MyCursorPagination]]></content>
      <categories>
        <category>restful framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django-Rest-Framework的解析器和渲染器]]></title>
    <url>%2F2017%2F11%2F22%2FDjango-Rest-Framework%E7%9A%84%E8%A7%A3%E6%9E%90%E5%99%A8%E5%92%8C%E6%B8%B2%E6%9F%93%E5%99%A8%2F</url>
    <content type="text"><![CDATA[解析器解析器的作用就是服务端接收客户端传来的数据，把数据解析成自己想要的数据类型的过程 本质就是对请求体中的数据进行解析 Django的解析器我们请求进来的请求体中的数据在request.body中，那也证明，解析器会把解析好的数据放入request.body 我们在视图中可以打印request的类型，能够知道request是WSGIRequest这个类 看源码，我么怎么拿到request.POST数据的 application/x-www-form-urlencoded不是不能上传文件，是只能上传文本格式的文件， multipart/form-data是将文件以二进制的形式上传，这样可以实现多种类型的文件上传 一个解析到request.POST, request.FILES中。 也就是说我们之前能在request中能到的各种数据是因为用了不同格式的数据解析器~ 那么我们的DRF能够解析什么样的数据类型呢  DRF的解析器什么时候我们的解析器会被调用，是不是在request.data拿数据的时候 我们说请求数据都在request.data中，那我们看Request类中的data 得到解析器后，调用解析器的parse方法 到这里，DRF配置的默认的解析器的类都有哪些 也就是说，我们的DRF支持Json，Form表单的请求，包括多种文件类型的数据 可以在视图中配置视图级别的解析器 这就是DRF的解析器 渲染器渲染器就是友好的展示数据 DRF提供的渲染器有 在浏览器中展示的DRF测试的那个页面，就是通过浏览器的渲染来做到的 当然我们可以展示Json数据类型]]></content>
      <categories>
        <category>restful framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django-Rest-Framework的权限和频率]]></title>
    <url>%2F2017%2F11%2F21%2FDjango-Rest-Framework%E7%9A%84%E6%9D%83%E9%99%90%E5%92%8C%E9%A2%91%E7%8E%87%2F</url>
    <content type="text"><![CDATA[DRF的权限权限是什么权限到底是是干什么用的 比如，我们申请博客的时候，一定要向管理员申请，也就是说管理员会有一些特殊的权利，我们作为用户是没有的 这些对某些事情决策的范围和程度，我们叫做权限，权限是我们在项目开发中非常常用的 那么看DRF框架给我们提供的权限组件有哪些方法 权限组件源码我们之前有DRF的版本和认证，也就知道了权限和频率跟版本认证都是在initial方法里初始化的 其实我们版本，认证，权限，频率控制走的源码流程大致相同 我们的权限类一定要有has_permission方法，否则会抛出异常，这就是框架为我们提供的钩子 我们先看到在rest_framework.permissions这个文件红中，存放了框架为我们提供的所有权限的方法 这里主要说一下BasePermission这个我们写权限继承的一个基础权限类 权限的详细用法在这里我们一定要清楚一点，我们的python代码是一行一行执行的，那么执行intial方法初始化这些组件的时候 也就是顺序的，我们的版本在前面，然后是认证，然后是权限，最后是频率 我们的权限执行的时候，我们的认证已经执行结束了 前提是在model中的UserInfo表中加了一个字段，用户类型的字段，做好数据库迁移 第一步 写权限类1234567891011121314class MyPermission(BasePermission): message = "VIP用户才能访问" def has_permission(self, request, view): """ 自定义权限只有vip用户能访问， 注意我们初始化时候的顺序是认证在权限前面的，所以只要认证通过~ 我们这里就可以通过request.user,拿到我们用户信息 request.auth就能拿到用户对象 """ if request.user and request.auth.type == 2: return True else: return False 第二部 局部视图注册123456789class TestAuthView(APIView): authentication_classes = [MyAuth, ] permission_classes = [MyPermission, ] def get(self, request, *args, **kwargs): print(request.user) print(request.auth) username = request.user return Response(username) 第三步 全局注册 settings.py1234567891011121314REST_FRAMEWORK = &#123; # 默认使用的版本控制类 'DEFAULT_VERSIONING_CLASS': 'rest_framework.versioning.URLPathVersioning', # 允许的版本 'ALLOWED_VERSIONS': ['v1', 'v2'], # 版本使用的参数名称 'VERSION_PARAM': 'version', # 默认使用的版本 'DEFAULT_VERSION': 'v1', # 配置全局认证 # 'DEFAULT_AUTHENTICATION_CLASSES': ["BRQP.utils.MyAuth", ] # 配置全局权限 "DEFAULT_PERMISSION_CLASSES": ["BROP.utils.MyPermission"]&#125; DEF的频率频率限制是做什么的开放平台的API接口调用需要限制其频率，以节约服务器资源和避免恶意的频繁调用 那我们的DRF提供了一些什么样的频率限制的方法 频率组件源码版本，认证，权限，频率这几个组件的源码是一个流程 可以突破一下自己，这个自己看 频率组件原理DRF中的频率控制基本原理是基于访问次数和时间的，当然我们可以通过自己定义的方法来实现。 当我们请求进来时，走到我们的频率组件的时候，DRF内部会有一个字典来记录访问者的IP 以这个访问者的IP为key，value为一个列表，存放访问者每次访问的时间 {IP1: [第三次访问的时间， 第二次访问的时间， 第一次访问的时间]} 把每次访问最新时间放入到列表的最前面，记录这样一个数据结构，通过什么方式限流呢： 如果我们设置的时间是10秒内只能访问5次 1，判断访问者的IP是否在这个请求IP的字典里 2，保证这个列表里都是最近10秒内的访问的时间 判断当前请求时间和列表里最早的（也就是最后的）请求时间的查 如果差大于10秒，说明请求以及不是最近10秒内的，删除掉 继续判断倒数第二个值，知道差值小于10秒 3，判断列表的长度（即访问次数），是否大于我们设置的5次 如果大于就限流，否则放行，并把时间放入了列表的最前面 频率组件的详细用法频率组件的配置方式其实就是跟上面的组件都一样 第一步12345678910111213141516171819202122232425262728293031323334353637383940414243VISIT_RECORD = &#123;&#125;class MyThrottle(object): """ 一分钟访问五次（可以设置为配置信息） """ def __init__(self): self.history = None def allow_request(self, request, view): # 获取用户的ip地址 ip = request.META.get('REMOTE_ADDR', '') # self.key = self.get_catch_key() # self.cache.get(self.key, []) # 构建访问记录 if ip not in VISIT_RECORD: VISIT_RECORD[ip] = [time.time(), ] else: history = VISIT_RECORD[ip] print('history', history) self.history = history history.insert(0, time.time()) # 确保列表的时间是允许范围内的 try: while self.history[0] - self.history[-1] &gt; 10: print('self.history', self.history) history.clear() except IndexError as e: print(e) return True # 判断列表的长度 if not len(self.history) &lt;= 5: return False return True # 等待信息 # [最近时间， 最老时间] def wait(self): return 10 - (self.history[0] - self.history[-1]) 第二步123456REST_FRAMEWORK = &#123; # ...... # 频率限制的配置 "DEFAULT_THROTTLE_CLASSES": ["Throttle.throttle.MyThrottle"], &#125;&#125; 第三步12345678from rest_framework.throttling import SimpleRateThrottleclass MyVisitThrottle(SimpleRateThrottle): scope = "WD" def get_cache_key(self, request, view): return self.get_ident(request) 第四步123456789REST_FRAMEWORK = &#123; # 频率限制的配置 # "DEFAULT_THROTTLE_CLASSES": ["Throttle.throttle.MyVisitThrottle"], "DEFAULT_THROTTLE_CLASSES": ["Throttle.throttle.MyThrottle"], "DEFAULT_THROTTLE_RATES":&#123; 'WD':'5/m', #速率配置每分钟不能超过5次访问，WD是scope定义的值， &#125;&#125; 可以在postman或者DRF自带的页面进行测试]]></content>
      <categories>
        <category>restful framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django-Rest-Framework的版本和认证]]></title>
    <url>%2F2017%2F11%2F20%2FDjango-Rest-Framework%E7%9A%84%E7%89%88%E6%9C%AC%E5%92%8C%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[DRF的版本版本控制是做什么用的，我们为什么要用首先要知道版本是干嘛用的，我们知道开发项目的时候有多个版本 当项目一直更新，版本就越来越多，以前的旧版本就不维护了 那这时，就需要对版本进行控制，这个DRF也给我们提供了一些封装好的版本控制方法 版本控制怎么用之前视图篇介绍了APIView，也只带APIView返回View中的view函数然后调用的dispach方法 那看一下dispatch方法，看下它都做了些什么 执行self.initial方法之前是各种赋值，包括request的重新封装，下面是路由分发，那我们看这个方法辽做了什么。 可以看到，version版本信息赋值给了request.version 版本控制方案赋值给了request.versioning_scheme 这个版本控制方案就是配置的版本控制的类 也就是说，APIView通过这个方法初始化自己提供的组件 接下来看一下框架提供了那些版本的控制方法 ---- 在rest_framework.versioning 框架一共给我们提供了这几个版本的控制方法，这里只给出一个，其他配置相同 详细用法第一步 settings.py12345678910REST_FRAMEWORK = &#123; # 默认使用的版本控制类 'DEFAULT_VERSIONING_CLASS': 'rest_framework.versioning.URLPathVersioning', # 允许的版本 'ALLOWED_VERSIONS': ['v1', 'v2'], # 版本使用的参数名称 'VERSION_PARAM': 'version', # 默认使用的版本 'DEFAULT_VERSION': 'v1',&#125; 第二步 urls.py1234urlpatterns = [ url(r"^versions", MyView.as_view()), url(r"^(?P&lt;version&gt;[v1|v2]+)/test01", TestView.as_view()),] 测试视图12345678910class TestView(APIView): def get(self, request, *args, **kwargs): print(request.versioning_scheme) ret = request.version if ret == "v1": return Response("版本v1的信息") elif ret == "v2": return Response("版本v2的信息") else: return Response("根本就匹配不到这个路由") 其他版本控制的类，配置方法差不多都一样 DRF的认证认证是干什么用的我们都知道，我们可以在网站上登录，然后可以有个人中心，对自己信息进行修改 但是我们每次给服务器发请求，由于Http的无状态，导致我们每次都是新的请求 那么服务端需要对每次来的请求进行认证，看用户是否登录，以及登录用户是谁 那么我们服务器对每个请求进行认证的时候，不可能在每个视图函数中都写认证 一定是把认证逻辑抽离出来，以前我们可能会加装饰器，或者中间件，来看看DRF框架提供了什么 认证怎么用上面版本控制的时候我们可以知道，在dispatch 方法里，执行了initial方法，那初始化了我们的版本 如果认证读的话，可以看到，版本的下面就是我们的认证，权限，频率组件。 认证组件 我们进去认证看 我们这个权限组件返回的是request.user，那么我们这里的request是新的还是旧的呢 我们的initial是我们request重新赋值之后的，所所以这里的request是新的，也就是Request类实例对象 那这个user一定是一个静态方法，进去一探究竟 这里没有给出反复的跳转截图，自行仔细跳转 通过上面基本可以知道，我们的认证类一定要实现的方法，以及返回值类型， 以及配置的参数authentication_classes 请看具体用法 认证的详细用法写一个认证demo，先建一张用户表，字段为为用户名以及对应的token值 models.py1234567# 先在model中注册模型类# 并且进行数据迁移# 测试我就简写了~class UserInfo(models.Model): username = models.CharField(max_length=32) token = models.UUIDField() views.py1234567# 写视图类并且用post请求注册一个用户class UserView(APIView): def post(self, request, *args, **kwargs): username = request.data["username"] UserInfo.objects.create(username=username, token=uuid.uuid4()) return Response("注册成功") 认证开始写一个认证的类1234567891011# 注意我们这个认证的类必须实现的方法以及返回值class MyAuth(BaseAuthentication): def authenticate(self, request): request_token = request.query_params.get("token", None) if not request_token: raise AuthenticationFailed(&#123;"code": 1001, "error": "缺少token"&#125;) token_obj = UserInfo.objects.filter(token=request_token).first() if not token_obj: raise AuthenticationFailed(&#123;"code": 1001, "error": "无效的token"&#125;) return token_obj.username, token_obj 视图级别认证12345class TestAuthView(APIView): authentication_classes = [MyAuth, ] def get(self, request, *args, **kwargs): return Response("测试认证") 全局配置认证123456789101112REST_FRAMEWORK = &#123; # 默认使用的版本控制类 'DEFAULT_VERSIONING_CLASS': 'rest_framework.versioning.URLPathVersioning', # 允许的版本 'ALLOWED_VERSIONS': ['v1', 'v2'], # 版本使用的参数名称 'VERSION_PARAM': 'version', # 默认使用的版本 'DEFAULT_VERSION': 'v1', # 配置全局认证 'DEFAULT_AUTHENTICATION_CLASSES': ["BRQP.utils.MyAuth", ]&#125;]]></content>
      <categories>
        <category>restful framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django-Rest-Framework代码记录]]></title>
    <url>%2F2017%2F11%2F19%2FDjangoRestFramework%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[主要文件代码[TOC] 表结构设计1234567891011121314151617181920212223242526272829303132# models.py 文件from django.db import modelsBOOK_CATEGORIES = ((1, 'Python'), (2, 'Linux'), (3, 'Go'))__all__ = ['Book', 'Author', 'Publisher']class Book(models.Model): title = models.CharField(max_length=32) category = models.IntegerField(choices=BOOK_CATEGORIES) pub_date = models.DateField() authors = models.ManyToManyField(to='Author') publisher = models.ForeignKey(to='Publisher', on_delete=models.CASCADE) def __str__(self): return self.titleclass Author(models.Model): name = models.CharField(max_length=32) def __str__(self): return self.nameclass Publisher(models.Model): title = models.CharField(max_length=32) address = models.CharField(max_length=32) def __str__(self): return self.title 自定义Serializer方式一：继承serializers.Serializer 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293# serializers.pyfrom rest_framework import serializersfrom appone.models import Bookclass PublisherSerializer(serializers.Serializer): id = serializers.IntegerField() title = serializers.CharField(max_length=32)class AuthorSerializer(serializers.Serializer): id = serializers.IntegerField() name = serializers.CharField(max_length=32)SENSITIVE_WORDS = ['极品', '最美', '之王', '之最']def my_validator(value): """ 自定义过滤器，可以传到字段的validators参数中 :param value: :return: """ if value in SENSITIVE_WORDS: raise serializers.ValidationError("含有敏感词汇")class BookSerializer(serializers.Serializer): id = serializers.IntegerField(required=False) # required为False时，反序列化不做校验 title = serializers.CharField(max_length=32, validators=[my_validator,]) pub_date = serializers.DateField() category = serializers.CharField(source="get_category_display", read_only=True) post_category = serializers.IntegerField(write_only=True) # 序列化不做校验，反序列化做校验 # 内部通过外键关系的Id拿到publisher_obj，然后把publisher_obj传入PublisherSerializer序列化器进行序列化 publisher = PublisherSerializer(read_only=True) authors = AuthorSerializer(many=True, read_only=True) publisher_id = serializers.IntegerField(write_only=True) # 反序列化时使用，前端传数据时以此名称作为建 author_list = serializers.ListField(write_only=True) # 反序列化时使用 def create(self, validated_data): book_obj = Book.objects.create( title=validated_data['title'], pub_date=validated_data['pub_date'], category=validated_data['post_category'], publisher_id=validated_data['publisher_id'] ) book_obj.authors.add(*validated_data['author_list']) return book_obj def update(self, instance, validated_data): instance.title = validated_data.get('title', instance.title) instance.pub_date = validated_data.get('pub_date', instance.pub_date) instance.category = validated_data.get('post_category', instance.category) instance.publisher_id = validated_data.get('publisher_id', instance.publisher_id) if validated_data.get('author_list'): instance.authors.set(validated_data['author_list']) instance.save() return instance def validate_title(self, value): """ 相当于局部钩子 :param value: 具体字段的值 :return: """ for word in SENSITIVE_WORDS: if word in value: raise serializers.ValidationError('标题含有敏感词汇') return value def validate(self, attrs): """ 相当于全局钩子 :param attrs: 所有字段组成的字典 :return: """ print("attrs:", attrs) return attrs"""继承serializers.Serializer自定义的Serializer中，必须定义create和update方法；当前端提交数据时，会在自定义的Serializer中查找create方法，当前端更新数据时，会在自定义的Serializer中查找update方法。添加新书时，前端传输数据示例：# 字段名称根据你创建的Serializer类中，为有外键关系字段定义的用于反序列化的具体名称决定&#123; "title": "自然语言处理", "pub_date": "2017-05-20", "post_category": 1, "publisher_id": 2, "author_list": [1, 2] &#125;""" 方式二：继承serializers.ModelSerializer 1234567891011121314151617181920212223242526272829303132333435363738394041class BookSerializer(serializers.ModelSerializer): # 有外键关系的字段和choices等一些特殊的字段，需要自定义展示效果；此处自定义的字段，在本类中必须有名称"get_字段"的钩子函数与其对应 # 注意：自定义的名字不要与原表中的字段名冲突 publisher_name = serializers.SerializerMethodField(read_only=True) authors_info = serializers.SerializerMethodField(read_only=True) category_name = serializers.SerializerMethodField(read_only=True) # 这是个钩子函数，会自动触发，此方法的返回值会赋值给上方的publisher_name def get_publisher_name(self, obj): return obj.publisher.title def get_authors_info(self, obj): author_queryset = obj.authors.all() return [&#123;'id': author.id, 'name': author.name&#125; for author in author_queryset] def get_category_name(self, obj): return obj.get_category_display() class Meta: model = Book fields = '__all__' # depth = 1 # 有外键关系的向下查找深度 extra_kwargs = &#123; "publisher": &#123;"write_only": True&#125;, "authors": &#123;"write_only": True&#125;, "category": &#123;"write_only": True&#125; &#125;"""继承serializers.ModelSerializer自定义的Serializer中，不用自定义create和update方法read_only=True 只在序列化时（后端传数据给前端浏览器用于展示），对字段进行校验write_only=True 只在反序列化时(后端拿到前端传过来的数据)，对字段进行校验添加新书时，前端传输数据示例：&#123; "publisher": 1, "authors": [1], "category": "1", "title": "Python袖珍指南", "pub_date": "2015-08-25" &#125;""" 路由文件项目的路由 12345678from django.conf.urls import url, includefrom django.contrib import adminurlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^api/', include("appone.urls")), url(r'^rest/', include("apprest.urls"))] 应用的路由 12345678# urls.pyfrom django.conf.urls import urlfrom .views import BookView, BookEditViewurlpatterns = [ url(r'^book$', BookView.as_view()), url(r'^book/(?P&lt;id&gt;\d+)', BookEditView.as_view()),] 视图函数文件1234567891011121314151617181920212223242526272829303132333435363738# views.pyfrom rest_framework.views import APIViewfrom rest_framework.response import Responsefrom appone.models import Bookfrom .serializers import BookSerializerclass BookView(APIView): def get(self, request): book_queryset = Book.objects.all() ser_obj = BookSerializer(book_queryset, many=True) # 如果传给BookSerializer的第一个参数只是一个对象，many=True可以省略 # print(request.query_params) # &lt;QueryDict: &#123;'format': ['api'], 'name': ['jason']&#125;&gt; return Response(ser_obj.data) def post(self, request): book_data = request.data ser_obj = BookSerializer(data=book_data) if ser_obj.is_valid(): ser_obj.save() return Response(ser_obj.validated_data) return Response(ser_obj.errors) # 前端提交过来数据校验未通过，返回错误信息给前端class BookEditView(APIView): def get(self, request, id): book_obj = Book.objects.filter(id=id).first() ser_obj = BookSerializer(book_obj) return Response(ser_obj.data) def put(self, request, id): book_obj = Book.objects.filter(id=id).first() ser_obj = BookSerializer(instance=book_obj, data=request.data, partial=True) # partial=True表示允许校验部分字段，因为更改图书对象时，可能只是更改一个或几个字段；如果不设置partial=True，那么前端传过来的数据必须包含所有必须的字段，即字段要完整 if ser_obj.is_valid(): print(ser_obj.validated_data) ser_obj.save() return Response(ser_obj.validated_data) return Response(ser_obj.errors)]]></content>
      <categories>
        <category>restful framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django-Rest-Framework的视图和路由]]></title>
    <url>%2F2017%2F11%2F18%2FDRF_view_router%2F</url>
    <content type="text"><![CDATA[Django-Rest-Framework的视图APIViewdjango中写CBV的时候继承的是View，rest_framework继承的是APIView，那么他们两个有什么不同呢 urlpatterns = [ url(r&apos;^book$&apos;, BookView.as_view()), url(r&apos;^book/(?P&lt;id&gt;\d+)$&apos;, BookEditView.as_view()), ] 可以看到，不管是View还是APIView最开始调用的都是as_view()方法，那走进源码看看 我们能看到，APIView继承了View, 并且执行了View中的as_view()方法，最后把view返回了，用csrf_exempt()方法包裹后去掉了csrf的认证。 那我们看看View中的as_view()方法做了什么 我们看到了~在View中的as_view方法返回了view函数，而view函数执行了self.dispatch()方法~~但是这里的dispatch方法应该是我们APIView中的 我们去initialize_request中看下把什么赋值给了request，并且赋值给了self.request, 也就是我们在视图中用的request.xxx到底是什么 我们看到，这个方法返回的是Request这个类的实例对象 我们注意我们看下这个Request类中的第一个参数request，是我们走我们django的时候的原来的request~ 我们看到了，这个Request类把原来的request赋值给了self._request, 也就是说以后_request是我们老的request，新的request是我们这个Request类 那我们继承APIView之后请求来的数据都在哪呢~~ 我们用了rest_framework框架以后，我们的request是重新封装的Request类~ request.query_params 存放的是我们get请求的参数 request.data 存放的是我们所有的数据，包括post请求的以及put，patch请求 相比原来的django的request，我们现在的request更加精简，清晰了~~~ 现在我们知道了APIView和View的一些区别~~当然还有~~后面还会说~~ 我们写的视图可能对多个表进行增删改查，就导致我们的视图特别多重复的代码~~ 那么我们尝试着来进行封装一下~~ 第一次封装APIView视图class BookView(APIView): def get(self, request): query_set = Book.objects.all() book_ser = BookSerializer(query_set, many=True) return Response(book_ser.data) def post(self, request): query_set = request.data book_ser = BookSerializer(data=query_set) if book_ser.is_valid(): book_ser.save() return Response(book_ser.validated_data) else: return Response(book_ser.errors) class BookEditView(APIView): def get(self, request, id): query_set = Book.objects.filter(id=id).first() book_ser = BookSerializer(query_set) return Response(book_ser.data) def patch(self, request, id): query_set = Book.objects.filter(id=id).first() book_ser = BookSerializer(query_set, data=request.data, partial=True) if book_ser.is_valid(): book_ser.save() return Response(book_ser.validated_data) else: return Response(book_ser.errors) def delete(self, request, id): query_set = Book.objects.filter(id=id).first() if query_set: query_set.delete() return Response(&quot;&quot;) else: return Response(&quot;删除的书籍不存在&quot;) 第一次封装class GenericAPIView(APIView): queryset = None serializer_class = None def get_queryset(self): return self.queryset.all() def get_serializer(self, *args, **kwargs): return self.serializer_class(*args, **kwargs) class ListModelMixin(object): def list(self, request, *args, **kwargs): queryset = self.get_queryset() serializer = self.get_serializer(queryset, many=True) return Response(serializer.data) class CreateModelMixin(object): def create(self, request, *args, **kwargs): serializer = self.get_serializer(data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.validated_data) else: return Response(serializer.errors) class RetrieveModelMixin(object): def retrieve(self, request, id, *args, **kwargs): book_obj = self.get_queryset().filter(pk=id).first() book_ser = self.get_serializer(book_obj) return Response(book_ser.data) class UpdateModelMixin(object): def update(self, request, id, *args, **kwargs): book_obj = self.get_queryset().filter(pk=id).first() book_ser = self.get_serializer(book_obj, data=request.data, partial=True) if book_ser.is_valid(): book_ser.save() return Response(book_ser.validated_data) else: return Response(book_ser.errors) class DestroyModelMixin(object): def destroy(self, request, id, *args, **kwargs): queryset = self.get_queryset() try: queryset.get(pk=id).delete() return Response(&quot;&quot;) except Exception as e: return Response(&quot;信息有误&quot;) # 我们把公共的部分抽出来 这样不管写多少表的增删改查都变的很简单 # 这样封装后我们的视图会变成这样 class BookView(GenericAPIView, ListModelMixin, CreateModelMixin): queryset = Book.objects.all() serializer_class = BookSerializer def get(self, request, *args, **kwargs): return self.list(request, *args, **kwargs) def post(self, request, *args, **kwargs): return self.create(request, *args, **kwargs) class BookEditView(GenericAPIView, RetrieveModelMixin, UpdateModelMixin, DestroyModelMixin): queryset = Book.objects.all() serializer_class = BookSerializer def get(self, request, id, *args, **kwargs): return self.retrieve(request, id, *args, **kwargs) def patch(self, request, id, *args, **kwargs): return self.update(request, id, *args, **kwargs) def destroy(self, request, id, *args, **kwargs): return self.delete(request, id, *args, **kwargs) 我们封装的GenericAPIView，包括封装每个方法的类，其实框架都帮我们封装好了~~ 我们可以直接继承这些类来实现上面的视图可是还有没有更简单的方法呢~我们再次封装一下~~ 第二次封装# 上面我们写的继承类太长了~~我们再改改 class ListCreateAPIView(GenericAPIView, ListModelMixin, CreateModelMixin): pass class RetrieveUpdateDestroyAPIView(GenericAPIView, RetrieveModelMixin, UpdateModelMixin, DestroyModelMixin): pass class BookView(ListCreateAPIView): queryset = Book.objects.all() serializer_class = BookSerializer def get(self, request, *args, **kwargs): return self.list(request, *args, **kwargs) def post(self, request, *args, **kwargs): return self.create(request, *args, **kwargs) class BookEditView(RetrieveUpdateDestroyAPIView): queryset = Book.objects.all() serializer_class = BookSerializer def get(self, request, id, *args, **kwargs): return self.retrieve(request, id, *args, **kwargs) def patch(self, request, id, *args, **kwargs): return self.update(request, id, *args, **kwargs) def delete(self, request, id, *args, **kwargs): return self.delete(request, id, *args, **kwargs) 这次我们只是让继承变的简单了一点而已，好像并没有什么大的进步我们可不可以把这两个视图合并成一个视图呢~~~框架给我们提供了一个路由传参的方法 我们看下ViewSetMixin action这个默认参数其实就是我们路由可以进行传参了 下面这个循环~可以看出~我们要传的参数是一个字段~key应该是我们的请求方式，value应该对应我们处理的方法~ 这样我们每个视图就不用在写函数了~因为已经和内部实现的函数相对应了~ 第三次封装路由 urls.pyurlpatterns = [ # url(r&apos;^book$&apos;, BookView.as_view()), # url(r&apos;^book/(?P&lt;id&gt;\d+)$&apos;, BookEditView.as_view()), url(r&apos;^book$&apos;, BookView.as_view({&quot;get&quot;: &quot;list&quot;, &quot;post&quot;: &quot;create&quot;})), url(r&apos;^book/(?P&lt;pk&gt;\d+)$&apos;, BookView.as_view({&quot;get&quot;: &quot;retrieve&quot;, &quot;patch&quot;: &quot;update&quot;, &quot;delete&quot;: &quot;destroy&quot;})), ] 第三次封装from rest_framework.viewsets import ViewSetMixin # class BookView(ViewSetMixin, ListCreateAPIView, RetrieveUpdateDestroyAPIView): # queryset = Book.objects.all() # serializer_class = BookSerializer # 如果我们再定义一个类 class ModelViewSet(ViewSetMixin, ListCreateAPIView, RetrieveUpdateDestroyAPIView): pass class BookView(ModelViewSet): queryset = Book.objects.all() serializer_class = BookSerializer 我们现在的视图就只要写两行就可以了 其实我们写的所有的视图~框架都帮我们封装好了 注意一点~用框架封装的视图~我们url上的那个关键字参数要用pk~系统默认的 奉献一张图来看下我们的继承顺序 Django-Rest-Framework的路由我们上面的路由传参写的特别多~~框架也帮我们封装好了~ from .views import BookView from rest_framework.routers import DefaultRouter router = DefaultRouter() router.register(r&quot;book&quot;, BookView) urlpatterns = [ # url(r&apos;^book$&apos;, BookView.as_view()), # url(r&apos;^book/(?P&lt;id&gt;\d+)$&apos;, BookEditView.as_view()), # url(r&apos;^book$&apos;, BookView.as_view({&quot;get&quot;: &quot;list&quot;, &quot;post&quot;: &quot;create&quot;})), # url(r&apos;^book/(?P&lt;pk&gt;\d+)$&apos;, BookView.as_view({&quot;get&quot;: &quot;retrieve&quot;, &quot;patch&quot;: &quot;update&quot;, &quot;delete&quot;: &quot;destroy&quot;})), ] urlpatterns += router.urls 我们可以看到通过框架我们可以把路由视图都变的非常简单~~ 但是需要自定制的时候还是需要我们自己用APIView写，当不需要那么多路由的时候，也不要用这种路由注册~~ 总之一切按照业务需要去用~~~ 总结urls.py12345678910111213141516171819202122232425from serdemo import viewsfrom rest_framework.routers import DefaultRouterrouter = DefaultRouter()router.register(r'book', views.BookModelView)urlpatterns = [ # 第一次 # url(r'^book/$', views.BookView.as_view()), # url(r'^book/(?P&lt;id&gt;\d+)', views.BookEditView.as_view()), # 第二次 # url(r'^book/$', views.BookView.as_view()), # url(r'^book/(?P&lt;id&gt;\d+)', views.BookEditView.as_view()), # 第三次 # url(r'^book/$', views.BookModelView.as_view(&#123;"get": "list", "post": "create"&#125;)), # url(r'^book/(?P&lt;id&gt;\d+)', views.BookModelView.as_view(&#123;"get": "retrieve", "put": "update", "delete": "destroy"&#125;)), # url(r'book_page$', views.PageBookView.as_view())]# 第三次urlpatterns += router.urls views.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149from demo import modelsfrom rest_framework.views import APIViewfrom rest_framework.response import Responsefrom serdemo import serializersfrom rest_framework.viewsets import ViewSetMixinfrom rest_framework import views # APIViewfrom rest_framework import viewsetsfrom rest_framework import genericsfrom rest_framework import mixinsfrom .pagination import MyPaginator, MyCursorPagination, MyLimitOffset# queryset不同 序列化器不同# def get:pass# def post:passclass GenericAPIView(APIView): queryset = None serializer_class = None def get_queryset(self): return self.queryset.all() def get_serializer(self, *args, **kwargs): return self.serializer_class(*args, **kwargs)class ListModelMixin(object): def list(self, request): queryset = self.get_queryset() ser_obj = self.get_serializer(queryset, many=True) return Response(ser_obj.data)class CreateModelMixin(object): def create(self, request): ser_obj = self.get_serializer(data=request.data) if ser_obj.is_valid(): ser_obj.save() return Response(ser_obj.data) return Response(ser_obj.errors)class RetrieveModelMixin(object): def retrieve(self, request, id): book_obj = self.get_queryset().filter(id=id).first() ser_obj = serializers.BookSerializer(book_obj) return Response(ser_obj.data)class UpdateModelMixin(object): def update(self, request, id): book_obj = self.get_queryset().filter(id=id).first() ser_obj = self.get_serializer(instance=book_obj, data=request.data, partial=True) if ser_obj.is_valid(): ser_obj.save() return Response(ser_obj.data) return Response(ser_obj.errors)class DestroyModelMixin(object): def destroy(self, request, id): book_obj = self.get_queryset().filter(id=id).first() if not book_obj: return Response("删除的对象不存在") book_obj.delete() return Response("")class ListCreateAPIView(GenericAPIView, ListModelMixin, CreateModelMixin): passclass RetrieveUpdateDestroyAPIView(GenericAPIView, RetrieveModelMixin, UpdateModelMixin, DestroyModelMixin): passclass ModelViewSet(ViewSetMixin, ListModelMixin, RetrieveUpdateDestroyAPIView): pass# get post# 封装一# class BookView(GenericAPIView, ListModelMixin, CreateModelMixin):# queryset = models.Book.objects.all()# serializer_class = serializers.BookSerializer## def get(self, request):# return self.list(request)## def post(self, request):# return self.create(request)# get put delete# 封装一# class BookEditView(GenericAPIView, RetrieveModelMixin, UpdateModelMixin, DestroyModelMixin):# queryset = models.Book.objects.all()# serializer_class = serializers.BookSerializer## def get(self, request, id):# return self.retrieve(request, id)## def put(self, request, id):# return self.update(request, id)## def delete(self, request, id):# return self.destroy(request, id)# # 分装二# class BookView(ListCreateAPIView):# queryset = models.Book.objects.all()# serializer_class = serializers.BookSerializer## def get(self, request):# return self.list(request)## def post(self, request):# return self.create(request)### # 封装二# class BookEditView(RetrieveUpdateDestroyAPIView):# queryset = models.Book.objects.all()# serializer_class = serializers.BookSerializer## def get(self, request, id):# return self.retrieve(request, id)## def put(self, request, id):# return self.update(request, id)## def delete(self, request, id):# return self.destroy(request, id)# 分装三 BookModelViewclass BookModelView(viewsets.ModelViewSet): # 只需要在路由中指定字典就可以 queryset = models.Book.objects.all() serializer_class = serializers.BookSerializer # 分页一 pagination_class = MyPaginator # 分页二 # pagination_class = MyLimitOffset # 分页三 # pagination_class = MyCursorPagination serializers.py123456789101112131415161718192021222324252627282930313233343536373839404142434445class BookSerializer(serializers.ModelSerializer): # 重写正序 category_info = serializers.SerializerMethodField(read_only=True) publisher_info = serializers.SerializerMethodField(read_only=True) authors_info = serializers.SerializerMethodField(read_only=True) def get_category_info(self, obj): # obj 就是序列化的每一个Book对象 return obj.get_category_display() def get_publisher_info(self, obj): # obj 就是序列化的每一个Book对象 publisher_obj = obj.publisher return &#123;"id": publisher_obj.pk, "title": publisher_obj.title&#125; def get_authors_info(self, obj): # obj 就是序列化的每一个Book对象 author_qureryset = obj.authors.all() return [&#123;"id": author_obj.pk, "name": author_obj.name&#125; for author_obj in author_qureryset] class Meta: model = models.Book fields = "__all__" # exclude=["id"] # 会让所有的外键关系变成只读read_only=True # depth = 1 # 向下找几层 # 反序列化的时候不用自己定义的，而是还是用原来的字段 extra_kwargs = &#123;"title": &#123;"validators": [my_validate]&#125;, "publisher": &#123;"write_only": True&#125;, "authors": &#123;"write_only": True&#125;, "category": &#123;"write_only": True&#125;&#125; # 验证 # 局部钩子校验 单个字段 def validate_title(self, value): # value 就是title 的值 对value处理 if "python" not in value.lower(): raise serializers.ValidationError('标题必须包含python') return value # 全局钩子校验 全部字段 def validate(self, attrs): # attr 字典有你传过来的所有的字段 if "python1" in attrs["title"].lower(): return attrs else: raise serializers.ValidationError("分类或标题不合符要求")]]></content>
      <categories>
        <category>restful framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django-Rest-Framework的序列化]]></title>
    <url>%2F2017%2F11%2F16%2FDjango-Rest-Framework%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96%2F</url>
    <content type="text"><![CDATA[可以直接看总结 正常的序列化from django.http import HttpResponse, JsonResponse from django.views import View from demo import models import json from django.core import serializers class BookView(View): def get(self, request): book_queryset = models.Book.objects.all().values(&quot;id&quot;, &apos;title&apos;) book_list = list(book_queryset) # 方式一 # ret = json.dumps(book_list, ensure_ascii=False) # return HttpResponse(ret) # 方式二 Django的序列化 # book_list_obj = models.Book.objects.all() # ret = serializers.serialize(&apos;json&apos;, book_list_obj, ensure_ascii=False) # return HttpResponse(ret) # 方式三 return JsonResponse(book_list, safe=False, json_dumps_params={&quot;ensure_ascii&quot;: False}) 为什么要用序列化组件当我们做前后端分离的项目~~我们前后端交互一般都选择JSON数据格式，JSON是一个轻量级的数据交互格式。 那么我们给前端数据的时候都要转成json格式，那就需要对我们从数据库拿到的数据进行序列化。 接下来我们看下django序列化和rest_framework序列化的对比~~ Django的序列化方法.values序列化结果 class BooksView(View): def get(self, request): book_list = Book.objects.values(&quot;id&quot;, &quot;title&quot;, &quot;chapter&quot;, &quot;pub_time&quot;, &quot;publisher&quot;) book_list = list(book_list) # 如果我们需要取外键关联的字段信息 需要循环获取外键 再去数据库查然后拼接成我们想要的 ret = [] for book in book_list: pub_dict = {} pub_obj = Publish.objects.filter(pk=book[&quot;publisher&quot;]).first() pub_dict[&quot;id&quot;] = pub_obj.pk pub_dict[&quot;title&quot;] = pub_obj.title book[&quot;publisher&quot;] = pub_dict ret.append(book) ret = json.dumps(book_list, ensure_ascii=False, cls=MyJson) return HttpResponse(ret) # json.JSONEncoder.default() # 解决json不能序列化时间字段的问题 class MyJson(json.JSONEncoder): def default(self, field): if isinstance(field, datetime.datetime): return field.strftime(&apos;%Y-%m-%d %H:%M:%S&apos;) elif isinstance(field, datetime.date): return field.strftime(&apos;%Y-%m-%d&apos;) else: return json.JSONEncoder.default(self, field) django serializers from django.core import serializers # 能够得到我们要的效果 结构有点复杂 class BooksView(View): def get(self, request): book_list = Book.objects.all() ret = serializers.serialize(&quot;json&quot;, book_list) return HttpResponse(ret) DRF序列化的方法首先，我们要用DRF的序列化，就要遵循人家框架的一些标准， – Django我们CBV继承类是View，现在DRF我们要用APIView – Django中返回的时候我们用HTTPResponse，JsonResponse，render ，DRF我们用Response 序列化第一步 声明序列化类class BookSerializer(serializers.Serializer): id = serializers.IntegerField() title = serializers.CharField(max_length=32) CHOICES = ((1, &quot;Linux&quot;), (2, &quot;Django&quot;), (3, &quot;Python&quot;)) chapter = serializers.ChoiceField(choices=CHOICES, source=&quot;get_chapter_display&quot;) pub_time = serializers.DateField() 第二步 序列化对象from rest_framework.views import APIView from rest_framework.response import Response class BookView(APIView): def get(self, request): book_list = Book.objects.all() ret = BookSerializer(book_list, many=True) return Response(ret.data) 外键关系的序列化from rest_framework import serializers from .models import Book class PublisherSerializer(serializers.Serializer): id = serializers.IntegerField(read_only=True) title = serializers.CharField(max_length=32) class UserSerializer(serializers.Serializer): id = serializers.IntegerField(read_only=True) name = serializers.CharField(max_length=32) age = serializers.IntegerField() class BookSerializer(serializers.Serializer): id = serializers.IntegerField(read_only=True) title = serializers.CharField(max_length=32) CHOICES = ((1, &quot;Linux&quot;), (2, &quot;Django&quot;), (3, &quot;Python&quot;)) chapter = serializers.ChoiceField(choices=CHOICES, source=&quot;get_chapter_display&quot;, read_only=True) pub_time = serializers.DateField() publisher = PublisherSerializer(read_only=True) user = UserSerializer(many=True, read_only=True) 反序列化当前端给我们发post的请求的时候~前端给我们传过来的数据~我们要进行一些校验然后保存到数据库~ 这些校验以及保存工作，DRF的Serializer也给我们提供了一些方法了~~ 首先~我们要写反序列化用的一些字段~有些字段要跟序列化区分开~~ Serializer提供了.is_valid() 和.save()方法~~ .save()反序列化 serializer.py class BookSerializer(serializers.Serializer): id = serializers.IntegerField(read_only=True) title = serializers.CharField(max_length=32) CHOICES = ((1, &quot;Linux&quot;), (2, &quot;Django&quot;), (3, &quot;Python&quot;)) chapter = serializers.ChoiceField(choices=CHOICES, source=&quot;get_chapter_display&quot;, read_only=True) w_chapter = serializers.IntegerField(write_only=True) pub_time = serializers.DateField() publisher = PublisherSerializer(read_only=True) user = UserSerializer(many=True, read_only=True) users = serializers.ListField(write_only=True) publisher_id = serializers.IntegerField(write_only=True) def create(self, validated_data): book = Book.objects.create(title=validated_data[&quot;title&quot;], chapter=validated_data[&quot;w_chapter&quot;], pub_time=validated_data[&quot;pub_time&quot;], publisher_id=validated_data[&quot;publisher_id&quot;]) book.user.add(*validated_data[&quot;users&quot;]) return book 序列化 views.py class BookView(APIView): def get(self, request): book_list = Book.objects.all() ret = BookSerializer(book_list, many=True) return Response(ret.data) def post(self, request): # book_obj = request.data print(request.data) serializer = BookSerializer(data=request.data) if serializer.is_valid(): print(12341253) serializer.save() return Response(serializer.validated_data) else: return Response(serializer.errors) 当前端给我们发送patch请求的时候，前端传给我们用户要更新的数据，我们要对数据进行部分验证~~ .is_valid()PATCH请求serializers.py class BookSerializer(serializers.Serializer): id = serializers.IntegerField(read_only=True) title = serializers.CharField(max_length=32) CHOICES = ((1, &quot;Linux&quot;), (2, &quot;Django&quot;), (3, &quot;Python&quot;)) chapter = serializers.ChoiceField(choices=CHOICES, source=&quot;get_chapter_display&quot;, read_only=True) w_chapter = serializers.IntegerField(write_only=True) pub_time = serializers.DateField() publisher = PublisherSerializer(read_only=True) user = UserSerializer(many=True, read_only=True) users = serializers.ListField(write_only=True) publisher_id = serializers.IntegerField(write_only=True) def create(self, validated_data): book = Book.objects.create(title=validated_data[&quot;title&quot;], chapter=validated_data[&quot;w_chapter&quot;], pub_time=validated_data[&quot;pub_time&quot;], publisher_id=validated_data[&quot;publisher_id&quot;]) book.user.add(*validated_data[&quot;users&quot;]) return book def update(self, instance, validated_data): instance.title = validated_data.get(&quot;title&quot;, instance.title) instance.chapter = validated_data.get(&quot;w_chapter&quot;, instance.chapter) instance.pub_time = validated_data.get(&quot;pub_time&quot;, instance.pub_time) instance.publisher_id = validated_data.get(&quot;publisher_id&quot;, instance.publisher_id) if validated_data.get(&quot;users&quot;): instance.user.set(validated_data.get(&quot;users&quot;)) instance.save() return instance PATCH请求views.py class BookView(APIView): def patch(self, request): print(request.data) book_id = request.data[&quot;id&quot;] book_info = request.data[&quot;book_info&quot;] book_obj = Book.objects.filter(pk=book_id).first() serializer = BookSerializer(book_obj, data=book_info, partial=True) if serializer.is_valid(): serializer.save() return Response(serializer.validated_data) else: return Response(serializer.errors) 验证如果需要对一些字段进行自定义的验证—DRF也给我们提供了钩子方法 单个字段的验证 局部钩子class BookSerializer(serializers.Serializer): id = serializers.IntegerField(read_only=True) title = serializers.CharField(max_length=32) # 省略了一些字段 跟上面代码里一样的 # 。。。。。 def validate_title(self, value): if &quot;python&quot; not in value.lower(): raise serializers.ValidationError(&quot;标题必须含有Python&quot;) return value 多个字段的验证 全局钩子class BookSerializer(serializers.Serializer): id = serializers.IntegerField(read_only=True) title = serializers.CharField(max_length=32) CHOICES = ((1, &quot;Linux&quot;), (2, &quot;Django&quot;), (3, &quot;Python&quot;)) chapter = serializers.ChoiceField(choices=CHOICES, source=&quot;get_chapter_display&quot;, read_only=True) w_chapter = serializers.IntegerField(write_only=True) pub_time = serializers.DateField() date_added = serializers.DateField(write_only=True) # 新增了一个上架时间字段 # 省略一些字段。。都是在原基础代码上增加的 # 。。。。。。 # 对多个字段进行验证 要求上架日期不能早于出版日期 上架日期要大 def validate(self, attrs): if attrs[&quot;pub_time&quot;] &gt; attrs[&quot;date_added&quot;]: raise serializers.ValidationError(&quot;上架日期不能早于出版日期&quot;) return attrs 验证器 validatorsdef my_validate(value): if &quot;敏感词汇&quot; in value.lower: raise serializers.ValidationError(&quot;包含敏感词汇，请重新提交&quot;) return value class BookSerializer(serializers.Serializer): id = serializers.IntegerField(read_only=True) title = serializers.CharField(max_length=32, validators=[my_validate]) # 。。。。。。 ModelSerializer已经清楚了Serializer的用法，会发现我们所有的序列化跟我们的模型都紧密相关~ 那么，DRF也给我们提供了跟模型紧密相关的序列化器~~ModelSerializer~~ -- 它会根据模型自动生成一组字段 -- 它简单的默认实现了.update()以及.create()方法 定义一个ModelSerializer序列化器定义ModelSerializer class BookSerializer(serializers.ModelSerializer): class Meta: model = Book fields = &quot;__all__&quot; # fields = [&quot;id&quot;, &quot;title&quot;, &quot;pub_time&quot;] # exclude = [&quot;user&quot;] # 分别是所有字段 包含某些字段 排除某些字段 外键关系的序列化注意：当序列化类MATE中定义了depth时，这个序列化类中引用字段（外键）则自动变为只读 外键关系序列化 class BookSerializer(serializers.ModelSerializer): class Meta: model = Book fields = &quot;__all__&quot; # fields = [&quot;id&quot;, &quot;title&quot;, &quot;pub_time&quot;] # exclude = [&quot;user&quot;] # 分别是所有字段 包含某些字段 排除某些字段 depth = 1 # depth 代表找嵌套关系的第几层 自定义字段我们可以声明一些字段来覆盖默认字段，来进行自定制~ 比如我们的选择字段，默认显示的是选择的key，我们要给用户展示的是value。 自定义字段 class BookSerializer(serializers.ModelSerializer): chapter = serializers.CharField(source=&quot;get_chapter_display&quot;, read_only=True) class Meta: model = Book fields = &quot;__all__&quot; # fields = [&quot;id&quot;, &quot;title&quot;, &quot;pub_time&quot;] # exclude = [&quot;user&quot;] # 分别是所有字段 包含某些字段 排除某些字段 depth = 1 Meta中其它关键字参数Meta中参数 class BookSerializer(serializers.ModelSerializer): chapter = serializers.CharField(source=&quot;get_chapter_display&quot;, read_only=True) class Meta: model = Book fields = &quot;__all__&quot; # fields = [&quot;id&quot;, &quot;title&quot;, &quot;pub_time&quot;] # exclude = [&quot;user&quot;] # 分别是所有字段 包含某些字段 排除某些字段 depth = 1 read_only_fields = [&quot;id&quot;] extra_kwargs = {&quot;title&quot;: {&quot;validators&quot;: [my_validate,]}} post以及patch请求由于depth会让我们外键变成只读，所以我们再定义一个序列化的类，其实只要去掉depth就可以了~~ post/patch请求序列化类 class BookSerializer(serializers.ModelSerializer): chapter = serializers.CharField(source=&quot;get_chapter_display&quot;, read_only=True) class Meta: model = Book fields = &quot;__all__&quot; # fields = [&quot;id&quot;, &quot;title&quot;, &quot;pub_time&quot;] # exclude = [&quot;user&quot;] # 分别是所有字段 包含某些字段 排除某些字段 read_only_fields = [&quot;id&quot;] extra_kwargs = {&quot;title&quot;: {&quot;validators&quot;: [my_validate,]}} SerializerMethodField外键关联的对象有很多字段我们是用不到的~都传给前端会有数据冗余~就需要我们自己去定制序列化外键对象的哪些字段~~ SerializerMethodField class BookSerializer(serializers.ModelSerializer): chapter = serializers.CharField(source=&quot;get_chapter_display&quot;, read_only=True) user = serializers.SerializerMethodField() publisher = serializers.SerializerMethodField() # get_是重写字段的钩子方法 def get_user(self, obj): # obj是当前序列化的book对象 users_query_set = obj.user.all() return [{&quot;id&quot;: user_obj.pk, &quot;name&quot;: user_obj.name} for user_obj in users_query_set] def get_publisher(self, obj): publisher_obj = obj.publisher return {&quot;id&quot;: publisher_obj.pk, &quot;title&quot;: publisher_obj.title} class Meta: model = Book fields = &quot;__all__&quot; # fields = [&quot;id&quot;, &quot;title&quot;, &quot;pub_time&quot;] # exclude = [&quot;user&quot;] # 分别是所有字段 包含某些字段 排除某些字段 read_only_fields = [&quot;id&quot;] extra_kwargs = {&quot;title&quot;: {&quot;validators&quot;: [my_validate,]}} 用ModelSerializer改进上面Serializer的完整版ModelSerializer class BookSerializer(serializers.ModelSerializer): dis_chapter = serializers.SerializerMethodField(read_only=True) users = serializers.SerializerMethodField(read_only=True) publishers = serializers.SerializerMethodField(read_only=True) def get_users(self, obj): # obj是当前序列化的book对象 users_query_set = obj.user.all() return [{&quot;id&quot;: user_obj.pk, &quot;name&quot;: user_obj.name} for user_obj in users_query_set] def get_publishers(self, obj): publisher_obj = obj.publisher return {&quot;id&quot;: publisher_obj.pk, &quot;title&quot;: publisher_obj.title} def get_dis_chapter(self, obj): return obj.get_chapter_display() class Meta: model = Book # fields = &quot;__all__&quot; # 字段是有序的 fields = [&quot;id&quot;, &quot;title&quot;,&quot;dis_chapter&quot;, &quot;pub_time&quot;, &quot;publishers&quot;, &quot;users&quot;,&quot;chapter&quot;, &quot;user&quot;, &quot;publisher&quot;] # exclude = [&quot;user&quot;] # 分别是所有字段 包含某些字段 排除某些字段 read_only_fields = [&quot;id&quot;, &quot;dis_chapter&quot;, &quot;users&quot;, &quot;publishers&quot;] extra_kwargs = {&quot;title&quot;: {&quot;validators&quot;: [my_validate,]}, &quot;user&quot;: {&quot;write_only&quot;: True}, &quot;publisher&quot;: {&quot;write_only&quot;: True}, &quot;chapter&quot;: {&quot;write_only&quot;: True}} 总结models.pyclass Book(models.Model): title = models.CharField(max_length=32) CHOICE = ((1, &quot;python&quot;), (2, &quot;Linux&quot;), (3, &apos;Go&apos;)) category = models.IntegerField(choices=CHOICE) pub_time = models.DateField() publisher = models.ForeignKey(to=&apos;Publisher&apos;) authors = models.ManyToManyField(to=&quot;Author&quot;) class Publisher(models.Model): title = models.CharField(max_length=32) class Author(models.Model): name = models.CharField(max_length=32) 同一个views.pyfrom demo import models from rest_framework.views import APIView from rest_framework.response import Response from serdemo import serializers # 展示增加全部数据 class BookView(APIView): def get(self, request): book_queryset = models.Book.objects.all() # many=True代表可以序列化多个数据 ser_obj = serializers.BookSerializer(book_queryset, many=True) return Response(ser_obj.data) def post(self, request): # 确定数据类型已经数据结构 # 对妹子传来的数据进行校验 book_obj = request.data ser_obj = serializers.BookSerializer(data=book_obj) if ser_obj.is_valid(): ser_obj.save() # 校验通过的数据 return Response(ser_obj.validated_data) return Response(ser_obj.errors) # 展示和编辑某条数据 class BookEditView(APIView): def get(self, request, id): book_obj = models.Book.objects.filter(id=id).first() ser_obj = serializers.BookSerializer(book_obj) return Response(ser_obj.data) def put(self, request, id): book_obj = models.Book.objects.filter(id=id).first() # partial=True 代表的是可以改部分数据 ser_obj = serializers.BookSerializer(instance=book_obj, data=request.data, partial=True) if ser_obj.is_valid(): ser_obj.save() return Response(ser_obj.validated_data) return Response(ser_obj.errors) 普通版Serializerfrom rest_framework import serializers from demo import models class PublisherSerializer(serializers.Serializer): id = serializers.IntegerField() title = serializers.CharField(max_length=32) class AuthorSerializer(serializers.Serializer): id = serializers.IntegerField() name = serializers.CharField(max_length=32) # 自定义校验 def my_validate(value): if &quot;敏感词汇&quot; in value.lower(): raise serializers.ValidationError(&quot;包含敏感词汇，请重新提交&quot;) return value class BookSerializer(serializers.Serializer): # required=False 反序列化的时候可以没有,只序列化用不走校验 id = serializers.IntegerField(required=False) title = serializers.CharField(max_length=32, validators=[my_validate]) pub_time = serializers.DateField() # read_only=True 序列化用，反序列化的时候不要了 category = serializers.CharField(source=&quot;get_category_display&quot;, read_only=True) # write_only=True 反序列化 的时候用 post_category = serializers.IntegerField(write_only=True) publisher = PublisherSerializer(read_only=True) authors = AuthorSerializer(many=True, read_only=True) publisher_id = serializers.IntegerField(write_only=True) author_list = serializers.ListField(write_only=True) # 重写create方法 创建新数据的时候 validated_data就是传来的数据 def create(self, validated_data): # validated_data 校验通过的数据 就是book_obj # 同ORM操作给Book表新增数据 book_obj = models.Book.objects.create( title=validated_data[&apos;title&apos;], pub_time=validated_data[&apos;pub_time&apos;], category=validated_data[&apos;post_category&apos;], publisher_id=validated_data[&apos;publisher_id&apos;] ) book_obj.authors.add(*validated_data[&apos;author_list&apos;]) return book_obj # 重写update方法 更新数据的时候 def update(self, instance, validated_data): # instance 更新的book_obj对象 # validated_data 校验通过的数据 # ORM做更新操作 instance.title = validated_data.get(&apos;title&apos;, instance.title) instance.pub_time = validated_data.get(&apos;pub_time&apos;, instance.pub_time) instance.category = validated_data.get(&apos;post_category&apos;, instance.category) instance.publisher_id = validated_data.get(&apos;publisher_id&apos;, instance.publisher_id) if validated_data.get(&apos;author_list&apos;): instance.authors.set(validated_data[&apos;author_list&apos;]) instance.save() return instance # 局部钩子校验 单个字段 数据校验 def validate_title(self, value): # value 就是title 的值 对value处理 if &quot;python&quot; not in value.lower(): raise serializers.ValidationError(&apos;标题必须包含python&apos;) return value # 全局钩子校验 全部字段 数据校验 def validate(self, attrs): # attr 字典有你传过来的所有的字段 if &quot;python&quot; in attrs[&quot;title&quot;].lower(): return attrs else: raise serializers.ValidationError(&quot;分类或标题不合符要求&quot;) 升级版ModelSerializerfrom rest_framework import serializers from demo import models class PublisherSerializer(serializers.Serializer): id = serializers.IntegerField() title = serializers.CharField(max_length=32) class AuthorSerializer(serializers.Serializer): id = serializers.IntegerField() name = serializers.CharField(max_length=32) # 自定义校验 def my_validate(value): if &quot;敏感词汇&quot; in value.lower(): raise serializers.ValidationError(&quot;包含敏感词汇，请重新提交&quot;) return value class BookSerializer(serializers.ModelSerializer): # 重写正序 category_info = serializers.SerializerMethodField(read_only=True) publisher_info = serializers.SerializerMethodField(read_only=True) authors_info = serializers.SerializerMethodField(read_only=True) def get_category_info(self, obj): # obj 就是序列化的每一个Book对象 return obj.get_category_display() def get_publisher_info(self, obj): # obj 就是序列化的每一个Book对象 publisher_obj = obj.publisher return {&quot;id&quot;: publisher_obj.pk, &quot;title&quot;: publisher_obj.title} def get_authors_info(self, obj): # obj 就是序列化的每一个Book对象 author_qureryset = obj.authors.all() return [{&quot;id&quot;: author_obj.pk, &quot;name&quot;: author_obj.name} for author_obj in author_qureryset] class Meta: model = models.Book fields = &quot;__all__&quot; # exclude=[&quot;id&quot;] # 会让所有的外键关系变成只读read_only=True # depth = 1 # 向下找几层 # 反序列化的时候不用自己定义的，而是还是用原来的字段 extra_kwargs = {&quot;title&quot;: {&quot;validators&quot;: [my_validate]}, &quot;publisher&quot;: {&quot;write_only&quot;: True}, &quot;authors&quot;: {&quot;write_only&quot;: True}, &quot;category&quot;: {&quot;write_only&quot;: True}} # 验证 # 局部钩子校验 单个字段 def validate_title(self, value): # value 就是title 的值 对value处理 if &quot;python&quot; not in value.lower(): raise serializers.ValidationError(&apos;标题必须包含python&apos;) return value # 全局钩子校验 全部字段 def validate(self, attrs): # attr 字典有你传过来的所有的字段 if &quot;python&quot; in attrs[&quot;title&quot;].lower(): return attrs else: raise serializers.ValidationError(&quot;分类或标题不合符要求&quot;)]]></content>
      <categories>
        <category>restful framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[RESTful规范]]></title>
    <url>%2F2017%2F11%2F14%2FRESTful%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[web服务交互 我们在浏览器中能看到的每个网站，都是一个web服务。那么我们在提供每个web服务的时候， 都需要前后端交互，前后端交互就一定有一些实现方案，我们通常叫web服务交互方案。 目前主流的三种web服务交互方案： -- REST （ Representational State Transfer）表述性状态转移 -- SOAP （Simple Object Access Protocol） 简单的对象访问协议 -- XML-RPC （XML Remote Procedure Call）基于XML的远程过程调用 XML-RPC是通过XML将调用函数封装，并使用HTTP协议作为传送机制。 后来在新的功能不断被引入下，这个标准慢慢演变成为今日的SOAP协定。 SOAP服务则是以本身所定义的操作集，来访问网络上的资源。 SOAP也是基于XML的，但是它不只限于HTTP协议的传输，包括TCP协议，UDP协议都可以传输。 REST是Roy Thomas Fielding博士于2000年在他的博士论文里提出来的。 REST相比SOAP更加简洁，性能和开发效率也有突出的优势。 我们今天主要说一下这个REST，现在越来越多的web服务开始采用REST风格设计和实现。 例如，amazon.com提供接近REST风格的Web服务进行图书查找；雅虎提供的Web服务也是REST风格的。 我们接下来要学的框架也是遵循REST风格的，那么我们来看下它到底是个什么样的风格， 了解了它是什么后，我们看下它的优点是什么，我们为什么用它。 REST风格表述性状态转移 资源 网页中能看到的都是资源 URL 统一资源定位符  URI 统一资源标识符 统一资源接口 对资源的操作根据HTTP请求方式的不同来进行不同的操作 遵循HTTP请求方式的语义 前后端传输的是资源的表述 展现的是资源的状态 通过超链接的指引来告诉用户接下来有哪些资源状态可以进入 凡是遵循TEST风格实现的前后端交互都叫RESTful架构核心思想面向资源去编程 url中尽量名词不要动词 根据HTTP请求方式的不同对资源进行不同的操作 在url中体现的体现版本 https://v3.bootcss.com/ https://.bootcss.com/v3 体现是否是API https://v3.bootcss.com/api 有过滤条件 https://v3.bootcss.com/course?page=1 尽量用https 在返回值中携带状态码 1** 信息，服务器收到请求，需要请求者继续执行操作 2** 成功，操作被成功接收并处理 3** 重定向，需要进一步的操作以完成请求 4** 客户端错误，请求包含语法错误或无法完成请求 5** 服务器错误，服务器在处理请求的过程中发生了错误 返回值 get 返回查看的所有或者单条数据 post 返回新增的这条数据 put/patch 返回更新的这条数据 delete 返回值空 携带错误信息 携带超链接 在不分离的项目用的多 ret = { code: 1000, data:{ id:1, name:&apos;小强&apos;, depart_id:http://www.luffycity.com/api/v1/depart/8/ } }]]></content>
      <categories>
        <category>restful framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[个人简介]]></title>
    <url>%2Fabout%2Findex.html</url>
    <content type="text"><![CDATA[危机感 | 对失败的容忍度 海燕 在苍茫的大海上，狂风卷集着乌云。在乌云和大海之间，海燕像黑色的闪电，在高傲地飞翔。 一会儿翅膀碰着波浪，一会儿箭一般地直冲向乌云，它叫喊着，──就在这鸟儿勇敢的叫喊声里，乌云听出了欢乐。 在这叫喊声里──充满着对暴风雨的渴望！在这叫喊声里，乌云听出了愤怒的力量、热情的火焰和胜利的信心。 海鸥在暴风雨来临之前呻吟着，──呻吟着，它们在大海上飞窜，想把自己对暴风雨的恐惧，掩藏到大海深处。 海鸭也在呻吟着，──它们这些海鸭啊，享受不了生活的战斗的欢乐：轰隆隆的雷声就把它们吓坏了。 蠢笨的企鹅，胆怯地把肥胖的身体躲藏到悬崖底下……只有那高傲的海燕，勇敢地，自由自在地，在泛起白沫的大海上飞翔！ 乌云越来越暗，越来越低，向海面直压下来，而波浪一边歌唱，一边冲向高空，去迎接那雷声。 雷声轰响。波浪在愤怒的飞沫中呼叫，跟狂风争鸣。看吧，狂风紧紧抱起一层层巨浪，恶狠狠地把它们甩到悬崖上，把这些大块的翡翠摔成尘雾和碎末。 海燕叫喊着，飞翔着，像黑色的闪电，箭一般地穿过乌云，翅膀掠起波浪的飞沫。 看吧，它飞舞着，像个精灵，──高傲的、黑色的暴风雨的精灵，——它在大笑，它又在号叫……它笑那些乌云，它因为欢乐而号叫！ 这个敏感的精灵，——它从雷声的震怒里，早就听出了困乏，它深信，乌云遮不住太阳，──是的，遮不住的！ 狂风吼叫……雷声轰响…… 一堆堆乌云，像青色的火焰，在无底的大海上燃烧。大海抓住闪电的箭光，把它们熄灭在自己的深渊里。这些闪电的影子，活像一条条火蛇，在大海里蜿蜒游动，一晃就消失了。 ——暴风雨！暴风雨就要来啦！ 这是勇敢的海燕，在怒吼的大海上，在闪电中间，高傲地飞翔；这是胜利的预言家在叫喊： ——让暴风雨来得更猛烈些吧！]]></content>
  </entry>
  <entry>
    <title><![CDATA[tags]]></title>
    <url>%2Ftags%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[分类]]></title>
    <url>%2Fcategories%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[留言板]]></title>
    <url>%2Fguestbook%2Findex.html</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
</search>
